import os
import io
import time
import json
import requests
import streamlit as st
import pandas as pd

# ================== PERFORMANCE PRODUCTS REPORT (Spend Click by SKU) ==================
def _rfc3339_day(s: str, end: bool = False) -> str:
    s = str(s or "").strip()
    if "T" in s:
        return s
    return f"{s}T23:59:59Z" if end else f"{s}T00:00:00Z"

def _parse_ru_money(x) -> float:
    """–ü–∞—Ä—Å–∏—Ç –¥–µ–Ω—å–≥–∏ –∏–∑ —Å—Ç—Ä–æ–∫ –≤–∏–¥–∞ '1 234,56', '-', '‚Äî', None."""
    if x is None:
        return 0.0
    s = str(x).strip()
    if s in ("", "-", "‚Äî", "None", "nan", "NaN"):
        return 0.0
    s = s.replace("\ufeff", "").replace("\xa0", " ").replace("‚ÇΩ", "").strip()
    s = s.replace(" ", "").replace(",", ".")
    try:
        return float(s)
    except Exception:
        return 0.0

@st.cache_data(ttl=60*30, show_spinner=False)
def load_perf_spend_click_by_sku(date_from: str, date_to: str) -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {sku:int -> spend_click(float)} –∏–∑ –æ—Ç—á—ë—Ç–∞ Performance products (JSON).

    –ü–æ–ª–µ spend_click –±–µ—Ä—ë–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –æ—Ç—á—ë—Ç–∞: MoneySpentFromCPC.
    –ö–ª—é—á–∏ –±–µ—Ä—ë–º –∏–∑ Secrets/.env:
      - PERF_CLIENT_ID / PERF_CLIENT_SECRET
      - fallback: OZON_PERF_CLIENT_ID / OZON_PERF_CLIENT_SECRET
      - fallback: OZON_CLIENT_ID / OZON_CLIENT_SECRET
    """
    perf_id = (st.secrets.get("PERF_CLIENT_ID", None) if hasattr(st, "secrets") else None) or os.getenv("PERF_CLIENT_ID") or os.getenv("OZON_PERF_CLIENT_ID") or os.getenv("OZON_CLIENT_ID")
    perf_secret = (st.secrets.get("PERF_CLIENT_SECRET", None) if hasattr(st, "secrets") else None) or os.getenv("PERF_CLIENT_SECRET") or os.getenv("OZON_PERF_CLIENT_SECRET") or os.getenv("OZON_CLIENT_SECRET")

    perf_id = str(perf_id or "").strip()
    perf_secret = str(perf_secret or "").strip()
    if not perf_id or not perf_secret:
        # –Ω–µ—Ç –∫–ª—é—á–µ–π ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ (–≤ UI –±—É–¥–µ—Ç 0)
        return {}

    BASE = "https://api-performance.ozon.ru"

    # 1) token
    try:
        r = requests.post(
            f"{BASE}/api/client/token",
            json={"client_id": perf_id, "client_secret": perf_secret, "grant_type": "client_credentials"},
            headers={"Content-Type": "application/json", "Accept": "application/json"},
            timeout=60,
        )
    except Exception:
        return {}

    if r.status_code != 200:
        return {}

    token = (r.json() or {}).get("access_token") or ""
    if not token:
        return {}

    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json", "Accept": "application/json"}

    # 2) generate json report
    try:
        gen = requests.post(
            f"{BASE}/api/client/statistics/products/generate/json",
            json={"from": _rfc3339_day(date_from, end=False), "to": _rfc3339_day(date_to, end=True)},
            headers=headers,
            timeout=60,
        )
    except Exception:
        return {}

    if gen.status_code != 200:
        return {}

    uuid = (gen.json() or {}).get("UUID") or (gen.json() or {}).get("uuid")
    if not uuid:
        return {}

    # 3) poll report json (–í–ê–ñ–ù–û: —É Ozon –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –≤—ã–¥–∞—á–∏)
    report_headers = {"Authorization": f"Bearer {token}", "Accept": "application/json"}
    candidates = [
        (f"{BASE}/api/client/statistics/report/json", {"UUID": str(uuid)}),
        (f"{BASE}/api/client/statistics/report", {"UUID": str(uuid), "format": "json"}),
        (f"{BASE}/api/client/statistics/report", {"UUID": str(uuid)}),
    ]

    last_err = None
    data = None
    for _ in range(90):  # ~180 —Å–µ–∫—É–Ω–¥ –ø—Ä–∏ sleep 2
        for url, params in candidates:
            try:
                rep = requests.get(url, params=params, headers=report_headers, timeout=60)
            except Exception as e:
                last_err = f"request error: {e}"
                continue

            if rep.status_code == 200:
                try:
                    data = rep.json()
                except Exception:
                    # –∏–Ω–æ–≥–¥–∞ content-type —Å—Ç—Ä–∞–Ω–Ω—ã–π, –Ω–æ json –µ—Å—Ç—å
                    try:
                        data = json.loads(rep.text)
                    except Exception:
                        return {}
                break

            if rep.status_code in (404, 409, 425):
                # –æ—Ç—á—ë—Ç –µ—â—ë –≥–æ—Ç–æ–≤–∏—Ç—Å—è
                last_err = f"{rep.status_code} preparing"
                continue

            # 400/401/5xx ‚Äî —Ä–µ–∞–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏
            last_err = f"{rep.status_code} {rep.text[:200]}"
            return {}

        if data is not None:
            break
        time.sleep(2)

    if data is None:
        return {}

    rows = (data.get("rows") or data.get("Rows") or data.get("result") or data.get("data") or [])
    if not isinstance(rows, list) or not rows:
        return {}

    df = pd.DataFrame(rows)
    if df.empty:
        return {}

    # SKU
    if "SKU" in df.columns:
        sku_field = "SKU"
    elif "Sku" in df.columns:
        sku_field = "Sku"
    elif "sku" in df.columns:
        sku_field = "sku"
    else:
        return {}

    df[sku_field] = pd.to_numeric(df[sku_field], errors="coerce")
    df = df.dropna(subset=[sku_field]).copy()
    if df.empty:
        return {}
    df[sku_field] = df[sku_field].astype(int)

    # MoneySpentFromCPC (spend_click)
    if "MoneySpentFromCPC" in df.columns:
        col = "MoneySpentFromCPC"
    elif "moneySpentFromCPC" in df.columns:
        col = "moneySpentFromCPC"
    else:
        # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–ª–∏ ‚Äî –ª—É—á—à–µ 0, —á–µ–º –ø–∞–¥–∞—Ç—å
        return {}

    df["spend_click"] = df[col].apply(_parse_ru_money)

    agg = df.groupby(sku_field, as_index=True)["spend_click"].sum()
    out = {int(k): float(v) for k, v in agg.to_dict().items()}
    return out

# --- DEBUG helper: raw Performance products report ---
def _perf_products_report_debug(date_from: str, date_to: str) -> dict:
    """DEBUG: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –æ—Ç—á—ë—Ç—É Performance products (json), —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –ø–æ—á–µ–º—É 0.
    –ù–∏—á–µ–≥–æ –Ω–µ –∫—ç—à–∏—Ä—É–µ—Ç –∏ –Ω–µ –º–µ–Ω—è–µ—Ç —Ä–∞—Å—á—ë—Ç—ã.
    """
    info = {"ok": False, "stage": None, "status": None}
    perf_id = (st.secrets.get("PERF_CLIENT_ID", None) if hasattr(st, "secrets") else None) or os.getenv("PERF_CLIENT_ID") or os.getenv("OZON_PERF_CLIENT_ID") or os.getenv("OZON_CLIENT_ID")
    perf_secret = (st.secrets.get("PERF_CLIENT_SECRET", None) if hasattr(st, "secrets") else None) or os.getenv("PERF_CLIENT_SECRET") or os.getenv("OZON_PERF_CLIENT_SECRET") or os.getenv("OZON_CLIENT_SECRET")
    perf_id = str(perf_id or "").strip()
    perf_secret = str(perf_secret or "").strip()
    info["has_keys"] = bool(perf_id and perf_secret)
    if not perf_id or not perf_secret:
        info["stage"] = "keys"
        return info

    BASE = "https://api-performance.ozon.ru"

    # token
    info["stage"] = "token"
    r = requests.post(
        f"{BASE}/api/client/token",
        json={"client_id": perf_id, "client_secret": perf_secret, "grant_type": "client_credentials"},
        headers={"Content-Type": "application/json", "Accept": "application/json"},
        timeout=60,
    )
    info["status"] = r.status_code
    if r.status_code != 200:
        info["error"] = (r.text or "")[:500]
        return info
    token = (r.json() or {}).get("access_token") or ""
    info["token"] = bool(token)
    if not token:
        info["error"] = "no access_token"
        return info

    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json", "Accept": "application/json"}

    # generate
    info["stage"] = "generate"
    gen = requests.post(
        f"{BASE}/api/client/statistics/products/generate/json",
        json={"from": _rfc3339_day(date_from, end=False), "to": _rfc3339_day(date_to, end=True)},
        headers=headers,
        timeout=60,
    )
    info["generate_status"] = gen.status_code
    if gen.status_code != 200:
        info["error"] = (gen.text or "")[:500]
        return info
    uuid = (gen.json() or {}).get("UUID") or (gen.json() or {}).get("uuid")
    info["uuid"] = uuid
    if not uuid:
        info["error"] = "no UUID in generate response"
        info["gen_json_keys"] = list((gen.json() or {}).keys())
        return info

    # poll
    info["stage"] = "poll"
    report_headers = {"Authorization": f"Bearer {token}", "Accept": "application/json"}

    wait_seconds = 0
    max_wait_seconds = 10 * 60  # 10 –º–∏–Ω—É—Ç
    last = None

    while wait_seconds < max_wait_seconds:
        rep = requests.get(
            f"{BASE}/api/client/statistics/report/json",
            params={"UUID": str(uuid), "uuid": str(uuid)},
            headers=report_headers,
            timeout=60,
        )
        last = rep.status_code

        if rep.status_code == 200:
            try:
                data = rep.json()
            except Exception:
                info["error"] = f"report not json, head={(rep.text or '')[:200]!r}"
                return info
            rows = data.get("rows") or []
            info["rows"] = len(rows)
            if rows:
                info["row_keys"] = list(rows[0].keys())[:40]
                df = pd.DataFrame(rows)
                if "MoneySpentFromCPC" in df.columns:
                    info["sum_MoneySpentFromCPC"] = float(df["MoneySpentFromCPC"].apply(_parse_ru_money).sum())
                if "MoneySpent" in df.columns:
                    info["sum_MoneySpent"] = float(df["MoneySpent"].apply(_parse_ru_money).sum())
            info["ok"] = True
            info["stage"] = "done"
            return info

        # 404/409/425 = –æ—Ç—á—ë—Ç –µ—â—ë –≥–æ—Ç–æ–≤–∏—Ç—Å—è
        if rep.status_code in (404, 409, 425):
            time.sleep(3)
            wait_seconds += 3
            continue

        info["error"] = (rep.text or "")[:500]
        info["report_status"] = rep.status_code
        return info

    info["report_status"] = last
    info["error"] = "report timeout"
    return info

def allocate_acquiring_cost_by_posting(df_ops: pd.DataFrame) -> pd.DataFrame:
    """–≠–∫–≤–∞–π—Ä–∏–Ω–≥ –ø–æ SKU –∑–∞ –ø–µ—Ä–∏–æ–¥ (–∫–∞–∫ –≤ –õ–ö).
    –ò—â–µ–º finance-–æ–ø–µ—Ä–∞—Ü–∏–∏ —Å operation_type_name/type_name = '–û–ø–ª–∞—Ç–∞ —ç–∫–≤–∞–π—Ä–∏–Ω–≥–∞' (–∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç '—ç–∫–≤–∞–π—Ä–∏–Ω–≥').
    –°—á–∏—Ç–∞–µ–º NET –ø–æ amount (—É—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ—Ä–Ω–æ/–ø–ª—é—Å–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏): —Ä–∞—Å—Ö–æ–¥ = max(-sum(amount), 0).
    –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –±–µ–∑ SKU ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–Ω—É—Ç—Ä–∏ posting_number –ø–æ SKU –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ accruals_for_sale (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ –ø–æ—Ä–æ–≤–Ω—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç df —Å –∫–æ–ª–æ–Ω–∫–æ–π acquiring_cost –Ω–∞ —Å—Ç—Ä–æ–∫–∞—Ö —Å SKU.
    """
    if df_ops is None or df_ops.empty:
        return df_ops

    df = df_ops.copy()
    if "acquiring_cost" not in df.columns:
        df["acquiring_cost"] = 0.0

    tn_col = "operation_type_name" if "operation_type_name" in df.columns else ("type_name" if "type_name" in df.columns else None)
    if tn_col is None or "amount" not in df.columns:
        return df

    tn = df[tn_col].astype(str).str.lower()
    mask_acq = tn.str.contains("–æ–ø–ª–∞—Ç–∞ —ç–∫–≤–∞–π—Ä–∏–Ω–≥–∞", na=False) | tn.str.contains("—ç–∫–≤–∞–π—Ä–∏–Ω–≥", na=False) | tn.str.contains("acquiring", na=False)
    if not mask_acq.any():
        return df

    amount = pd.to_numeric(df["amount"], errors="coerce").fillna(0.0)

    # –ï—Å–ª–∏ –Ω–µ—Ç posting_number ‚Äî —Ç–æ–ª—å–∫–æ –ø—Ä—è–º—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å SKU
    if "posting_number" not in df.columns:
        direct = mask_acq & df["sku"].notna()
        if direct.any():
            tmp = df.loc[direct, ["sku"]].copy()
            tmp["amount"] = amount[direct].values
            net = tmp.groupby("sku")["amount"].sum()
            # –¥–æ–±–∞–≤–∏–º –Ω–∞ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∂–¥–æ–≥–æ SKU
            for sku, amt_sum in net.items():
                idx = df.index[df["sku"] == sku]
                if len(idx) > 0:
                    df.loc[idx[0], "acquiring_cost"] += float(max(-amt_sum, 0.0))
        return df

    # 1) –ø—Ä—è–º—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å SKU: NET –ø–æ (posting_number, sku)
    direct = mask_acq & df["sku"].notna() & df["posting_number"].astype(str).ne("")
    if direct.any():
        tmp = df.loc[direct, ["posting_number", "sku"]].copy()
        tmp["amount"] = amount[direct].values
        net = tmp.groupby(["posting_number", "sku"], as_index=False)["amount"].sum()
        net["acq_cost"] = net["amount"].apply(lambda x: float(max(-x, 0.0)))

        key = df.loc[df["sku"].notna() & df["posting_number"].astype(str).ne(""), ["posting_number", "sku"]].copy()
        key["idx"] = key.index.values
        net2 = net.merge(key, on=["posting_number", "sku"], how="left").dropna(subset=["idx"])
        if not net2.empty:
            df.loc[net2["idx"].astype(int).values, "acquiring_cost"] += net2["acq_cost"].astype(float).values

    # 2) —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ SKU: NET –ø–æ posting_number –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    und = mask_acq & df["sku"].isna() & df["posting_number"].astype(str).ne("")
    if not und.any():
        return df

    acq_post = df.loc[und, ["posting_number"]].copy()
    acq_post["amount"] = amount[und].values
    acq_sum = acq_post.groupby("posting_number", as_index=False)["amount"].sum()
    acq_sum["acq_cost"] = acq_sum["amount"].apply(lambda x: float(max(-x, 0.0)))
    acq_sum = acq_sum[acq_sum["acq_cost"] > 0]
    if acq_sum.empty:
        return df

    base = df.loc[df["sku"].notna() & df["posting_number"].astype(str).ne(""), ["posting_number", "sku"]].copy()
    if base.empty:
        return df

    if "accruals_for_sale" in df.columns:
        w = pd.to_numeric(df.loc[base.index, "accruals_for_sale"], errors="coerce").fillna(0.0).abs()
        base["w"] = w.values
        base.loc[base["w"] <= 0, "w"] = 1.0
    else:
        base["w"] = 1.0

    base["w_sum"] = base.groupby("posting_number")["w"].transform("sum")
    base["share"] = base["w"] / base["w_sum"]

    alloc = base.merge(acq_sum[["posting_number", "acq_cost"]], on="posting_number", how="inner")
    if alloc.empty:
        return df
    alloc["acq_alloc"] = alloc["acq_cost"] * alloc["share"]

    key = df.loc[df["sku"].notna() & df["posting_number"].astype(str).ne(""), ["posting_number", "sku"]].copy()
    key["idx"] = key.index.values
    alloc2 = alloc.merge(key, on=["posting_number", "sku"], how="left").dropna(subset=["idx"])
    if alloc2.empty:
        return df

    df.loc[alloc2["idx"].astype(int).values, "acquiring_cost"] += alloc2["acq_alloc"].astype(float).values
    return df

def allocate_acquiring_amount_by_posting(df_ops: pd.DataFrame) -> pd.DataFrame:
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç acquiring_amount (amount –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º —ç–∫–≤–∞–π—Ä–∏–Ω–≥–∞) –ø–æ SKU –Ω–∞ —É—Ä–æ–≤–Ω–µ posting_number.

    –í–ê–ñ–ù–û: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º–µ–Ω–Ω–æ amount (–º–æ–∂–µ—Ç –±—ã—Ç—å + –∏ -), —á—Ç–æ–±—ã –≤–æ–∑–≤—Ä–∞—Ç—ã/–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ —É–º–µ–Ω—å—à–∞–ª–∏ —ç–∫–≤–∞–π—Ä–∏–Ω–≥ (–∫–∞–∫ –≤ –õ–ö).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç df_ops —Å –∫–æ–ª–æ–Ω–∫–æ–π acquiring_amount_alloc (amount, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –Ω–∞ SKU-—Å—Ç—Ä–æ–∫–∏).
    """
    if df_ops is None or df_ops.empty:
        return df_ops
    df = df_ops.copy()

    if "acquiring_amount_alloc" not in df.columns:
        df["acquiring_amount_alloc"] = 0.0

    # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ —è–≤–ª—è—é—Ç—Å—è —ç–∫–≤–∞–π—Ä–∏–Ω–≥–æ–º
    tn_col = "operation_type_name" if "operation_type_name" in df.columns else ("type_name" if "type_name" in df.columns else None)
    if tn_col is None:
        return df
    tn = df[tn_col].astype(str).str.lower()
    mask_acq = tn.str.contains("—ç–∫–≤–∞–π—Ä–∏–Ω–≥", na=False) | tn.str.contains("acquiring", na=False)
    if not mask_acq.any():
        return df

    # –±–µ—Ä—ë–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É, –µ—Å–ª–∏ –µ—Å—Ç—å
    if "acquiring_amount" in df.columns:
        amt = pd.to_numeric(df["acquiring_amount"], errors="coerce").fillna(0.0)
    else:
        amt = pd.to_numeric(df.get("amount", 0), errors="coerce").fillna(0.0)

    # 1) –ø—Ä—è–º—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å SKU
    direct = mask_acq & df["sku"].notna()
    df.loc[direct, "acquiring_amount_alloc"] += amt[direct].astype(float)

    # 2) —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ SKU ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–Ω—É—Ç—Ä–∏ posting_number
    if "posting_number" not in df.columns:
        return df

    und = mask_acq & df["sku"].isna() & df["posting_number"].astype(str).ne("")
    if not und.any():
        return df

    base = df.loc[df["sku"].notna() & df["posting_number"].astype(str).ne(""), ["posting_number", "sku"]].copy()
    if base.empty:
        return df

    # –≤–µ—Å–∞: accruals_for_sale (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ 1
    if "accruals_for_sale" in df.columns:
        w = pd.to_numeric(
            df.loc[df["sku"].notna() & df["posting_number"].astype(str).ne(""), "accruals_for_sale"],
            errors="coerce"
        ).fillna(0.0).abs()
        base["w"] = w.values
        base.loc[base["w"] <= 0, "w"] = 1.0
    else:
        base["w"] = 1.0

    base["w_sum"] = base.groupby("posting_number")["w"].transform("sum")
    base["share"] = base["w"] / base["w_sum"]

    acq_by_post = df.loc[und, ["posting_number"]].copy()
    acq_by_post["acq_amt"] = amt[und].values
    acq_sum = acq_by_post.groupby("posting_number", as_index=False)["acq_amt"].sum()

    alloc = base.merge(acq_sum, on="posting_number", how="inner")
    if alloc.empty:
        return df
    alloc["acq_alloc"] = alloc["acq_amt"] * alloc["share"]

    key = df.loc[df["sku"].notna() & df["posting_number"].astype(str).ne(""), ["posting_number", "sku"]].copy()
    key["idx"] = key.index.values
    alloc2 = alloc.merge(key, on=["posting_number", "sku"], how="left").dropna(subset=["idx"])
    if alloc2.empty:
        return df

    idx = alloc2["idx"].astype(int).values
    df.loc[idx, "acquiring_amount_alloc"] += alloc2["acq_alloc"].astype(float).values

    return df

from datetime import date, timedelta, datetime
from dotenv import load_dotenv
import sys
from pathlib import Path

# ================== AUTH ==================
APP_PASSWORD = os.getenv("APP_PASSWORD")

if "auth_ok" not in st.session_state:
    st.session_state.auth_ok = False

if not st.session_state.auth_ok:
    st.markdown(
        """
        <style>
        .auth-banner {
            max-width: 520px;
            margin: 60px auto 18px;
            padding: 16px 22px;
            border-radius: 12px;

            background: var(--secondary-background-color);
            color: var(--text-color);

            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
            text-align: center;
            font-weight: 700;
            font-size: 20px;
        }

        /* –°–¢–ò–õ–ò–ó–£–ï–ú –°–ê–ú st.form ‚Äî –≠–¢–û –í–ê–ñ–ù–û */
        div[data-testid="stForm"] {
            max-width: 520px;
            margin: 0 auto 80px;
            padding: 26px 26px 18px;
            border-radius: 12px;

            background: var(--background-color);
            border: 1px solid rgba(49, 51, 63, 0.18);
            box-shadow: 0 10px 30px rgba(0,0,0,0.08);
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.markdown(
        '<div class="auth-banner">–û—Ü–∏—Ñ—Ä–æ–≤–∫–∞ –ø–æ Ozon</div>',
        unsafe_allow_html=True,
    )

    with st.form("login_form"):
        st.markdown("## üîê –í—Ö–æ–¥ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")

        pwd = st.text_input(
            "–ü–∞—Ä–æ–ª—å",
            type="password",
            placeholder="–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å",
        )

        submitted = st.form_submit_button("–í–æ–π—Ç–∏")

        if submitted:
            if pwd == APP_PASSWORD:
                st.session_state.auth_ok = True
                st.rerun()
            else:
                st.error("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")

    st.stop()


BASE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(BASE_DIR / "src"))

from ozon_client import OzonSellerClient, last_closed_month, OzonAPIError

# ================== FRIENDLY API ERROR UI ==================

def _humanize_ozon_error(exc: Exception) -> tuple[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∑–∞–≥–æ–ª–æ–≤–æ–∫, –¥–µ—Ç–∞–ª–∏) –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI."""
    if isinstance(exc, OzonAPIError):
        sc = exc.status_code
        # —Ç–∏–ø–æ–≤—ã–µ –ø—Ä–∏—á–∏–Ω—ã
        if sc in (401, 403):
            title = "Ozon API: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ (401/403)"
            details = (
                f"–ó–∞–ø—Ä–æ—Å: {exc.path}\n"
                "–ü—Ä–æ–≤–µ—Ä—å Client-Id / Api-Key (Streamlit secrets) –∏ –¥–æ—Å—Ç—É–ø—ã –∫–ª—é—á–∞.\n\n"
                f"–û—Ç–≤–µ—Ç: {exc.body}"
            )
            return title, details
        if sc == 429:
            title = "Ozon API: –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429)"
            details = (
                f"–ó–∞–ø—Ä–æ—Å: {exc.path}\n"
                "Ozon –≤–µ—Ä–Ω—É–ª –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —á–∞—Å—Ç–æ—Ç–µ. –ü–æ–¥–æ–∂–¥–∏ 30‚Äì60 —Å–µ–∫—É–Ω–¥ –∏ –Ω–∞–∂–º–∏ ¬´–ü–æ–≤—Ç–æ—Ä–∏—Ç—å¬ª.\n\n"
                f"–û—Ç–≤–µ—Ç: {exc.body}"
            )
            return title, details
        if sc >= 500:
            title = "Ozon API: –≤—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ (5xx)"
            details = f"–ó–∞–ø—Ä–æ—Å: {exc.path}\n\n–û—Ç–≤–µ—Ç: {exc.body}"
            return title, details
        return f"Ozon API error ({sc})", f"–ó–∞–ø—Ä–æ—Å: {exc.path}\n\n–û—Ç–≤–µ—Ç: {exc.body}"

    # –ø—Ä–æ—á–∏–µ –æ—à–∏–±–∫–∏ —Å–µ—Ç–∏/—Ç–∞–π–º–∞—É—Ç—ã
    if isinstance(exc, requests.exceptions.Timeout):
        return "Ozon API: —Ç–∞–π–º–∞—É—Ç", str(exc)
    if isinstance(exc, requests.exceptions.RequestException):
        return "Ozon API: –æ—à–∏–±–∫–∞ —Å–µ—Ç–∏", str(exc)
    return "–û—à–∏–±–∫–∞", str(exc)


def _block_with_retry(title: str, details: str, cache_clear_fn=None):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±–µ–∑ –∫—Ä–∞—Å–Ω–æ–≥–æ –ø–∞–¥–µ–Ω–∏—è."""
    st.error(title)
    with st.expander("–î–µ—Ç–∞–ª–∏", expanded=False):
        st.code(details)

    c1, c2 = st.columns([1, 2])
    with c1:
        if st.button("–ü–æ–≤—Ç–æ—Ä–∏—Ç—å", use_container_width=True):
            try:
                if cache_clear_fn is not None:
                    cache_clear_fn()
                else:
                    st.cache_data.clear()
            finally:
                st.rerun()
    with c2:
        st.caption("–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è ‚Äî –ø—Ä–æ–≤–µ—Ä—å –∫–ª—é—á–∏ Ozon API –≤ secrets –∏ –ª–∏–º–∏—Ç—ã API.")

    st.stop()


# ================== CONFIG ==================
st.set_page_config(
    layout="wide",
    page_title="–û—Ü–∏—Ñ—Ä–æ–≤–∫–∞ Ozon",
    initial_sidebar_state="collapsed",
)
import sys
from pathlib import Path

def resource_path(rel: str) -> str:
    # –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –≤ exe: —Ñ–∞–π–ª—ã –ª–µ–∂–∞—Ç –≤ _MEIPASS
    if hasattr(sys, "_MEIPASS"):
        return str(Path(sys._MEIPASS) / rel)
    # –ø—Ä–∏ –æ–±—ã—á–Ω–æ–º –∑–∞–ø—É—Å–∫–µ: —Ä—è–¥–æ–º —Å app.py
    return str(Path(__file__).resolve().parent / rel)

def _get_setting(name: str, default: str = "") -> str:
    """–ë–µ—Ä—ë–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑:
    1) –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    2) Streamlit secrets (–¥–ª—è Streamlit Cloud)
    3) default
    """
    v = os.getenv(name)
    if v is not None and str(v).strip() != "":
        return str(v).strip()
    try:
        # st.secrets –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ/–≤ exe
        if hasattr(st, "secrets") and name in st.secrets:
            return str(st.secrets.get(name)).strip()
    except Exception:
        pass
    return default

# –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞/EXE: –º–æ–∂–Ω–æ –¥–µ—Ä–∂–∞—Ç—å .env —Ä—è–¥–æ–º, –Ω–æ –≤ –æ–±–ª–∞–∫–µ –µ–≥–æ –Ω–µ –±—É–¥–µ—Ç.
try:
    load_dotenv(resource_path(".env"), override=False)
except Exception:
    pass


# --- Ozon Seller API ---
client_id = _get_setting("OZON_CLIENT_ID", "")
api_key = _get_setting("OZON_API_KEY", "")
if not client_id or not api_key:
    st.error("–ù–µ—Ç OZON_CLIENT_ID / OZON_API_KEY (–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ Streamlit secrets).")
    st.stop()

client = OzonSellerClient(client_id, api_key)

# --- Supabase (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è COGS/OPEX –≤ –æ–±–ª–∞–∫–µ) ---
SUPABASE_URL = _get_setting("SUPABASE_URL", "")
SUPABASE_SERVICE_ROLE_KEY = _get_setting("SUPABASE_SERVICE_ROLE_KEY", "")
SUPABASE_SCHEMA = _get_setting("SUPABASE_SCHEMA", "public") or "public"
USE_SUPABASE = bool(SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY)

def _sb_headers() -> dict:
    h = {
        "apikey": SUPABASE_SERVICE_ROLE_KEY,
        "Authorization": f"Bearer {SUPABASE_SERVICE_ROLE_KEY}",
        "Content-Type": "application/json",
    }
    # –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –Ω–µ public —Å—Ö–µ–º—É ‚Äî Supabase REST —Ç—Ä–µ–±—É–µ—Ç —É–∫–∞–∑–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª—å
    if SUPABASE_SCHEMA and SUPABASE_SCHEMA != "public":
        h["Accept-Profile"] = SUPABASE_SCHEMA
        h["Content-Profile"] = SUPABASE_SCHEMA
    return h

def _sb_url(table: str) -> str:
    base = SUPABASE_URL.rstrip("/")
    return f"{base}/rest/v1/{table}"

def _sb_fetch(table: str, select: str = "*", limit: int = 10000) -> pd.DataFrame:
    # –ø—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ç–∞–±–ª–∏—Ü)
    params = {"select": select, "limit": str(limit)}
    r = requests.get(_sb_url(table), headers=_sb_headers(), params=params, timeout=30)
    if r.status_code >= 300:
        raise RuntimeError(f"Supabase fetch {table}: {r.status_code} {r.text}")
    data = r.json() if r.text else []
    return pd.DataFrame(data)

def _sb_replace_all(table: str, rows: list[dict], delete_filter: str) -> None:
    # 1) –æ—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–æ —Ñ–∏–ª—å—Ç—Ä—É
    r_del = requests.delete(_sb_url(table) + f"?{delete_filter}", headers=_sb_headers(), timeout=30)
    if r_del.status_code >= 300:
        raise RuntimeError(f"Supabase delete {table}: {r_del.status_code} {r_del.text}")
    # 2) –≤—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
    if rows:
        r_ins = requests.post(
            _sb_url(table),
            headers={**_sb_headers(), "Prefer": "return=minimal"},
            data=json.dumps(rows, ensure_ascii=False),
            timeout=30,
        )
        if r_ins.status_code >= 300:
            raise RuntimeError(f"Supabase insert {table}: {r_ins.status_code} {r_ins.text}")


# ================== PERF API (ADS) ==================
class OzonPerfClient:
    """
    Ozon Performance API (ADS) ‚Äî —Ä–∞–±–æ—á–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç CSV.

    - campaigns: GET /api/client/campaign (JSON)
    - daily:     GET /api/client/statistics/daily (CSV, sep=';', decimal=',')

    –í–ê–ñ–ù–û:
    - campaignIds –Ω–µ–ª—å–∑—è —Å–ª–∞—Ç—å —Å—Ç—Ä–æ–∫–æ–π "1,2,3"
      –ù—É–∂–Ω–æ campaignIds=1&campaignIds=2 (requests —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫)
    """

    def __init__(self, client_id: str, client_secret: str, base_url: str = "https://api-performance.ozon.ru"):
        self.client_id = str(client_id).strip()
        self.client_secret = str(client_secret).strip()
        self.base_url = base_url.rstrip("/")
        self._token = None
        self._token_ts = 0.0
        self._token_ttl = 50 * 60  # 50 –º–∏–Ω
        self._last_debug = {}

    # ----------------- token -----------------
    def _request_json(self, method: str, path: str, *, headers=None, params=None, json_body=None, timeout=30) -> dict:
        url = self.base_url + path
        h = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "ozon-ads-dashboard/1.0",
        }
        if headers:
            h.update(headers)

        r = requests.request(method=method.upper(), url=url, headers=h, params=params, json=json_body, timeout=timeout)

        if r.status_code < 200 or r.status_code >= 300:
            raise RuntimeError(f"{r.status_code} {path}: {r.text}")

        try:
            return r.json()
        except Exception:
            # –∏–Ω–æ–≥–¥–∞ JSON –±–µ–∑ content-type
            raise RuntimeError(f"–û–∂–∏–¥–∞–ª JSON, –Ω–æ –ø—Ä–∏—à–ª–æ –Ω–µ JSON: {r.text[:1000]}")

    def _get_token_uncached(self) -> str:
        data = self._request_json(
            "POST",
            "/api/client/token",
            json_body={
                "client_id": int(self.client_id) if self.client_id.isdigit() else self.client_id,
                "client_secret": self.client_secret,
                "grant_type": "client_credentials",
            },
        )
        token = data.get("access_token")
        if not token:
            raise RuntimeError(f"–ù–µ –ø–æ–ª—É—á–∏–ª access_token. –û—Ç–≤–µ—Ç: {data}")
        return token

    def get_token(self) -> str:
        now = time.time()
        if self._token and (now - self._token_ts) < self._token_ttl:
            return self._token
        token = self._get_token_uncached()
        self._token = token
        self._token_ts = now
        return token

    # ----------------- helpers -----------------
    @staticmethod
    def _safe_date10(s: str):
        try:
            s10 = str(s)[:10]
            return datetime.strptime(s10, "%Y-%m-%d").date()
        except Exception:
            return None

    @staticmethod
    def _iter_chunks(d1: date, d2: date, max_days: int = 62):
        cur = d1
        while cur <= d2:
            chunk_to = min(cur + timedelta(days=max_days - 1), d2)
            yield cur, chunk_to
            cur = chunk_to + timedelta(days=1)

    def last_debug(self) -> dict:
        return self._last_debug or {}
    @staticmethod
    def _humanize_error(msg: str) -> str:
        m = (msg or "").strip()

        # –°–∞–º–∞—è —á–∞—Å—Ç–∞—è: –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–µ—Ä–∏–æ–¥–∞
        if "max statistics period" in m and "62" in m:
            return (
                "Performance API: –≤—ã–±—Ä–∞–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n\n"
                "‚ö†Ô∏è Ozon –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –≤—ã–≥—Ä—É–∑–∫—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∫–ª–∞–º—ã –º–∞–∫—Å–∏–º—É–º **62 –¥–Ω—è** –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å.\n"
                "–°–æ–∫—Ä–∞—Ç–∏ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ 30‚Äì60 –¥–Ω–µ–π) ‚Äî –∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ä–µ–∫–ª–∞–º—ã –ø–æ—è–≤—è—Ç—Å—è.\n\n"
                "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –ø—Ä–æ–¥–∞–∂–∏/–ø—Ä–∏–±—ã–ª—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º —Å—á–∏—Ç–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –∏ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∏ –Ω–∞ –±–æ–ª—å—à–æ–º –ø–µ—Ä–∏–æ–¥–µ."
            )

        # –ù–∞ –±—É–¥—É—â–µ–µ ‚Äî –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω/–¥–æ—Å—Ç—É–ø
        if "401" in m or "unauthorized" in m.lower():
            return (
                "Performance API: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ (401).\n\n"
                "–ü—Ä–æ–≤–µ—Ä—å PERF_CLIENT_ID / PERF_CLIENT_SECRET –≤ .env –∏ –ø—Ä–∞–≤–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."
            )

        return f"Performance API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {m}"

    # ----------------- campaigns -----------------
    def list_campaigns(self) -> list[dict]:
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        data = self._request_json("GET", "/api/client/campaign", headers=headers)

        if isinstance(data, list):
            return data

        for k in ("list", "result", "campaigns", "items", "data", "rows"):
            if isinstance(data, dict) and isinstance(data.get(k), list):
                return data[k]

        return []

    def campaign_ids_overlapping(self, date_from_str: str, date_to_str: str, limit: int = 300) -> list[int]:
        d_from = self._safe_date10(date_from_str)
        d_to = self._safe_date10(date_to_str)
        camps = self.list_campaigns()

        ids: list[int] = []
        for c in camps:
            cid = c.get("id")
            if cid is None:
                continue

            c_from = self._safe_date10(c.get("fromDate") or c.get("dateFrom") or c.get("date_from") or "")
            c_to = self._safe_date10(c.get("toDate") or c.get("dateTo") or c.get("date_to") or "")

            ok = True
            if d_from and d_to and (c_from or c_to):
                left = c_from or d_from
                right = c_to or d_to
                ok = not (right < d_from or left > d_to)

            if ok:
                try:
                    ids.append(int(cid))
                except Exception:
                    pass

            if len(ids) >= limit:
                break

        return ids

    # ----------------- daily CSV -----------------
    @staticmethod
    def _parse_csv_semicolon(text: str) -> pd.DataFrame:
        cleaned = (text or "").lstrip("\ufeff").strip()
        if not cleaned:
            return pd.DataFrame()

        df = pd.read_csv(
            io.StringIO(cleaned),
            sep=";",
            dtype=str,
            keep_default_na=False,
        )

        # –ü—Ä–∏–≤–æ–¥–∏–º —á–∏—Å–ª–∞: "1 234,56" -> 1234.56
        for col in df.columns:
            s = df[col].astype(str)
            if s.str.contains(r"\d", regex=True).any():
                s2 = (
                    s.str.replace("\u00a0", "", regex=False)
                     .str.replace(" ", "", regex=False)
                     .str.replace(",", ".", regex=False)
                )
                df[col] = pd.to_numeric(s2, errors="ignore")

        return df

    @staticmethod
    def _norm_col(s: str) -> str:
        return str(s).strip().lower().replace("\u00a0", " ").replace("  ", " ")

    @staticmethod
    def _pick_num(df: pd.DataFrame, candidates: list[str]) -> float:
        cols_l = {OzonPerfClient._norm_col(c): c for c in df.columns}
        for name in candidates:
            key = OzonPerfClient._norm_col(name)
            if key in cols_l:
                v = pd.to_numeric(df[cols_l[key]], errors="coerce").fillna(0).sum()
                try:
                    return float(v)
                except Exception:
                    return 0.0
        return 0.0

    @staticmethod
    def _pick_int(df: pd.DataFrame, candidates: list[str]) -> int:
        return int(round(OzonPerfClient._pick_num(df, candidates)))

    def fetch_statistics_daily(self, date_from_str: str, date_to_str: str, campaign_ids: list[int]) -> tuple[dict, dict]:
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        # params: –µ—Å–ª–∏ ids –ø—É—Å—Ç—ã–µ ‚Äî –ø—Ä–æ–±—É–µ–º –±–µ–∑ campaignIds (—É —Ç–µ–±—è —Ç–∞–∫ —Ä–µ–∞–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–ª–æ)
        params: dict = {"dateFrom": date_from_str, "dateTo": date_to_str}

        ids = [int(x) for x in (campaign_ids or []) if str(x).isdigit()]
        if ids:
            # –ö–õ–Æ–ß–ï–í–û–ï: —Å–ø–∏—Å–æ–∫ -> campaignIds=1&campaignIds=2...
            params["campaignIds"] = ids[:200]

        url = self.base_url + "/api/client/statistics/daily"

        r = requests.get(
            url,
            headers={
                "Authorization": f"Bearer {token}",
                "Accept": "*/*",
                "User-Agent": "ozon-ads-dashboard/1.0",
            },
            params=params,
            timeout=20
        )

        meta = {
            "ok_variant": {"method": "GET", "path": "/api/client/statistics/daily", "params": params},
            "status_code": r.status_code,
            "content_type": r.headers.get("Content-Type", ""),
            "url": r.url,
        }

        if r.status_code != 200:
            raise RuntimeError(f"{r.status_code} /api/client/statistics/daily: {r.text}")

        df = self._parse_csv_semicolon(r.text)

        # --- –ú–ï–¢–†–ò–ö–ò –ò–ó –¢–í–û–ï–ì–û CSV (—Ä—É—Å—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏) ---
        spent = self._pick_num(df, ["–†–∞—Å—Ö–æ–¥, ‚ÇΩ", "–†–∞—Å—Ö–æ–¥", "–ó–∞—Ç—Ä–∞—Ç—ã", "Cost", "Spent"])
        revenue = self._pick_num(df, ["–ó–∞–∫–∞–∑—ã, ‚ÇΩ", "–ó–∞–∫–∞–∑—ã ‚ÇΩ", "–í—ã—Ä—É—á–∫–∞", "–û–±–æ—Ä–æ—Ç", "Revenue"])
        orders = self._pick_int(df, ["–ó–∞–∫–∞–∑—ã, —à—Ç.", "–ó–∞–∫–∞–∑—ã, —à—Ç", "–ó–∞–∫–∞–∑—ã —à—Ç", "Orders", "Orders count"])
        clicks = self._pick_num(df, ["–ö–ª–∏–∫–∏", "Clicks"])
        shows = self._pick_num(df, ["–ü–æ–∫–∞–∑—ã", "Impressions", "Shows"])

        drr = (spent / revenue * 100.0) if revenue else 0.0
        cpc = (spent / clicks) if clicks else 0.0
        ctr = (clicks / shows * 100.0) if shows else 0.0

        dbg = {
            **meta,
            "rows_count": int(len(df)),
            "columns": [str(c) for c in df.columns],
            "head": df.head(5).to_dict(orient="records") if not df.empty else [],
        }

        metrics = {"spent": spent, "revenue": revenue, "orders": orders, "clicks": float(clicks), "shows": float(shows), "drr": drr, "cpc": cpc, "ctr": ctr}
        return metrics, dbg

    def fetch_shop_summary(self, date_from_str: str, date_to_str: str) -> tuple[dict, str, dict]:
        base = {"spent": 0.0, "revenue": 0.0, "orders": 0, "drr": 0.0, "cpc": 0.0, "ctr": 0.0}

        try:
            d1 = self._safe_date10(date_from_str)
            d2 = self._safe_date10(date_to_str)
            if not d1 or not d2:
                return base, "Performance API: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –ø–µ—Ä–∏–æ–¥–∞.", {"error": "bad dates"}

            # ids –∫–∞–∫ —Ä–∞–Ω—å—à–µ
            ids = self.campaign_ids_overlapping(date_from_str, date_to_str, limit=300)

            totals = {
                "spent": 0.0,
                "revenue": 0.0,
                "orders": 0,
                "clicks": 0.0,
                "shows": 0.0,
            }

            chunks_info = []
            errors = []

            for a, b in self._iter_chunks(d1, d2, max_days=62):
                a_s = a.strftime("%Y-%m-%d")
                b_s = b.strftime("%Y-%m-%d")

                try:
                    m, dbg = self.fetch_statistics_daily(a_s, b_s, ids)

                    # —Å—É–º–º–∏—Ä—É–µ–º "—Å—ã—Ä—ã–µ" –∏—Ç–æ–≥–∏
                    totals["spent"] += float(m.get("spent", 0.0))
                    totals["revenue"] += float(m.get("revenue", 0.0))
                    totals["orders"] += int(m.get("orders", 0) or 0)

                    # clicks/shows –±–µ—Ä–µ–º –∏–∑ dbg? —É –Ω–∞—Å –æ–Ω–∏ –≤ metrics —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω—ã —Ç–æ–ª—å–∫–æ –∫–∞–∫ cpc/ctr,
                    # –ø–æ—ç—Ç–æ–º—É –ª—É—á—à–µ –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –≤–Ω—É—Ç—Ä–∏ fetch_statistics_daily –∏ –≤–µ—Ä–Ω—É—Ç—å clicks/shows —Ç–æ–∂–µ.
                    # –ù–æ —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å, –∏–∑–≤–ª–µ—á—ë–º –∏–∑ df —á–µ—Ä–µ–∑ dbg –Ω–µ–ª—å–∑—è.
                    # => –†–µ—à–µ–Ω–∏–µ: –î–û–ë–ê–í–ò –≤ metrics –Ω–∏–∂–µ clicks/shows. (—Å–º. –º–∏–Ω–∏-–ø—Ä–∞–≤–∫—É ‚Ññ2.1)
                    totals["clicks"] += float(m.get("clicks", 0.0))
                    totals["shows"] += float(m.get("shows", 0.0))

                    chunks_info.append({"from": a_s, "to": b_s, "rows": int(dbg.get("rows_count", 0))})
                except Exception as e:
                    errors.append({"from": a_s, "to": b_s, "error": str(e)})

            # –µ—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å
            if totals["spent"] == 0 and totals["revenue"] == 0 and totals["orders"] == 0 and not chunks_info:
                note = self._humanize_error(errors[0]["error"]) if errors else "Performance API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
                dbg = {"error": "all chunks failed", "errors": errors, "chunks": chunks_info}
                self._last_debug = dbg
                return base, note, dbg

            # –ø–µ—Ä–µ—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –æ—Ç –∏—Ç–æ–≥–æ–≤
            spent = totals["spent"]
            revenue = totals["revenue"]
            orders = totals["orders"]
            clicks = totals["clicks"]
            shows = totals["shows"]

            drr = (spent / revenue * 100.0) if revenue else 0.0
            cpc = (spent / clicks) if clicks else 0.0
            ctr = (clicks / shows * 100.0) if shows else 0.0

            metrics = {"spent": spent, "revenue": revenue, "orders": orders, "drr": drr, "cpc": cpc, "ctr": ctr}

            note = ""
            if (d2 - d1).days + 1 > 62:
                note = f"Performance: –ø–µ—Ä–∏–æ–¥ –±–æ–ª—å—à–µ 62 –¥–Ω–µ–π ‚Äî –ø–æ—Å—á–∏—Ç–∞–Ω–æ —á–∞–Ω–∫–∞–º–∏ ({len(chunks_info)} –∑–∞–ø—Ä–æ—Å–æ–≤)."
            if errors:
                note = (note + "\n" if note else "") + f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å {len(errors)} —á–∞–Ω–∫–æ–≤ ‚Äî –∏—Ç–æ–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º."

            dbg = {
                "campaign_ids_count": len(ids),
                "campaign_ids_sample": ids[:50],
                "chunks": chunks_info,
                "errors": errors,
                "dateFrom": date_from_str,
                "dateTo": date_to_str,
            }
            self._last_debug = dbg

            return metrics, note, dbg

        except Exception as e:
            msg = str(e)
            note = self._humanize_error(msg)
            dbg = {"error": msg}
            self._last_debug = dbg
            return base, note, dbg


perf_id = _get_setting("PERF_CLIENT_ID", "")
perf_secret = _get_setting("PERF_CLIENT_SECRET", "")
perf_client: OzonPerfClient | None = None
if perf_id and perf_secret:
    try:
        perf_client = OzonPerfClient(perf_id, perf_secret)
    except Exception:
        perf_client = None

st.title("–û—Ü–∏—Ñ—Ä–æ–≤–∫–∞ Ozon")

# ================== GLOBAL STYLES ==================
st.markdown(
    """
<style>
div[data-testid="stDateInput"] small { display: none !important; }

.ts-tile{
  border-radius: 14px;
  padding: 14px 16px 12px 16px;
  border: 2px solid rgba(0,0,0,0.2);
  background: rgba(255,255,255,0.06);
  min-height: 108px;
}
.ts-title{ font-size: 13px; opacity: 0.9; margin-bottom: 6px; }
.ts-value{ font-size: 26px; font-weight: 800; line-height: 1.05; }
.ts-delta{ margin-top: 6px; font-size: 13px; font-weight: 700; opacity: 0.95; }

.ts-good{ background: rgba(34,197,94,0.18); border-color: rgba(34,197,94,0.60); }
.ts-good .ts-delta{ color: rgba(34,197,94,1); }

.ts-bad{ background: rgba(239,68,68,0.18); border-color: rgba(239,68,68,0.60); }
.ts-bad .ts-delta{ color: rgba(239,68,68,1); }

.ts-neutral{ background: rgba(148,163,184,0.12); border-color: rgba(148,163,184,0.40); }
.ts-neutral .ts-delta{ color: rgba(148,163,184,1); }

@media (max-width: 900px){
  .ts-value{ font-size: 22px; }
  .ts-tile{ min-height: 98px; }
}
</style>
""",
    unsafe_allow_html=True,
)

st.markdown("""
<style>
/* –î–µ–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç/placeholder –≤ input –≤–∏–∑—É–∞–ª—å–Ω–æ –ø–æ —Ü–µ–Ω—Ç—Ä—É (–∑–∞ —Å—á—ë—Ç padding/line-height) */
div[data-testid="stTextInput"] input {
  padding-top: 0.55rem !important;
  padding-bottom: 0.55rem !important;
  line-height: 1.2 !important;
}

/* –ß—É—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º selectbox, —á—Ç–æ–±—ã –æ–Ω –≤—ã–≥–ª—è–¥–µ–ª –∫–∞–∫ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è */
div[data-testid="stSelectbox"] div[role="combobox"] {
  padding-top: 0.45rem !important;
  padding-bottom: 0.45rem !important;
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* ===== OPEX: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω–ø—É—Ç—ã –≤ —Å—Ç—Ä–æ–∫–µ "–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥" ===== */

/* –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–ª–æ–Ω–æ–∫ –ø–æ –Ω–∏–∑—É */
div[data-testid="stHorizontalBlock"]{
  align-items: flex-end;
}

/* –¥–µ–ª–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –≤—ã—Å–æ—Ç—É –ø–æ–ª–µ–π –≤–≤–æ–¥–∞ (date/text/number) */
div[data-testid="stDateInput"] input,
div[data-testid="stTextInput"] input,
div[data-testid="stNumberInput"] input{
  height: 44px !important;
  line-height: 44px !important;
  padding-top: 0 !important;
  padding-bottom: 0 !important;
}

/* st_tags (baseweb tag input) ‚Äî —á—Ç–æ–±—ã –±—ã–ª —Ç–æ–π –∂–µ –≤—ã—Å–æ—Ç—ã */
div[data-baseweb="tag-input"]{
  min-height: 44px !important;
  align-items: center !important;
}
div[data-baseweb="tag-input"] > div{
  min-height: 44px !important;
  align-items: center !important;
}

/* –∫–Ω–æ–ø–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è ‚Äî –≤ —Ç—É –∂–µ –≤—ã—Å–æ—Ç—É */
button[kind="secondary"], button[kind="primary"]{
  height: 44px !important;
}
</style>
""", unsafe_allow_html=True)

# ================== HELPERS ==================
def money(x) -> str:
    try:
        return f"{float(x):,.0f} ‚ÇΩ".replace(",", " ")
    except Exception:
        return "0 ‚ÇΩ"

def _to_float(x):
    try:
        return float(x)
    except Exception:
        return 0.0

def _to_int(x):
    try:
        return int(float(x))
    except Exception:
        return 0

def to_cost(x: float) -> float:
    x = float(x or 0.0)
    return abs(x)

DATA_DIR = "data"
COGS_PATH = os.path.join(DATA_DIR, "cogs.csv")
OPEX_PATH = os.path.join(DATA_DIR, "opex.csv")
OPEX_TYPES_PATH = os.path.join(DATA_DIR, "opex_types.json")

def load_opex_types() -> list[str]:
    ensure_data_dir()
    if os.path.exists(OPEX_TYPES_PATH):
        try:
            with open(OPEX_TYPES_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            if isinstance(data, list):
                out = []
                for x in data:
                    s = str(x).strip()
                    if s:
                        out.append(s)
                return sorted(set(out), key=lambda s: s.lower())
        except Exception:
            pass
    return []

def save_opex_types(types: list[str]):
    ensure_data_dir()
    out = []
    for x in (types or []):
        s = str(x).strip()
        if s:
            out.append(s)
    out = sorted(set(out), key=lambda s: s.lower())
    with open(OPEX_TYPES_PATH, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)


def ensure_data_dir():
    os.makedirs(DATA_DIR, exist_ok=True)

# ================== COGS ==================
def normalize_cogs_upload(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame(columns=["article", "sku", "cogs"])

    df2 = df.copy()
    df2.columns = [str(c).strip() for c in df2.columns]

    sku_candidates = [c for c in df2.columns if c.lower() in ("sku", "item.sku", "–æ–∑–æ–Ω sku", "ozon sku")]
    if not sku_candidates:
        sku_candidates = [c for c in df2.columns if "sku" in c.lower()]
    sku_col = sku_candidates[0] if sku_candidates else None

    cogs_candidates = [c for c in df2.columns if c.lower() in ("—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Å–µ–±–µ—Å", "cogs", "cost", "cost_price", "costprice")]
    if not cogs_candidates:
        cogs_candidates = [c for c in df2.columns if "—Å–µ–±" in c.lower() or "cost" in c.lower()]
    cogs_col = cogs_candidates[0] if cogs_candidates else None

    art_candidates = [c for c in df2.columns if "–∞—Ä—Ç–∏–∫—É–ª" in c.lower() or "offer" in c.lower() or "article" in c.lower()]
    art_col = art_candidates[0] if art_candidates else None

    if sku_col is None or cogs_col is None:
        if df2.shape[1] >= 3:
            art_col = art_col or df2.columns[0]
            sku_col = sku_col or df2.columns[1]
            cogs_col = cogs_col or df2.columns[2]
        else:
            return pd.DataFrame(columns=["article", "sku", "cogs"])

    out = pd.DataFrame({
        "article": df2[art_col] if art_col in df2.columns else "",
        "sku": df2[sku_col],
        "cogs": df2[cogs_col],
    })

    out["sku"] = (
    out["sku"]
    .astype(str)
    .str.replace(r"[^\d]", "", regex=True)   # —É–±–∏—Ä–∞–µ–º –∑–∞–ø—è—Ç—ã–µ/–ø—Ä–æ–±–µ–ª—ã/–º—É—Å–æ—Ä
    )
    out["sku"] = pd.to_numeric(out["sku"], errors="coerce").astype("Int64")
    out["cogs"] = pd.to_numeric(out["cogs"], errors="coerce").fillna(0.0)
    out = out.dropna(subset=["sku"]).copy()
    out["sku"] = out["sku"].astype(int)
    out["article"] = out["article"].astype(str).fillna("")
    out = out[["article", "sku", "cogs"]].drop_duplicates(subset=["sku"], keep="last").sort_values("sku")
    return out

def load_cogs() -> pd.DataFrame:
    ensure_data_dir()
    # 1) Supabase –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–µ–µ
    if USE_SUPABASE:
        try:
            df = _sb_fetch("cogs", select="sku,article,cogs", limit=100000)
            if not df.empty:
                df.columns = [str(c).strip() for c in df.columns]
                if "article" not in df.columns:
                    df["article"] = ""
                df["sku"] = pd.to_numeric(df["sku"], errors="coerce").astype("Int64")
                df["cogs"] = pd.to_numeric(df["cogs"], errors="coerce").fillna(0.0)
                df = df.dropna(subset=["sku"]).copy()
                df["sku"] = df["sku"].astype(int)
                df["article"] = df["article"].fillna("").astype(str)
                df = df[["article","sku","cogs"]].drop_duplicates(subset=["sku"], keep="last").sort_values("sku")
                return df
        except Exception:
            pass
    if os.path.exists(COGS_PATH):
        try:
            df = pd.read_csv(COGS_PATH, encoding="utf-8-sig")
            df.columns = [str(c).strip() for c in df.columns]
            if "sku" not in df.columns or "cogs" not in df.columns:
                df = normalize_cogs_upload(df)
            else:
                if "article" not in df.columns:
                    df["article"] = ""
                df["sku"] = (
                    df["sku"]
                    .astype(str)
                    .str.replace(r"[^\d]", "", regex=True)
                )
                df["sku"] = pd.to_numeric(df["sku"], errors="coerce").astype("Int64")
                df["cogs"] = pd.to_numeric(df["cogs"], errors="coerce").fillna(0.0)
                df = df.dropna(subset=["sku"]).copy()
                df["sku"] = df["sku"].astype(int)
                df["article"] = df["article"].astype(str).fillna("")
                df = df[["article", "sku", "cogs"]].drop_duplicates(subset=["sku"], keep="last").sort_values("sku")
            return df
        except Exception:
            return pd.DataFrame(columns=["article", "sku", "cogs"])
    return pd.DataFrame(columns=["article", "sku", "cogs"])

def save_cogs(df: pd.DataFrame):
    ensure_data_dir()
    df2 = df.copy() if df is not None else pd.DataFrame(columns=["article","sku","cogs"])
    if "article" not in df2.columns:
        df2["article"] = ""
    if "cogs" not in df2.columns:
        df2["cogs"] = 0.0

    df2 = df2[["article", "sku", "cogs"]].copy()
    df2["sku"] = pd.to_numeric(df2["sku"], errors="coerce").astype("Int64")
    df2["cogs"] = pd.to_numeric(df2["cogs"], errors="coerce").fillna(0.0)
    df2 = df2.dropna(subset=["sku"]).copy()
    df2["sku"] = df2["sku"].astype(int)
    df2["article"] = df2["article"].astype(str).fillna("")
    df2 = df2.drop_duplicates(subset=["sku"], keep="last").sort_values("sku")

    # 1) Supabase
    if USE_SUPABASE:
        rows = df2[["sku", "article", "cogs"]].copy()
        payload = rows.to_dict(orient="records")
        _sb_replace_all("cogs", payload, "sku=gt.0")

    # 2) –õ–æ–∫–∞–ª—å–Ω–æ (fallback)
    df2.to_csv(COGS_PATH, index=False, encoding="utf-8-sig")


# ================== OPEX (Operational expenses) ==================
def _opex_empty() -> pd.DataFrame:
    return pd.DataFrame(columns=["date", "type", "amount"])

def load_opex() -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç OPEX.

    –í Streamlit Cloud —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ñ–µ–º–µ—Ä–Ω–æ–π, –ø–æ—ç—Ç–æ–º—É:
    1) –µ—Å–ª–∏ USE_SUPABASE=True ‚Äî —Å–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –∏–∑ Supabase —Ç–∞–±–ª–∏—Ü—É `opex`;
    2) –∏–Ω–∞—á–µ / –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî —á–∏—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π CSV (fallback).
    """
    ensure_data_dir()

    # 1) Supabase (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    if USE_SUPABASE:
        try:
            df = _sb_fetch("opex", select="date,type,amount", limit=100000)
            if df is not None and not df.empty:
                df.columns = [str(c).strip().lower() for c in df.columns]
                # –æ–∂–∏–¥–∞–µ–º: date, type, amount
                if "date" not in df.columns and "–¥–∞—Ç–∞" in df.columns:
                    df = df.rename(columns={"–¥–∞—Ç–∞": "date"})
                if "type" not in df.columns:
                    for c in df.columns:
                        if "—Ç–∏–ø" in c or "category" in c:
                            df = df.rename(columns={c: "type"})
                            break
                if "amount" not in df.columns:
                    for c in df.columns:
                        if "—Å—É–º–º" in c or "amount" in c:
                            df = df.rename(columns={c: "amount"})
                            break
                if {"date","type","amount"}.issubset(set(df.columns)):
                    df = df[["date","type","amount"]].copy()
                    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
                    df["type"] = df["type"].fillna("").astype(str)
                    df["amount"] = pd.to_numeric(df["amount"], errors="coerce").fillna(0.0)
                    df = df.dropna(subset=["date"]).sort_values(["date","type"]).reset_index(drop=True)
                    return df
        except Exception:
            # —É–ø–∞–ª–∏ –Ω–∞ Supabase ‚Äî –∏–¥—ë–º –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π fallback
            pass

    # 2) –õ–æ–∫–∞–ª—å–Ω—ã–π CSV (fallback)
    if os.path.exists(OPEX_PATH):
        try:
            df = pd.read_csv(OPEX_PATH, encoding="utf-8-sig")
            df.columns = [str(c).strip().lower() for c in df.columns]
            # –æ–∂–∏–¥–∞–µ–º: date, type, amount
            if "date" not in df.columns:
                # –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
                if "–¥–∞—Ç–∞" in df.columns:
                    df = df.rename(columns={"–¥–∞—Ç–∞": "date"})
            if "type" not in df.columns:
                for c in df.columns:
                    if "—Ç–∏–ø" in c or "category" in c:
                        df = df.rename(columns={c: "type"})
                        break
            if "amount" not in df.columns:
                for c in df.columns:
                    if "—Å—É–º–º" in c or "amount" in c:
                        df = df.rename(columns={c: "amount"})
                        break
            if not {"date","type","amount"}.issubset(set(df.columns)):
                return _opex_empty()
            df = df[["date","type","amount"]].copy()
            df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
            df["type"] = df["type"].fillna("").astype(str)
            df["amount"] = pd.to_numeric(df["amount"], errors="coerce").fillna(0.0)
            df = df.dropna(subset=["date"]).sort_values(["date","type"]).reset_index(drop=True)
            return df
        except Exception:
            return _opex_empty()

    return _opex_empty()

def save_opex(df: pd.DataFrame):
    ensure_data_dir()

    df2 = df.copy() if df is not None else _opex_empty()
    if df2.empty:
        df2 = _opex_empty()

    df2 = df2[["date","type","amount"]].copy()
    df2["date"] = pd.to_datetime(df2["date"], errors="coerce").dt.date
    df2["type"] = df2["type"].fillna("").astype(str)
    df2["amount"] = pd.to_numeric(df2["amount"], errors="coerce").fillna(0.0)
    df2 = df2.dropna(subset=["date"]).sort_values(["date","type"]).reset_index(drop=True)

    # 1) Supabase
    if USE_SUPABASE:
        rows = df2.copy()
        rows["date"] = pd.to_datetime(rows["date"], errors="coerce").dt.strftime("%Y-%m-%d")
        payload = rows.to_dict(orient="records")
        _sb_replace_all("opex", payload, "date=gte.1900-01-01")

    # 2) –õ–æ–∫–∞–ª—å–Ω–æ
    out = df2.copy()
    out["date"] = out["date"].apply(lambda d: d.strftime("%Y-%m-%d") if hasattr(d, "strftime") else str(d))
    out.to_csv(OPEX_PATH, index=False, encoding="utf-8-sig")

def opex_sum_period(df_opex: pd.DataFrame, d_from: date, d_to: date) -> float:
    if df_opex is None or df_opex.empty:
        return 0.0
    mask = (df_opex["date"] >= d_from) & (df_opex["date"] <= d_to)
    return float(pd.to_numeric(df_opex.loc[mask, "amount"], errors="coerce").fillna(0.0).sum())


# --- Sidebar COGS ---
st.sidebar.header("–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å")
ensure_data_dir()

uploaded = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ (–ê—Ä—Ç–∏–∫—É–ª / SKU / –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å)",
    type=["csv", "xlsx", "xls"],
    accept_multiple_files=False
)

# --- –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê SUPABASE (–≤—Ä–µ–º–µ–Ω–Ω–æ) ---
if USE_SUPABASE:
    st.sidebar.write("‚úÖ")
else:
    st.sidebar.write("SUPABASE OFF ‚ùå (–Ω–µ—Ç SUPABASE_URL –∏–ª–∏ SUPABASE_SERVICE_ROLE_KEY)")

cogs_df = load_cogs()
df_opex = load_opex()

if uploaded is not None:
    try:
        if uploaded.name.lower().endswith(".csv"):
            tmp = pd.read_csv(uploaded, encoding="utf-8-sig")
        else:
            tmp = pd.read_excel(uploaded)

        cogs_df = normalize_cogs_upload(tmp)
        save_cogs(cogs_df)

        st.sidebar.success("–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    except Exception as e:
        st.sidebar.error(f"–ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

# ================== OPS -> DF ==================
def _service_bucket(name: str) -> str:
    n = (name or "").lower()

    # ‚úÖ –û–ø–ª–∞—Ç–∞ –∑–∞ –∑–∞–∫–∞–∑ (CPA) ‚Äî –í–†–ï–ú–ï–ù–ù–û –ò–°–ö–õ–Æ–ß–ê–ï–ú –∏–∑ "–†–∞—Å—Ö–æ–¥—ã Ozon"
    # (–ø–æ—Ç–æ–º –≤—ã–≤–µ–¥–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ)
    if ("–æ–ø–ª–∞—Ç–∞" in n and "–∑–∞–∫–∞–∑" in n) or ("pay" in n and "order" in n) or ("cpa" in n):
        return "ads_order"

    # –ë–∞–ª–ª—ã –∑–∞ —Å–∫–∏–¥–∫–∏
    if ("–±–∞–ª–ª" in n and "—Å–∫–∏–¥" in n) or ("bonus" in n and "discount" in n):
        return "bonus"

    # –ü—Ä–æ–≥—Ä–∞–º–º—ã –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤
    if ("–ø–∞—Ä—Ç–Ω" in n) or ("partner" in n):
        return "partner"

    return "other"


def extract_services_breakdown_from_ops(
    ops: list[dict],
    exclude_names: tuple[str, ...] = ("—ç–∫–≤–∞–π—Ä–∏–Ω–≥", "acquiring"),
) -> pd.DataFrame:
    """
    DEBUG: –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ—Ç –≤—Å–µ services –∏–∑ —Å—ã—Ä—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π finance (ops list).
    exclude_names ‚Äî –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ (lower), –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ services
    (–Ω–∞–ø—Ä–∏–º–µ—Ä, —ç–∫–≤–∞–π—Ä–∏–Ω–≥, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –¥–≤–æ–π–Ω–æ–≥–æ —É—á–µ—Ç–∞).
    """
    rows = []
    for op in (ops or []):
        op_id = op.get("operation_id")
        op_type_name = op.get("operation_type_name", "") or op.get("operation_type", "")
        op_date = op.get("operation_date", "")
        posting = op.get("posting") or {}
        posting_number = posting.get("posting_number", "")
        delivery_schema = posting.get("delivery_schema", "")

        services = op.get("services") or []
        for s in services:
            name = s.get("name") or s.get("service_name") or s.get("title") or ""
            name_l = str(name).lower()

            # ‚ùå –∏—Å–∫–ª—é—á–∞–µ–º —ç–∫–≤–∞–π—Ä–∏–Ω–≥ –∏–∑ services (–æ–Ω –¥–æ–ª–∂–µ–Ω —Å—á–∏—Ç–∞—Ç—å—Å—è –ø–æ amount/operation_type_name)
            if exclude_names and any(x in name_l for x in exclude_names):
                continue

            price = _to_float(s.get("price", 0))
            rows.append({
                "operation_id": op_id,
                "operation_date": op_date,
                "type_name": op_type_name,
                "posting_number": posting_number,
                "delivery_schema": delivery_schema,
                "service_name": str(name),
                "price": float(price),
                "cost": float(max(-price, 0.0)),  # —Ä–∞—Å—Ö–æ–¥—ã –∫–∞–∫ +—á–∏—Å–ª–æ
                "is_acquiring": ("—ç–∫–≤–∞–π—Ä–∏–Ω–≥" in name_l) or ("acquiring" in name_l),
            })

    df = pd.DataFrame(rows)
    if not df.empty:
        # —É–¥–æ–±–Ω–æ —Å—Ä–∞–∑—É –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
        df["cost"] = pd.to_numeric(df["cost"], errors="coerce").fillna(0.0)
        df["price"] = pd.to_numeric(df["price"], errors="coerce").fillna(0.0)
    return df

def ops_to_df(ops: list[dict]) -> pd.DataFrame:
    rows = []
    for op in ops:
        op_id = op.get("operation_id")
        op_group = op.get("type", "")
        op_code = op.get("operation_type", "")
        op_type_name = op.get("operation_type_name", "") or op_code
        op_date = op.get("operation_date", "")

        accruals_total = _to_float(op.get("accruals_for_sale", 0))
        commission_total = _to_float(op.get("sale_commission", 0))
        amount_total = _to_float(op.get("amount", 0))
        
        # –≠–∫–≤–∞–π—Ä–∏–Ω–≥ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è (–∏–∑ amount)
        is_acq_op = ("—ç–∫–≤–∞–π—Ä–∏–Ω–≥" in str(op_type_name).lower()) or ("acquiring" in str(op_type_name).lower())
        acquiring_total = amount_total if is_acq_op else 0.0


        posting = op.get("posting") or {}
        posting_number = posting.get("posting_number", "")
        delivery_schema = posting.get("delivery_schema", "")

        items = op.get("items") or []
        services = op.get("services") or []        # --- —É—Å–ª—É–≥–∏: –æ–±—â–∏–π + —Ä–∞–∑—Ä–µ–∑ –Ω–∞ "–±–∞–ª–ª—ã/–ø–∞—Ä—Ç–Ω–µ—Ä–∫–∏/–ø—Ä–æ—á–µ–µ"
        services_total = 0.0
        bonus_sum = 0.0
        partner_sum = 0.0
        
        acquiring_services_sum = 0.0
        ads_order_sum = 0.0

        for s in services:
            sname = (s.get("name") or s.get("service_name") or s.get("title") or "").lower()

            # ‚ùå —ç–∫–≤–∞–π—Ä–∏–Ω–≥ –Ω–µ –¥–æ–ª–∂–µ–Ω –ø–æ–ø–∞–¥–∞—Ç—å –≤ services
            if "—ç–∫–≤–∞–π—Ä–∏–Ω–≥" in sname or "acquiring" in sname:
                continue

            price = _to_float(s.get("price", 0))
            services_total += price
            sname = s.get("name") or s.get("service_name") or s.get("title") or ""
            sname_l = str(sname).lower()

            # –≠–∫–≤–∞–π—Ä–∏–Ω–≥ –±–µ—Ä—ë–º –∏–∑ services (–∫–∞–∫ –≤ –õ–ö), –Ω–æ –∏—Å–∫–ª—é—á–∞–µ–º –∏–∑ services_sum
            if ("—ç–∫–≤–∞–π—Ä–∏–Ω–≥" in sname_l) or ("acquiring" in sname_l):
                acquiring_services_sum += price
                continue

            b = _service_bucket(str(sname))
            if b == "bonus":
                bonus_sum += price
            elif b == "partner":
                partner_sum += price
            elif b == "ads_order":
                # –í–ê–ñ–ù–û: –≤—Ä–µ–º–µ–Ω–Ω–æ –∏—Å–∫–ª—é—á–∞–µ–º –∏–∑ —Ä–∞—Å—Ö–æ–¥–æ–≤ Ozon (–æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–∫–∞ –Ω–µ –≤—ã–≤–æ–¥–∏–º)
                ads_order_sum += price

        services_other = services_total - bonus_sum - partner_sum - ads_order_sum
        base = {
            "operation_id": op_id,
            "operation_date": op_date,
            "type": op_group,
            "operation_type": op_code,
            "type_name": op_type_name,
            "posting_number": posting_number,
            "delivery_schema": delivery_schema,
        }

        if not items:
            # items –ø—É—Å—Ç–æ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É, –ø–æ—Ç–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–º –ø–æ SKU –ø–æ posting_number
            rows.append({
                **base,
                "sku": None,
                "name": None,
                "qty": 0.0,
                "accruals_for_sale": accruals_total,
                "sale_commission": commission_total,
                "services_sum": services_other,
                "acquiring_service": acquiring_services_sum,
                "acquiring_amount": acquiring_total,
                "bonus_points": bonus_sum,
                "partner_programs": partner_sum,
                "amount": amount_total,
            })
            continue

        qtys = [max(_to_float(it.get("quantity", 1)), 0.0) for it in items]
        total_qty = sum(qtys) if qtys else 0.0
        if total_qty <= 0:
            total_qty = float(len(items))
            qtys = [1.0] * len(items)

        for it, q in zip(items, qtys):
            w = q / total_qty if total_qty else 0.0
            rows.append({
                **base,
                "sku": it.get("sku"),
                "name": it.get("name"),
                "qty": q,
                "accruals_for_sale": accruals_total * w,
                "sale_commission": commission_total * w,
                "services_sum": services_other * w,
                "acquiring_service": acquiring_services_sum * w,
                "acquiring_amount": acquiring_total * w,
                "bonus_points": bonus_sum * w,
                "partner_programs": partner_sum * w,
                "amount": amount_total * w,
            })

    df = pd.DataFrame(rows)
    for c in ["accruals_for_sale", "sale_commission", "services_sum", "acquiring_service", "bonus_points", "partner_programs", "amount", "qty"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
    return df


def redistribute_ops_without_items(df_ops: pd.DataFrame) -> pd.DataFrame:
    """
    –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ sku=None (items –ø—É—Å—Ç—ã–µ), –ø–æ SKU –≤–Ω—É—Ç—Ä–∏ —Ç–æ–≥–æ –∂–µ posting_number,
    –∏—Å–ø–æ–ª—å–∑—É—è –≤–µ—Å–∞ –ø–æ qty –∏–∑ —Å—Ç—Ä–æ–∫ —ç—Ç–æ–≥–æ –∂–µ posting_number, –≥–¥–µ sku —É–∂–µ –∏–∑–≤–µ—Å—Ç–µ–Ω.
    –°—É–º–º—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è 1-–≤-1, –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Å—Ç–∞—é—Ç –≤–∏—Å–µ—Ç—å –≤ "sku=None".
    """
    if df_ops is None or df_ops.empty:
        return df_ops

    df = df_ops.copy()

    need = df["sku"].isna() & df["posting_number"].astype(str).str.strip().ne("")
    if not need.any():
        return df

    has = df["sku"].notna() & df["posting_number"].astype(str).str.strip().ne("")
    if not has.any():
        return df

    # –≤–µ—Å–∞ –ø–æ qty –≤–Ω—É—Ç—Ä–∏ posting_number –∏ sku
    wbase = (
        df.loc[has, ["posting_number", "sku", "name", "qty"]]
        .copy()
    )
    wbase["sku"] = pd.to_numeric(wbase["sku"], errors="coerce")
    wbase = wbase.dropna(subset=["sku"])
    if wbase.empty:
        return df

    wbase["qty"] = pd.to_numeric(wbase["qty"], errors="coerce").fillna(0.0).clip(lower=0.0)
    w = (
        wbase.groupby(["posting_number", "sku"], as_index=False)
        .agg(w_qty=("qty", "sum"), name=("name", "first"))
    )
    # –Ω–æ—Ä–º–∏—Ä—É–µ–º –≤–µ—Å–∞ –≤–Ω—É—Ç—Ä–∏ posting_number
    w["w_sum"] = w.groupby("posting_number")["w_qty"].transform("sum")
    w = w[w["w_sum"] > 0].copy()
    if w.empty:
        return df
    w["weight"] = w["w_qty"] / w["w_sum"]

    # —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ items
    miss = df.loc[need].copy()
    keep = df.loc[~need].copy()

    out_rows = [keep]

    # —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º miss –ø–æ sku –∏–∑ w
    for _, r in miss.iterrows():
        pn = str(r.get("posting_number", "")).strip()
        ww = w[w["posting_number"] == pn]
        if ww.empty:
            # –Ω–µ –Ω–∞—à–ª–∏ –∫—É–¥–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –±—ã–ª–æ
            out_rows.append(pd.DataFrame([r]))
            continue

        for _, wr in ww.iterrows():
            k = float(wr["weight"])
            newr = r.copy()
            newr["sku"] = int(wr["sku"])
            if pd.isna(newr.get("name")) or str(newr.get("name")).strip() == "":
                newr["name"] = wr.get("name")

            # qty: –µ—Å–ª–∏ —ç—Ç–æ orders/returns ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º qty –∫–∞–∫ w_qty
            # (–µ—Å–ª–∏ qty –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ = 0, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ ‚Äî –±–µ—Ä–µ–º w_qty)
            if str(newr.get("type")) in ("orders", "returns"):
                newr["qty"] = float(wr["w_qty"])

            # —Å—É–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –≤–µ—Å—É
            for c in ["accruals_for_sale", "sale_commission", "services_sum", "acquiring_service", "bonus_points", "partner_programs", "amount"]:
                newr[c] = _to_float(newr.get(c, 0)) * k

            out_rows.append(pd.DataFrame([newr]))

    out = pd.concat(out_rows, ignore_index=True)

    # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —á–∏—Å—Ç–∫–∞ —Ç–∏–ø–æ–≤
    for c in ["accruals_for_sale", "sale_commission", "services_sum", "bonus_points", "partner_programs", "amount", "qty"]:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0.0)

    return out


# ================== MONTH-SAFE CHUNK LOADER ==================
def month_safe_chunks(d_from: date, d_to: date):
    cur = d_from
    while cur <= d_to:
        if cur.month == 12:
            next_month_start = date(cur.year + 1, 1, 1)
        else:
            next_month_start = date(cur.year, cur.month + 1, 1)
        month_end = next_month_start - timedelta(days=1)
        chunk_to = min(month_end, d_to)
        yield cur, chunk_to
        cur = chunk_to + timedelta(days=1)

@st.cache_data(ttl=600)
def load_ops_range(date_from_str: str, date_to_str: str) -> tuple[list[dict], str, str]:
    d1 = datetime.strptime(date_from_str, "%Y-%m-%d").date()
    d2 = datetime.strptime(date_to_str, "%Y-%m-%d").date()

    ops_all = []
    try:
        for a, b in month_safe_chunks(d1, d2):
            ops_part = client.fetch_finance_transactions(a.strftime("%Y-%m-%d"), b.strftime("%Y-%m-%d"))
            ops_all.extend(ops_part)
        return ops_all, "", ""
    except Exception as e:
        title, details = _humanize_ozon_error(e)
        return [], title, details


def _merge_analytics_chunks(chunks: list[list[dict]]) -> pd.DataFrame:
    # Sum units per SKU across chunks
    if not chunks:
        return pd.DataFrame()
    rows = []
    for part in chunks:
        if part:
            rows.extend(part)
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    if df.empty or "sku" not in df.columns:
        return pd.DataFrame()
    for c in ["ordered_units", "delivered_units", "returned_units", "cancelled_units"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
        else:
            df[c] = 0.0
    return df.groupby("sku", as_index=False)[["ordered_units","delivered_units","returned_units","cancelled_units"]].sum()


@st.cache_data(ttl=3600)
def load_analytics_range(date_from_str: str, date_to_str: str) -> tuple[pd.DataFrame, str, str]:
    d1 = datetime.strptime(date_from_str, "%Y-%m-%d").date()
    d2 = datetime.strptime(date_to_str, "%Y-%m-%d").date()

    parts = []
    try:
        for a, b in month_safe_chunks(d1, d2):
            # Analytics API expects YYYY-MM-DD (no Z). We keep it consistent with UI.
            part = client.fetch_analytics_sku_units(a.strftime("%Y-%m-%d"), b.strftime("%Y-%m-%d"))
            parts.append(part)
        df = _merge_analytics_chunks(parts)
        return df, "", ""
    except Exception as e:
        title, details = _humanize_ozon_error(e)
        return pd.DataFrame(), title, details
@st.cache_data(ttl=600)
def load_ads_summary(date_from_str: str, date_to_str: str) -> dict:
    base = {"spent": 0.0, "revenue": 0.0, "orders": 0, "drr": 0.0, "cpc": 0.0, "ctr": 0.0, "_note": "", "_debug": {}}

    if perf_client is None:
        base["_note"] = "Performance: PERF_CLIENT_ID / PERF_CLIENT_SECRET –Ω–µ –∑–∞–¥–∞–Ω—ã."
        return base

    metrics, note, dbg = perf_client.fetch_shop_summary(date_from_str, date_to_str)
    out = {**metrics, "_note": note, "_debug": dbg}
    return out




@st.cache_data(ttl=600)
def load_ads_spend_by_article(date_from_str: str, date_to_str: str) -> dict:
    """
    –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–ª–∞–º–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø–æ –ê—Ä—Ç–∏–∫—É–ª—É –∑–∞ –ø–µ—Ä–∏–æ–¥.

    –ò—Å—Ç–æ—á–Ω–∏–∫:
      - GET /api/client/statistics/daily (CSV): —Ä–∞—Å—Ö–æ–¥—ã –ø–æ –∫–∞–º–ø–∞–Ω–∏—è–º –∏ –¥–Ω—è–º
      - GET /api/client/campaign/{campaign_id}/objects (JSON): —Å–ø–∏—Å–æ–∫ SKU –≤ –∫–∞–º–ø–∞–Ω–∏–∏

    –ú–∞–ø–ø–∏–Ω–≥ SKU -> –ê—Ä—Ç–∏–∫—É–ª –±–µ—Ä—ë–º –∏–∑ COGS (load_cogs()).
    –ù–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π –æ—Å—Ç–∞—Ç–æ–∫ –¥–æ–±–∏–≤–∞–µ–º –≤ __OTHER_ADS__ —Ç–∞–∫, —á—Ç–æ–±—ã –¥–Ω–µ–≤–Ω—ã–µ —Å—É–º–º—ã –∏ –∏—Ç–æ–≥ —Å–æ–≤–ø–∞–ª–∏ —Å –∫–∞–±–∏–Ω–µ—Ç–æ–º.

    –ü–æ–≤–µ–¥–µ–Ω–∏–µ "cloud-safe":
      - –Ω–µ –ø–∞–¥–∞–µ–º –ø–æ HTTPError
      - –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ—Ç—Ä–∞–∏ –∏ –æ–±—â–µ–µ –≤—Ä–µ–º—è –Ω–∞ 1 –∫–∞–º–ø–∞–Ω–∏—é
      - –µ—Å–ª–∏ –∫–∞–º–ø–∞–Ω–∏—é –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å (429/5xx/—Ç–∞–π–º–∞—É—Ç) ‚Äî –µ—ë —Ä–∞—Å—Ö–æ–¥ –ø–æ–ø–∞–¥—ë—Ç –≤ __OTHER_ADS__
    """

    out = {"by_article": {}, "total": 0.0, "other": 0.0, "note": "", "debug": {}}

    perf_id = _get_setting("PERF_CLIENT_ID", "").strip()
    perf_secret = _get_setting("PERF_CLIENT_SECRET", "").strip()
    if not perf_id or not perf_secret:
        out["note"] = "Performance: PERF_CLIENT_ID / PERF_CLIENT_SECRET –Ω–µ –∑–∞–¥–∞–Ω—ã ‚Äî —Ä–µ–∫–ª–∞–º–∞ –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."
        return out

    BASE = "https://api-performance.ozon.ru/api/client"

    # --- –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π (–≤–∞–∂–Ω–æ –¥–ª—è Streamlit Cloud) ---
    OBJ_MAX_RETRIES = 6          # –º–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ objects –æ–¥–Ω–æ–π –∫–∞–º–ø–∞–Ω–∏–∏
    OBJ_TIMEOUT_SEC = 20         # timeout –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ objects
    OBJ_TOTAL_BUDGET_SEC = 60    # –º–∞–∫—Å–∏–º—É–º –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–¥–Ω—É –∫–∞–º–ø–∞–Ω–∏—é (–≤ —Å—É–º–º–µ –ø–æ —Ä–µ—Ç—Ä–∞—è–º)
    DAILY_TIMEOUT_SEC = 120      # daily –æ–±—ã—á–Ω–æ –∫—Ä—É–ø–Ω—ã–π
    SLEEP_BETWEEN_CALLS = 0.15   # —á—É—Ç—å —Ä–∞–∑–≥—Ä—É–∂–∞–µ–º API
    RETRY_429_BASE_SLEEP = 2.0   # –±–∞–∑–æ–≤–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ 429 (–±—É–¥–µ—Ç —Ä–∞—Å—Ç–∏)

    def _get_token() -> str:
        r = requests.post(
            f"{BASE}/token",
            json={
                "client_id": int(perf_id) if perf_id.isdigit() else perf_id,
                "client_secret": perf_secret,
                "grant_type": "client_credentials",
            },
            timeout=30,
        )
        r.raise_for_status()
        data = r.json()
        token = data.get("access_token")
        if not token:
            raise RuntimeError(f"–ù–µ –ø–æ–ª—É—á–∏–ª access_token: {data}")
        return token

    def _headers(token: str) -> dict:
        return {
            "Authorization": f"Bearer {token}",
            "Accept": "*/*",
            "User-Agent": "ozon-ads-dashboard/1.0",
        }

    def _parse_ru_money(s: str) -> float:
        s = (s or "").strip().replace("\ufeff", "").replace("\xa0", "").replace(" ", "").replace(",", ".")
        try:
            return float(s)
        except Exception:
            return 0.0

    def _parse_daily(csv_text: str) -> list[dict]:
        import csv as _csv

        rows = []
        lines = (csv_text or "").splitlines()
        if not lines:
            return rows
        if lines[0].startswith("\ufeff"):
            lines[0] = lines[0].replace("\ufeff", "")

        reader = _csv.DictReader(lines, delimiter=";")
        for r in reader:
            cid = str((r.get("ID") or "")).strip()
            d = str((r.get("–î–∞—Ç–∞") or "")).strip()[:10]
            spend = _parse_ru_money(str(r.get("–†–∞—Å—Ö–æ–¥, ‚ÇΩ") or r.get("–†–∞—Å—Ö–æ–¥") or "0"))
            if not cid or not d:
                continue
            if spend == 0:
                continue
            rows.append({"campaign_id": cid, "date": d, "spend": float(spend)})
        return rows

    def _get_campaign_objects_cloudsafe(token: str, campaign_id: str) -> tuple[list[str], str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (skus, status):
          status:
            - "ok"
            - "rate_limited" (429)
            - "http_error:<code>"
            - "timeout"
            - "bad_json"
            - "unknown_error"
            - "budget_exceeded"
        """
        url = f"{BASE}/campaign/{campaign_id}/objects"
        t0 = time.time()
        last_status = "unknown_error"

        for attempt in range(1, OBJ_MAX_RETRIES + 1):
            # –±—é–¥–∂–µ—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∫–∞–º–ø–∞–Ω–∏—é
            if (time.time() - t0) > OBJ_TOTAL_BUDGET_SEC:
                return [], "budget_exceeded"

            try:
                r = requests.get(url, headers=_headers(token), timeout=OBJ_TIMEOUT_SEC)

                if r.status_code == 429:
                    # backoff
                    last_status = "rate_limited"
                    sleep_s = RETRY_429_BASE_SLEEP * (attempt ** 1.3)
                    time.sleep(min(sleep_s, 15.0))
                    continue

                if r.status_code >= 300:
                    last_status = f"http_error:{r.status_code}"
                    # –Ω–∞ 5xx –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â—ë —Ä–∞–∑, –Ω–∞ 4xx (–∫—Ä–æ–º–µ 429) –æ–±—ã—á–Ω–æ —Å–º—ã—Å–ª–∞ –Ω–µ—Ç
                    if 500 <= r.status_code <= 599:
                        time.sleep(1.0 + attempt * 0.5)
                        continue
                    return [], last_status

                try:
                    data = r.json()
                except Exception:
                    return [], "bad_json"

                skus = []
                if isinstance(data, dict) and isinstance(data.get("list"), list):
                    for item in data["list"]:
                        if isinstance(item, dict) and "id" in item:
                            skus.append(str(item["id"]).strip())

                skus = [s for s in skus if s]
                return skus, "ok"

            except requests.exceptions.Timeout:
                last_status = "timeout"
                time.sleep(0.8 + attempt * 0.4)
                continue
            except Exception:
                last_status = "unknown_error"
                time.sleep(0.8 + attempt * 0.4)
                continue

        return [], last_status

    # --- SKU -> ARTICLE –∏–∑ COGS ---
    sku2art = {}
    try:
        cogs_local = load_cogs()
        if cogs_local is not None and not cogs_local.empty:
            tmp = cogs_local[["sku", "article"]].copy()
            tmp["sku"] = pd.to_numeric(tmp["sku"], errors="coerce").astype("Int64")
            tmp = tmp.dropna(subset=["sku"]).copy()
            tmp["sku"] = tmp["sku"].astype(int).astype(str)
            tmp["article"] = tmp["article"].fillna("").astype(str).str.strip()
            sku2art = {r["sku"]: r["article"] for _, r in tmp.iterrows() if r["sku"] and r["article"]}
    except Exception:
        sku2art = {}

    # --- —Ç–æ–∫–µ–Ω + daily ---
    try:
        token = _get_token()
    except Exception as e:
        out["note"] = f"Performance token error: {e}"
        return out

    try:
        r = requests.get(
            f"{BASE}/statistics/daily",
            headers=_headers(token),
            params={"dateFrom": date_from_str, "dateTo": date_to_str},
            timeout=DAILY_TIMEOUT_SEC,
        )
        if r.status_code >= 300:
            out["note"] = f"Performance daily error: {r.status_code}"
            out["debug"] = {"daily_status": r.status_code, "daily_text_head": (r.text or "")[:400]}
            return out
        daily_rows = _parse_daily(r.text)
    except Exception as e:
        out["note"] = f"Performance daily request failed: {e}"
        return out

    # --- TOTAL –ø–æ –¥–Ω—è–º (–∫–∞–∫ –≤ –∫–∞–±–∏–Ω–µ—Ç–µ) ---
    total_by_day: dict[str, float] = {}
    for row in daily_rows:
        d = row["date"]
        total_by_day[d] = total_by_day.get(d, 0.0) + float(row["spend"])

    # --- —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ---
    camp2skus: dict[str, list[str]] = {}
    camp2status: dict[str, str] = {}
    agg: dict[tuple[str, str], float] = {}   # (date, article) -> spend

    # —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ "–ø–æ—á–µ–º—É —É—à–ª–æ –≤ OTHER"
    skipped_campaigns = 0
    failed_campaigns = 0
    empty_objects_campaigns = 0
    no_mapping_campaigns = 0

    for row in daily_rows:
        cid = row["campaign_id"]
        d = row["date"]
        spend = float(row["spend"])

        if cid not in camp2skus:
            skus, status = _get_campaign_objects_cloudsafe(token, cid)
            camp2skus[cid] = skus
            camp2status[cid] = status
            time.sleep(SLEEP_BETWEEN_CALLS)

        skus = camp2skus.get(cid) or []
        status = camp2status.get(cid, "unknown_error")

        if status != "ok":
            # –Ω–µ —Å–º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å objects -> –ø—É—Å—Ç—å —Ä–∞—Å—Ö–æ–¥ —É—Ö–æ–¥–∏—Ç –≤ OTHER (—á–µ—Ä–µ–∑ diff –Ω–∏–∂–µ)
            failed_campaigns += 1
            continue

        if not skus:
            empty_objects_campaigns += 1
            continue

        # –∞—Ä—Ç–∏–∫—É–ª—ã –ø–æ sku
        arts = []
        for sku in skus:
            art = sku2art.get(str(sku))
            if art:
                arts.append(art)

        if not arts:
            no_mapping_campaigns += 1
            continue

        part = spend / len(arts)
        for art in arts:
            key = (d, art)
            agg[key] = agg.get(key, 0.0) + part

    # --- —Å–∫–æ–ª—å–∫–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –ø–æ –¥–Ω—è–º ---
    alloc_by_day: dict[str, float] = {}
    for (d, _a), v in agg.items():
        alloc_by_day[d] = alloc_by_day.get(d, 0.0) + float(v)

    # --- –¥–æ–±–∏–≤–∞–µ–º OTHER, —á—Ç–æ–±—ã –¥–Ω–µ–≤–Ω—ã–µ —Å—É–º–º—ã —Å–æ–≤–ø–∞–ª–∏ ---
    for d, total in total_by_day.items():
        alloc = alloc_by_day.get(d, 0.0)
        diff = float(total) - float(alloc)
        if abs(diff) >= 0.01:
            key = (d, "__OTHER_ADS__")
            agg[key] = agg.get(key, 0.0) + diff

    # --- –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –∑–∞ –ø–µ—Ä–∏–æ–¥ ---
    by_article: dict[str, float] = {}
    for (_d, art), v in agg.items():
        by_article[art] = by_article.get(art, 0.0) + float(v)

    total = float(sum(by_article.values()))
    other = float(by_article.get("__OTHER_ADS__", 0.0))

    out["by_article"] = by_article
    out["total"] = total
    out["other"] = other

    # note (–∫–æ—Ä–æ—Ç–∫–æ)
    notes = []
    if failed_campaigns:
        notes.append(f"‚ö†Ô∏è –ö–∞–º–ø–∞–Ω–∏–π —Å –æ—à–∏–±–∫–∞–º–∏ objects: {failed_campaigns} (–∏—Ö —Ä–∞—Å—Ö–æ–¥ —É—à—ë–ª –≤ __OTHER_ADS__).")
    if no_mapping_campaigns:
        notes.append(f"‚ö†Ô∏è –ö–∞–º–ø–∞–Ω–∏–π –±–µ–∑ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è SKU‚Üí–ê—Ä—Ç–∏–∫—É–ª: {no_mapping_campaigns} (—É—à–ª–æ –≤ __OTHER_ADS__).")
    out["note"] = " ".join(notes)

    out["debug"] = {
        "period": f"{date_from_str}..{date_to_str}",
        "daily_rows_with_spend": int(len(daily_rows)),
        "campaigns_cached": int(len(camp2skus)),
        "sku2art_size": int(len(sku2art)),
        "failed_objects_campaigns": int(failed_campaigns),
        "empty_objects_campaigns": int(empty_objects_campaigns),
        "no_mapping_campaigns": int(no_mapping_campaigns),
        "other_total": round(other, 2),
        "total_allocated": round(total, 2),
        "status_sample": dict(list(camp2status.items())[:15]),
    }
    return out

def allocate_ads_by_article(sku_table: pd.DataFrame, ads_by_article: dict) -> pd.DataFrame:
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∫–ª–∞–º—É –ø–æ SKU-—Å—Ç—Ä–æ–∫–∞–º, –Ω–æ —Ç–∞–∫, —á—Ç–æ–±—ã —Å—É–º–º–∞ –ø–æ –æ–¥–Ω–æ–º—É –∞—Ä—Ç–∏–∫—É–ª—É —Å–æ—Ö—Ä–∞–Ω—è–ª–∞—Å—å.

    ads_by_article: dict {article: spend_total_for_period}
    """
    out = sku_table.copy()
    if out is None or out.empty:
        out["ads_total"] = 0.0
        return out

    if "article" not in out.columns:
        out["article"] = ""
    out["article"] = out["article"].fillna("").astype(str).str.strip()

    # –±–∞–∑–∞ –¥–ª—è –¥–æ–ª–µ–π –≤–Ω—É—Ç—Ä–∏ –∞—Ä—Ç–∏–∫—É–ª–∞: –≤—ã—Ä—É—á–∫–∞ SKU
    base = pd.to_numeric(out.get("accruals_net", 0.0), errors="coerce").fillna(0.0)
    out["_ads_base"] = base

    out["ads_total"] = 0.0

    # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞
    for art, spend in (ads_by_article or {}).items():
        spend = float(spend or 0.0)
        if spend == 0:
            continue

        mask = out["article"].eq(str(art))
        if not mask.any():
            continue

        s = out.loc[mask, "_ads_base"]
        denom = float(s.sum())
        if denom > 0:
            out.loc[mask, "ads_total"] = spend * (s / denom)
        else:
            # –µ—Å–ª–∏ –≤—ã—Ä—É—á–∫–∏ –Ω–µ—Ç ‚Äî –¥–µ–ª–∏–º –ø–æ—Ä–æ–≤–Ω—É
            n = int(mask.sum())
            out.loc[mask, "ads_total"] = spend / max(n, 1)

    # –û—Å—Ç–∞—Ç–æ–∫ OTHER –Ω–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ SKU (—á—Ç–æ–±—ã –Ω–µ –∏—Å–∫–∞–∂–∞—Ç—å —Ç–æ–≤–∞—Ä—ã),
    # –Ω–æ –æ–Ω –±—É–¥–µ—Ç —É—á—Ç—ë–Ω –≤ –ø–ª–∏—Ç–∫–µ "–†–∞—Å—Ö–æ–¥ –Ω–∞ —Ä–µ–∫–ª–∞–º—É" (total –≤–∫–ª—é—á–∞–µ—Ç OTHER).
    out = out.drop(columns=["_ads_base"], errors="ignore")
    return out


# ================== SOLD SKU TABLE ==================
def build_sold_sku_table(df_ops: pd.DataFrame, cogs_df_local: pd.DataFrame, analytics_units=None) -> pd.DataFrame:
    # –≠–∫–≤–∞–π—Ä–∏–Ω–≥: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º acquiring_amount –ø–æ SKU –Ω–∞ —É—Ä–æ–≤–Ω–µ posting_number (–¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ sku)
    df_ops = allocate_acquiring_amount_by_posting(df_ops)

    sku_df = df_ops[df_ops["sku"].notna()].copy()
    if sku_df.empty:
        return pd.DataFrame()

    sku_df["sku"] = pd.to_numeric(sku_df["sku"], errors="coerce").astype("Int64")
    sku_df = sku_df.dropna(subset=["sku"]).copy()
    sku_df["sku"] = sku_df["sku"].astype(int)

    # —Ä–∞—Å—Ö–æ–¥—ã (–≤ API –æ–±—ã—á–Ω–æ –º–∏–Ω—É—Å–æ–º)
    sku_df["commission_cost"] = (-sku_df["sale_commission"]).clip(lower=0.0)
    sku_df["services_cost"] = (-sku_df["services_sum"]).clip(lower=0.0)
    # –≠–∫–≤–∞–π—Ä–∏–Ω–≥: —Ö—Ä–∞–Ω–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π amount (—Å–æ –∑–Ω–∞–∫–æ–º). –†–∞—Å—Ö–æ–¥ –ø–æ—Å—á–∏—Ç–∞–µ–º –ù–ï–¢–¢–û –Ω–∞ —É—Ä–æ–≤–Ω–µ SKU.
    sku_df["acquiring_amount"] = pd.to_numeric(sku_df.get("acquiring_amount_alloc", 0), errors="coerce").fillna(0.0)

    # ‚Äú–ë–∞–ª–ª—ã –∑–∞ —Å–∫–∏–¥–∫–∏‚Äù –∏ ‚Äú–ü—Ä–æ–≥—Ä–∞–º–º—ã –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤‚Äù (–≤ –õ–ö –∏–¥—É—Ç –ü–õ–Æ–°–û–ú –∫ –≤—ã—Ä—É—á–∫–µ)
    sku_df["bonus_amt"] = pd.to_numeric(sku_df.get("bonus_points", 0), errors="coerce").fillna(0.0)
    sku_df["partner_amt"] = pd.to_numeric(sku_df.get("partner_programs", 0), errors="coerce").fillna(0.0)


    # –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
    # –í–∞–∂–Ω–æ: –≤ finance API –ø–æ–ª–µ `type` –Ω–µ –≤—Å–µ–≥–¥–∞ —Å—Ç—Ä–æ–≥–æ = orders/returns –¥–ª—è –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫,
    # –∫–æ—Ç–æ—Ä—ã–µ –õ–ö –æ—Ç–Ω–æ—Å–∏—Ç –∫ –∑–∞–∫–∞–∑–∞–º/–≤–æ–∑–≤—Ä–∞—Ç–∞–º. –ü–æ—ç—Ç–æ–º—É –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ –∑–Ω–∞–∫—É –≤—ã—Ä—É—á–∫–∏.
    def _qty_kind(row) -> str:
        t = str(row.get("type", "")).lower()
        name = str(row.get("type_name", "")).lower()
        code = str(row.get("operation_type", "")).lower()
        s = f"{t} {name} {code}"

        # –í–æ–∑–≤—Ä–∞—Ç—ã/—Å—Ç–æ—Ä–Ω–æ
        if any(k in s for k in ["–≤–æ–∑–≤—Ä–∞—Ç", "return", "refund", "—Å—Ç–æ—Ä–Ω–æ", "–æ—Ç–º–µ–Ω–∞", "cancell"]):
            return "returns"

        # –ü—Ä–æ–¥–∞–∂–∏/—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è/–¥–æ—Å—Ç–∞–≤–∫–∞ (–≤—ã–∫—É–ø)
        if any(k in s for k in ["–ø—Ä–æ–¥–∞–∂", "—Ä–µ–∞–ª–∏–∑–∞—Ü", "–≤—ã–∫—É–ø", "sale", "delivered", "–¥–æ—Å—Ç–∞–≤", "–ø–µ—Ä–µ–¥–∞–Ω"]):
            return "orders"

        # –§–æ–ª–ª–±–µ–∫ –ø–æ –∑–Ω–∞–∫—É –≤—ã—Ä—É—á–∫–∏
        accr = _to_float(row.get("accruals_for_sale", 0))
        if accr < 0:
            return "returns"
        if accr > 0:
            return "orders"
        return ""

    sku_df["_qty_kind"] = sku_df.apply(_qty_kind, axis=1)
    sku_df["qty_orders"] = sku_df.apply(lambda r: r["qty"] if r["_qty_kind"] == "orders" else 0.0, axis=1)
    sku_df["qty_returns"] = sku_df.apply(lambda r: r["qty"] if r["_qty_kind"] == "returns" else 0.0, axis=1)


    g = (
        sku_df.groupby(["sku"], as_index=False)
        .agg(
            name=("name", "first"),
            qty_orders=("qty_orders", "sum"),
            qty_returns=("qty_returns", "sum"),
            gross_sales=("accruals_for_sale", "sum"),
            amount_net=("amount", "sum"),
            commission=("commission_cost", "sum"),
            logistics=("services_cost", "sum"),
            acquiring_amount=("acquiring_amount", "sum"),
            bonus_points=("bonus_amt", "sum"),
            partner_programs=("partner_amt", "sum"),
        )
    )

    # --- –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞ (Orders / Buyout / Returns) –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –õ–ö.
    # –í–ê–ñ–ù–û: –õ–ö (—é–Ω–∏—Ç-—ç–∫–æ–Ω–æ–º–∏–∫–∞) —Å—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ Analytics, –∞ –Ω–µ –ø–æ Finance.
    # Finance-–æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ "–î–æ—Å—Ç–∞–≤–∫–∞ –ø–æ–∫—É–ø–∞—Ç–µ–ª—é" –º–æ–≥—É—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—è—Ü–µ, –ø–æ—ç—Ç–æ–º—É qty –∏–∑ Finance –±—É–¥–µ—Ç –º–µ–Ω—å—à–µ.
    if analytics_units is not None and not analytics_units.empty and "sku" in analytics_units.columns:
        au = analytics_units.copy()
        au["sku"] = pd.to_numeric(au["sku"], errors="coerce").astype("Int64")
        au = au.dropna(subset=["sku"]).copy()
        au["sku"] = au["sku"].astype(int)

        # normalize columns
        colmap = {
            "ordered_units": "qty_orders_analytics",
            "delivered_units": "qty_delivered_analytics",
            "returned_units": "qty_returns_analytics",
            "cancelled_units": "qty_cancelled_analytics",
        }
        for src, dst in colmap.items():
            if src in au.columns:
                au[dst] = pd.to_numeric(au[src], errors="coerce").fillna(0.0)
            else:
                au[dst] = 0.0

        au = au[["sku"] + list(colmap.values())]
        g = g.merge(au, on="sku", how="left")

        # Keep finance-based qty for debug
        g["qty_orders_finance"] = g["qty_orders"]
        g["qty_returns_finance"] = g["qty_returns"]

        # Override with Analytics (if present)
        g["qty_orders"] = g["qty_orders_analytics"].fillna(0.0)
        g["qty_returns"] = g["qty_returns_analytics"].fillna(0.0)

        # Buyout: prefer delivered_units, else ordered - returned
        delivered = g.get("qty_delivered_analytics")
        if delivered is not None:
            g["qty_buyout"] = delivered.fillna(0.0)
        else:
            g["qty_buyout"] = g["qty_orders"] - g["qty_returns"]
    else:
        g["qty_buyout"] = g["qty_orders"] - g["qty_returns"]

    # –≠–∫–≤–∞–π—Ä–∏–Ω–≥ (–∫–∞–∫ –≤ –õ–ö): N–ï–¢–¢–û –ø–æ amount, –∑–∞—Ç–µ–º –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–∞—Å—Ö–æ–¥ (–ø–ª—é—Å)
    if "acquiring_amount" in g.columns:
        g["acquiring"] = (-pd.to_numeric(g["acquiring_amount"], errors="coerce").fillna(0.0)).clip(lower=0.0)
    else:
        g["acquiring"] = 0.0
    # –í–ê–ñ–ù–û: ‚Äú–í—ã—Ä—É—á–∫–∞‚Äù –∫–∞–∫ –≤ –õ–ö = –í—ã—Ä—É—á–∫–∞ Ozon + –ë–∞–ª–ª—ã –∑–∞ —Å–∫–∏–¥–∫–∏ + –ü—Ä–æ–≥—Ä–∞–º–º—ã –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤
    g["accruals_net"] = g["gross_sales"] + g["bonus_points"] + g["partner_programs"]

    g["sale_costs"] = g["commission"] + g["logistics"] + g["acquiring"]

    # COGS
    if cogs_df_local is None or cogs_df_local.empty:
        g["article"] = ""
        g["cogs_unit"] = 0.0
    else:
        c2 = cogs_df_local.copy()
        c2["sku"] = pd.to_numeric(c2["sku"], errors="coerce").astype("Int64")
        c2 = c2.dropna(subset=["sku"]).copy()
        c2["sku"] = c2["sku"].astype(int)
        if "article" not in c2.columns:
            c2["article"] = ""
        if "cogs" not in c2.columns:
            c2["cogs"] = 0.0
        c2["cogs"] = pd.to_numeric(c2["cogs"], errors="coerce").fillna(0.0)
        c2 = c2[["sku", "article", "cogs"]].drop_duplicates(subset=["sku"], keep="last")
        g = g.merge(c2.rename(columns={"cogs": "cogs_unit"}), how="left", on="sku")
        g["article"] = g["article"].fillna("").astype(str)
        g["cogs_unit"] = pd.to_numeric(g["cogs_unit"], errors="coerce").fillna(0.0)

    # –∞–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –±—ã–ª–æ)
    try:
        known = g[(g["article"].astype(str).str.strip() != "") & g["name"].notna()].copy()
        if not known.empty:
            name_to_article = (
                known.assign(_a=known["article"].astype(str).str.strip())
                .groupby("name")["_a"]
                .agg(lambda s: s.value_counts().index[0])
            )
            mask_empty = g["article"].astype(str).str.strip() == ""
            g.loc[mask_empty, "article"] = (
                g.loc[mask_empty, "name"]
                .map(name_to_article)
                .apply(lambda a: f"–î—É–±–ª—å ({a})" if isinstance(a, str) and a.strip() else "")
            )
    except Exception:
        pass
    g["article"] = g["article"].fillna("").astype(str)

    g["cogs_total"] = (g["qty_buyout"].clip(lower=0.0) * g["cogs_unit"]).fillna(0.0)

    g = g.sort_values("accruals_net", ascending=False)
    return g


def allocate_tax_by_share(sku_table: pd.DataFrame, total_tax: float) -> pd.DataFrame:
    out = sku_table.copy()
    total_sales = out["accruals_net"].sum()
    out["tax_total"] = (out["accruals_net"] / total_sales) * float(total_tax) if total_sales and total_tax else 0.0
    return out

def allocate_cost_by_share(sku_table: pd.DataFrame, total_cost: float, out_col: str) -> pd.DataFrame:
    out = sku_table.copy()
    total_sales = float(out["accruals_net"].sum()) if "accruals_net" in out.columns else 0.0
    if total_sales and total_cost:
        out[out_col] = (out["accruals_net"] / total_sales) * float(total_cost)
    else:
        out[out_col] = 0.0
    return out


def compute_profitability(sku_table: pd.DataFrame) -> pd.DataFrame:
    out = sku_table.copy()

    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏
    for c in ["accruals_net", "sale_costs", "cogs_total", "tax_total", "qty_buyout", "cogs_unit"]:
        if c not in out.columns:
            out[c] = 0.0

    for c in ["ads_total", "opex_total"]:
        if c not in out.columns:
            out[c] = 0.0

    
    # –ø—Ä–∏–±—ã–ª—å:
    # 1) –ü—Ä–∏–±—ã–ª—å (–¥–æ –Ω–∞–ª–æ–≥–∞ –∏ –æ–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥–æ–≤) = –í—ã—Ä—É—á–∫–∞ ‚àí –†–∞—Å—Ö–æ–¥—ã Ozon ‚àí –†–µ–∫–ª–∞–º–∞ (–∫–ª–∏–∫) ‚àí –†–µ–∫–ª–∞–º–∞ (–∑–∞–∫–∞–∑) ‚àí –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ
    # helper: –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É (–µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç ‚Äî –≤–µ—Ä–Ω—ë–º –Ω—É–ª–∏ –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º)
    def _col_num(df: pd.DataFrame, col: str) -> pd.Series:
        if col in df.columns:
            return pd.to_numeric(df[col], errors="coerce").fillna(0.0)
        return pd.Series(0.0, index=df.index)

    # –í–ê–ñ–ù–û: –≤ —Ç–≤–æ—ë–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ —Å–µ–π—á–∞—Å:
    # - "–†–µ–∫–ª–∞–º–∞ (–∫–ª–∏–∫), ‚ÇΩ" –±–µ—Ä—ë—Ç—Å—è –∏–∑ out["ads_total"]
    # - "–†–µ–∫–ª–∞–º–∞ (–∑–∞–∫–∞–∑), ‚ÇΩ" –±–µ—Ä—ë—Ç—Å—è –∏–∑ out["ads_spend_click"]
    ads_click = _col_num(out, "ads_total")
    ads_order = _col_num(out, "ads_spend_click")

    out["profit_before_tax_opex"] = (
        pd.to_numeric(out.get("accruals_net", 0.0), errors="coerce").fillna(0.0)
        - pd.to_numeric(out.get("sale_costs", 0.0), errors="coerce").fillna(0.0)
        - ads_click
        - ads_order
        - pd.to_numeric(out.get("cogs_total", 0.0), errors="coerce").fillna(0.0)
    )

    out["profit_before_tax_opex_per_unit"] = out.apply(
        lambda r: (float(r["profit_before_tax_opex"]) / float(r.get("qty_buyout", 0) or 0))
        if float(r.get("qty_buyout", 0) or 0) > 0 else 0.0,
        axis=1,
    )

    # 2) –ü—Ä–∏–±—ã–ª—å (–ø–æ—Å–ª–µ –Ω–∞–ª–æ–≥–∞ –∏ –æ–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥–æ–≤) ‚Äî –∫–∞–∫ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º –∏ —Ä–µ–∫–ª–∞–º—É (–∑–∞–∫–∞–∑)
    out["profit"] = (
        out["profit_before_tax_opex"]
        - pd.to_numeric(out.get("tax_total", 0.0), errors="coerce").fillna(0.0)
        - pd.to_numeric(out.get("opex_total", 0.0), errors="coerce").fillna(0.0)
    )

    out["profit_per_unit"] = out.apply(
        lambda r: (float(r["profit"]) / float(r.get("qty_buyout", 0) or 0))
        if float(r.get("qty_buyout", 0) or 0) > 0 else 0.0,
        axis=1,
    )

    out["margin_%"] = out.apply(
        lambda r: (float(r["profit"]) / float(r["accruals_net"]) * 100.0) if float(r.get("accruals_net", 0) or 0) else 0.0,
        axis=1,
    )

    # ROI –ø–æ –¢–ó: (–ü—Ä–∏–±—ã–ª—å –Ω–∞ 1 —à—Ç) / (–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç)
    out["roi_%"] = out.apply(
        lambda r: (float(r["profit_per_unit"]) / float(r.get("cogs_unit", 0) or 0) * 100.0) if float(r.get("cogs_unit", 0) or 0) > 0 else 0.0,
        axis=1,
    )

    return out

def export_soldsku_xlsx(df: pd.DataFrame) -> bytes:
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as w:
        df.to_excel(w, index=False, sheet_name="SoldSKU")
    return bio.getvalue()

# ================== TILE LOGIC ==================
def _delta_pct(cur, prev):
    prev = float(prev)
    cur = float(cur)
    if prev == 0:
        return None
    return (cur - prev) / abs(prev) * 100.0

def _tile_class(delta, is_expense: bool, good_when_up: bool = False):
    if delta is None:
        return "ts-neutral", "‚Äî"
    arrow = "‚ñ≤" if delta > 0 else "‚ñº"
    txt = f"{arrow} {delta:+.1f}%"
    if is_expense:
        if good_when_up:
            return ("ts-good" if delta > 0 else "ts-bad"), txt
        return ("ts-good" if delta < 0 else "ts-bad"), txt
    return ("ts-good" if delta > 0 else "ts-bad"), txt

def render_tiles(tiles: list[dict], cols_per_row: int = 4, row_gap_px: int = 16):
    for i in range(0, len(tiles), cols_per_row):
        row = tiles[i:i + cols_per_row]
        cols = st.columns(cols_per_row)
        for c, t in zip(cols, row):
            klass, delta_txt = _tile_class(t.get("delta"), t.get("is_expense", False), t.get("good_when_up", False))
            c.markdown(
                f"""
<div class="ts-tile {klass}">
  <div class="ts-title">{t.get("title","")}</div>
  <div class="ts-value">{t.get("value","")}</div>
  <div class="ts-delta">{delta_txt}</div>
</div>
""",
                unsafe_allow_html=True
            )
        if i + cols_per_row < len(tiles):
            st.markdown(f"<div style='height:{int(row_gap_px)}px'></div>", unsafe_allow_html=True)

# ================== KPI CORE ==================
STORAGE_FBO_TYPE_NAMES = {"–£—Å–ª—É–≥–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ"}

def calc_kpi(df_ops_local: pd.DataFrame, sold_local: pd.DataFrame):
    total_amount = df_ops_local["amount"].sum() if not df_ops_local.empty else 0.0
    sales_net = float(sold_local["accruals_net"].sum()) if sold_local is not None and not sold_local.empty else 0.0

    sum_sale_commission = df_ops_local["sale_commission"].sum() if not df_ops_local.empty else 0.0
    commission_cost = max(0.0, -float(sum_sale_commission))

    over_local = df_ops_local[df_ops_local["sku"].isna()].copy() if not df_ops_local.empty else pd.DataFrame(columns=["type_name", "amount"])
    storage_fbo_raw = 0.0
    if not over_local.empty:
        storage_fbo_raw = over_local[over_local["type_name"].astype(str).isin(STORAGE_FBO_TYPE_NAMES)]["amount"].sum()
    storage_fbo = to_cost(storage_fbo_raw)

    if sold_local is None or sold_local.empty:
        qty_orders = 0
        qty_returns = 0
        buyout_pct = 0.0
        total_tax = 0.0
        total_cogs = 0.0
        sale_costs = 0.0
    else:
        qty_orders = _to_int(sold_local["qty_orders"].sum())
        qty_returns = _to_int(sold_local["qty_returns"].sum())
        buyout_pct = ((qty_orders - qty_returns) / qty_orders * 100.0) if qty_orders else 0.0

        total_tax = float(sales_net) * 0.06

        tmp = allocate_tax_by_share(sold_local, total_tax)
        tmp = compute_profitability(tmp)
        total_cogs = float(tmp["cogs_total"].sum())
        sale_costs = float(sold_local["sale_costs"].sum())

    net_profit = float(total_amount) - float(total_cogs) - float(total_tax)
    profit_pct = (net_profit / sales_net * 100.0) if sales_net else 0.0

    return {
        "sales_net": float(sales_net),
        "qty_orders": int(qty_orders),
        "qty_returns": int(qty_returns),
        "buyout_pct": float(buyout_pct),
        "storage_fbo": float(storage_fbo),
        "sale_costs": float(to_cost(sale_costs)),
        "cogs": float(to_cost(total_cogs)),
        "tax": float(to_cost(total_tax)),
        "commission_cost": float(to_cost(commission_cost)),
        "amount_total": float(total_amount),
        "net_profit": float(net_profit),
        "profit_pct": float(profit_pct),
    }

def month_name_ru(m: int) -> str:
    names = ["", "–Ø–Ω–≤–∞—Ä—å","–§–µ–≤—Ä–∞–ª—å","–ú–∞—Ä—Ç","–ê–ø—Ä–µ–ª—å","–ú–∞–π","–ò—é–Ω—å","–ò—é–ª—å","–ê–≤–≥—É—Å—Ç","–°–µ–Ω—Ç—è–±—Ä—å","–û–∫—Ç—è–±—Ä—å","–ù–æ—è–±—Ä—å","–î–µ–∫–∞–±—Ä—å"]
    return names[m] if 1 <= m <= 12 else str(m)

# ================== UI ==================
tab1, tab2, tab3, tab4 = st.tabs(["–û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏", "–°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º", "AB–°-–∞–Ω–∞–ª–∏–∑", "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã"])

# ================== TAB 1 ==================
with tab1:
    st.subheader("–°–≤–æ–¥–∫–∞ –º–∞–≥–∞–∑–∏–Ω–∞ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")

    today = date.today()
    yesterday = today - timedelta(days=1)

    presets = ["–ü–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π", "–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π"]
    preset = st.selectbox("–ü–µ—Ä–∏–æ–¥", presets, index=2)

    def compute_range_from_preset(p: str):
        if p == "–ü–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å":
            return (yesterday, yesterday)
        if p == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π":
            return (yesterday - timedelta(days=6), yesterday)
        if p == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π":
            return (yesterday - timedelta(days=29), yesterday)
        return (yesterday - timedelta(days=29), yesterday)

    d_from, d_to = compute_range_from_preset(preset)

    if preset == "–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π":
        c1, c2 = st.columns(2)
        with c1:
            d_from = st.date_input("–î–∞—Ç–∞ —Å", value=d_from)
        with c2:
            d_to = st.date_input("–î–∞—Ç–∞ –ø–æ", value=d_to)
    else:
        st.caption(f"–í—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥: {d_from.strftime('%Y-%m-%d')} ‚Äî {d_to.strftime('%Y-%m-%d')}")

    if d_from > d_to:
        st.warning("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –±–æ–ª—å—à–µ –¥–∞—Ç—ã –∫–æ–Ω—Ü–∞ ‚Äî –ø–æ–ø—Ä–∞–≤—å –ø–µ—Ä–∏–æ–¥.")
        st.stop()

    days_len = (d_to - d_from).days + 1
    prev_to = d_from - timedelta(days=1)
    prev_from = prev_to - timedelta(days=days_len - 1)
    st.caption(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥ {prev_from.strftime('%Y-%m-%d')} ‚Äî {prev_to.strftime('%Y-%m-%d')}")

    ops_now, ops_err_title, ops_err_details = load_ops_range(d_from.strftime("%Y-%m-%d"), d_to.strftime("%Y-%m-%d"))
    if ops_err_title:
        _block_with_retry(ops_err_title, ops_err_details, cache_clear_fn=load_ops_range.clear)


    # ================== DEBUG: —Ä–∞–∑–±–æ—Ä –ª–æ–≥–∏—Å—Ç–∏–∫–∏ –ø–æ –æ–¥–Ω–æ–º—É –∞—Ä—Ç–∏–∫—É–ª—É (Polyarnaya-210) ==================
    # ================== DEBUG: –†–ê–ó–ë–û–† –£–°–õ–£–ì (services) –ò–ó –°–´–†–´–• –û–ü–ï–†–ê–¶–ò–ô ==================
    df_ops = ops_to_df(ops_now)
    # –≠–∫–≤–∞–π—Ä–∏–Ω–≥: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ SKU –Ω–∞ –ø–æ–ª–Ω–æ–º df_ops (–ø–æ posting_number)
    df_ops = allocate_acquiring_cost_by_posting(df_ops)
    df_ops = redistribute_ops_without_items(df_ops)  # ‚úÖ –î–û–ë–ê–í–ò–¢–¨

    df_ops_prev = pd.DataFrame(columns=df_ops.columns)
    if prev_from <= prev_to:
        ops_prev, ops_prev_err_title, ops_prev_err_details = load_ops_range(prev_from.strftime("%Y-%m-%d"), prev_to.strftime("%Y-%m-%d"))
        if ops_prev_err_title:
            _block_with_retry(ops_prev_err_title, ops_prev_err_details, cache_clear_fn=load_ops_range.clear)
        df_ops_prev = ops_to_df(ops_prev)
        df_ops_prev = redistribute_ops_without_items(df_ops_prev)  # ‚úÖ –î–û–ë–ê–í–ò–¢–¨

    analytics_df, ana_err_title, ana_err_details = load_analytics_range(
        d_from.strftime("%Y-%m-%d"),
        d_to.strftime("%Y-%m-%d"),
    )
    if ana_err_title:
        st.warning(f"Analytics (qty) –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å: {ana_err_title}")
        with st.expander("Details", expanded=False):
            st.write(ana_err_details)
    sold = build_sold_sku_table(df_ops, cogs_df, analytics_df)

    # --- DEBUG: —Ä–∞–∑—Ä–µ–∑ –æ–ø–µ—Ä–∞—Ü–∏–π –ø–æ –æ–¥–Ω–æ–º—É SKU (–ø–æ–º–æ–≥–∞–µ—Ç –Ω–∞–π—Ç–∏ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Å –õ–ö)
    debug_sku = st.sidebar.text_input(
        "DEBUG SKU (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
        value="",
        help="–í–≤–µ–¥–∏—Ç–µ SKU, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–∞–∑—Ä–µ–∑ –æ–ø–µ—Ä–∞—Ü–∏–π –∏ –ø–æ–Ω—è—Ç—å, –∫–∞–∫–∏–µ —Ç–∏–ø—ã –Ω–µ –ø–æ–ø–∞–ª–∏ –≤ –∑–∞–∫–∞–∑—ã/–≤–æ–∑–≤—Ä–∞—Ç—ã.",
    )
    if str(debug_sku).strip().isdigit():
        _sku = int(str(debug_sku).strip())
        with st.expander(f"DEBUG: –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ SKU {_sku}", expanded=False):
            _ops = df_ops.copy()
            _ops["sku"] = pd.to_numeric(_ops.get("sku"), errors="coerce").astype("Int64")
            _ops = _ops[_ops["sku"] == _sku].copy()
            if _ops.empty:
                st.info("–ü–æ —ç—Ç–æ–º—É SKU –Ω–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ.")
            else:
                # –ö–æ—Ä–æ—Ç–∫–∏–π —Å–≤–æ–¥ –ø–æ —Ç–∏–ø–∞–º
                cols = [
                    "operation_date",
                    "type",
                    "operation_type",
                    "type_name",
                    "posting_number",
                    "qty",
                    "accruals_for_sale",
                    "sale_commission",
                    "services_sum",
                    "acquiring_amount_alloc" if "acquiring_amount_alloc" in _ops.columns else "acquiring_amount",
                    "bonus_points",
                    "partner_programs",
                    "amount",
                ]
                cols = [c for c in cols if c in _ops.columns]
                st.dataframe(_ops[cols].sort_values("operation_date"))

                gb_cols = [c for c in ["type", "operation_type", "type_name"] if c in _ops.columns]
                if gb_cols:
                    agg_map = {c: "sum" for c in ["qty", "accruals_for_sale", "sale_commission", "services_sum", "bonus_points", "partner_programs", "amount"] if c in _ops.columns}
                    gdebug = _ops.groupby(gb_cols, as_index=False).agg(agg_map)
                    st.write("–°–≤–æ–¥ –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π:")
                    st.dataframe(gdebug.sort_values("accruals_for_sale", ascending=False))
    analytics_prev_df, _, _ = load_analytics_range(prev_from.strftime('%Y-%m-%d'), prev_to.strftime('%Y-%m-%d')) if (not df_ops_prev.empty and prev_from <= prev_to) else (pd.DataFrame(), '', '')
    sold_prev = build_sold_sku_table(df_ops_prev, cogs_df, analytics_prev_df) if not df_ops_prev.empty else pd.DataFrame()

    k = calc_kpi(df_ops, sold)
    k_prev = calc_kpi(df_ops_prev, sold_prev)

    ads_now_raw = load_ads_summary(d_from.strftime("%Y-%m-%d"), d_to.strftime("%Y-%m-%d"))
    ads_prev_raw = load_ads_summary(prev_from.strftime("%Y-%m-%d"), prev_to.strftime("%Y-%m-%d"))

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–ª–∞–º–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º (—Ç–æ—á–Ω–µ–µ, —á–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏—è –≤—ã—Ä—É—á–∫–µ)
    ads_alloc_now = load_ads_spend_by_article(d_from.strftime("%Y-%m-%d"), d_to.strftime("%Y-%m-%d"))
    ads_alloc_prev = load_ads_spend_by_article(prev_from.strftime("%Y-%m-%d"), prev_to.strftime("%Y-%m-%d"))

    # –ë–µ—Ä—ë–º —Ä–∞—Å—Ö–æ–¥ –∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (total –≤–∫–ª—é—á–∞–µ—Ç __OTHER_ADS__ –∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å "–∫–∞–∫ –≤ –∫–∞–±–∏–Ω–µ—Ç–µ")
    ads_now = {**ads_now_raw}
    ads_prev = {**ads_prev_raw}
    ads_now["spent"] = float(ads_alloc_now.get("total", 0.0) or 0.0)
    ads_prev["spent"] = float(ads_alloc_prev.get("total", 0.0) or 0.0)

    # ---- ROAS ----
    def calc_roas(ads: dict) -> float:
        spent = float(ads.get("spent", 0) or 0)
        revenue = float(ads.get("revenue", 0) or 0)
        return (revenue / spent) if spent > 0 else 0.0

    roas_now = calc_roas(ads_now)
    roas_prev = calc_roas(ads_prev)


    # ---- OPEX (—Ä—É—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã) ----
    opex_now = opex_sum_period(df_opex, d_from, d_to)
    opex_prev = opex_sum_period(df_opex, prev_from, prev_to)

    # note –æ—Ç Performance –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –Ω–æ –ù–ï –∑–∞–≤—è–∑—ã–≤–∞–µ–º –Ω–∞ –Ω–µ–≥–æ –ª–æ–≥–∏–∫—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    ads_tiles = []

    # note –º–æ–∂–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ
    if ads_now.get("_note"):
        st.info(ads_now["_note"])
    if ads_alloc_now.get("note"):
        st.info(ads_alloc_now["note"])

    # ads_tiles —Ñ–æ—Ä–º–∏—Ä—É–µ–º –í–°–ï–ì–î–ê
    ads_tiles = [
        {"title": "–†–∞—Å—Ö–æ–¥ –Ω–∞ —Ä–µ–∫–ª–∞–º—É", "value": money(ads_now.get("spent", 0.0)),
         "delta": _delta_pct(_to_float(ads_now.get("spent", 0.0)), _to_float(ads_prev.get("spent", 0.0))),
         "is_expense": True},

        {"title": "–í—ã—Ä—É—á–∫–∞ —Å —Ä–µ–∫–ª–∞–º—ã", "value": money(ads_now.get("revenue", 0.0)),
         "delta": _delta_pct(_to_float(ads_now.get("revenue", 0.0)), _to_float(ads_prev.get("revenue", 0.0))),
         "is_expense": False},

        {"title": "–ó–∞–∫–∞–∑—ã —Å —Ä–µ–∫–ª–∞–º—ã", "value": f'{_to_int(ads_now.get("orders", 0))} —à—Ç',
         "delta": _delta_pct(_to_float(ads_now.get("orders", 0)), _to_float(ads_prev.get("orders", 0))),
         "is_expense": False},

        {"title": "DRR", "value": f'{_to_float(ads_now.get("drr", 0.0)):.1f}%',
         "delta": _delta_pct(_to_float(ads_now.get("drr", 0.0)), _to_float(ads_prev.get("drr", 0.0))),
         "is_expense": True},

        {"title": "ROAS", "value": f'x{roas_now:.2f}',
         "delta": _delta_pct(roas_now, roas_prev),
         "is_expense": False},

        {"title": "CPC", "value": f'{_to_float(ads_now.get("cpc", 0.0)):.1f} ‚ÇΩ',
         "delta": _delta_pct(_to_float(ads_now.get("cpc", 0.0)), _to_float(ads_prev.get("cpc", 0.0))),
         "is_expense": True},

        {"title": "CTR", "value": f'{_to_float(ads_now.get("ctr", 0.0)):.2f}%',
         "delta": _delta_pct(_to_float(ads_now.get("ctr", 0.0)), _to_float(ads_prev.get("ctr", 0.0))),
         "is_expense": False},
    ]

    sales_tile_value = (
        f'{money(k["sales_net"])} / {k["qty_orders"]} —à—Ç'
        if k["qty_orders"]
        else money(k["sales_net"])
    )

    # --- –ø–µ—Ä–µ—Å—á—ë—Ç KPI –ø–æ –Ω–æ–≤—ã–º —Ñ–æ—Ä–º—É–ª–∞–º (—É—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∫–ª–∞–º—É + –æ–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã) ---
    ads_spent_now = float(ads_now.get("spent", 0.0) or 0.0)
    ads_spent_prev = float(ads_prev.get("spent", 0.0) or 0.0)

    net_profit_now = float(k["sales_net"]) - float(k["sale_costs"]) - ads_spent_now - float(k["cogs"]) - float(k["tax"]) - float(opex_now)
    net_profit_prev = float(k_prev["sales_net"]) - float(k_prev["sale_costs"]) - ads_spent_prev - float(k_prev["cogs"]) - float(k_prev["tax"]) - float(opex_prev)

    margin_now = (net_profit_now / float(k["sales_net"]) * 100.0) if float(k["sales_net"]) else 0.0
    margin_prev = (net_profit_prev / float(k_prev["sales_net"]) * 100.0) if float(k_prev["sales_net"]) else 0.0

    roi_now = (net_profit_now / float(k["cogs"]) * 100.0) if float(k["cogs"]) else 0.0
    roi_prev = (net_profit_prev / float(k_prev["cogs"]) * 100.0) if float(k_prev["cogs"]) else 0.0

    sales_tile_value = f'{money(k["sales_net"])} / {k["qty_orders"]} —à—Ç' if k["qty_orders"] else money(k["sales_net"])
    commission_delta = _delta_pct(k["commission_cost"], k_prev["commission_cost"])

    tiles = [
        {"title": "–ü—Ä–æ–¥–∞–∂–∏", "value": sales_tile_value, "delta": _delta_pct(k["sales_net"], k_prev["sales_net"]), "is_expense": False},
        {"title": "–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å", "value": money(net_profit_now), "delta": _delta_pct(net_profit_now, net_profit_prev), "is_expense": False},
        {"title": "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å", "value": f"{margin_now:.1f}%", "delta": _delta_pct(margin_now, margin_prev), "is_expense": False},
        {"title": "ROI", "value": f"{roi_now:.1f}%", "delta": _delta_pct(roi_now, roi_prev), "is_expense": False},

        {"title": "% –≤—ã–∫—É–ø–∞", "value": f'{k["buyout_pct"]:.1f}%', "delta": _delta_pct(k["buyout_pct"], k_prev["buyout_pct"]), "is_expense": False},
        {"title": "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç", "value": str(k["qty_returns"]), "delta": _delta_pct(k["qty_returns"], k_prev["qty_returns"]), "is_expense": True},
        {"title": "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã", "value": money(opex_now), "delta": _delta_pct(opex_now, opex_prev), "is_expense": True},
        {"title": "–†–∞—Å—Ö–æ–¥—ã –Ω–∞ –ø—Ä–æ–¥–∞–∂—É", "value": money(k["sale_costs"]), "delta": _delta_pct(k["sale_costs"], k_prev["sale_costs"]), "is_expense": True},

        {"title": "–•—Ä–∞–Ω–µ–Ω–∏–µ (FBO)", "value": money(k["storage_fbo"]), "delta": _delta_pct(k["storage_fbo"], k_prev["storage_fbo"]), "is_expense": True},
        {"title": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂", "value": money(k["cogs"]), "delta": _delta_pct(k["cogs"], k_prev["cogs"]), "is_expense": True, "good_when_up": True},
        {"title": "–ù–∞–ª–æ–≥–∏/–ö–æ–º–∏—Å—Å–∏—è", "value": f'{money(k["tax"])} / {money(k["commission_cost"])}', "delta": commission_delta, "is_expense": True},
    ]

    st.markdown("### –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    render_tiles(tiles, cols_per_row=4)

    st.markdown("### –†–µ–∫–ª–∞–º–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    render_tiles(ads_tiles, cols_per_row=4)

    st.divider()

    over = df_ops[df_ops["sku"].isna()].copy()
    with st.expander("–î–µ—Ç–∞–ª–∏", expanded=False):
        st.markdown("**–î–∞–Ω–Ω—ã–µ –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º**")
        if over.empty:
            st.info("–ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π –±–µ–∑ SKU –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ.")
        else:
            over_g = (
                over.groupby("type_name", as_index=False)
                .agg(amount=("amount", "sum"))
                .sort_values("amount")
            )
            over_g = over_g.rename(columns={"type_name": "–¢–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏", "amount": "–ó–Ω–∞—á–µ–Ω–∏–µ"}).copy()
            # –æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ —á–∏—Å–ª–æ–º ‚Äî —á—Ç–æ–±—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
            over_g["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(over_g["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").fillna(0.0)
            st.dataframe(
                over_g,
                use_container_width=True,
                hide_index=True,
                column_config={"–ó–Ω–∞—á–µ–Ω–∏–µ": st.column_config.NumberColumn(format="%.0f")},
            )

    st.markdown("## –°–ø–∏—Å–æ–∫ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö SKU ")
    if sold is None or sold.empty:
        st.warning("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ—Ç SKU-–æ–ø–µ—Ä–∞—Ü–∏–π (items[].sku).")
    else:
        total_tax = float(sold["accruals_net"].sum()) * 0.06

        # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º: –Ω–∞–ª–æ–≥, —Ä–µ–∫–ª–∞–º–∞, –æ–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã
        sold_view = allocate_tax_by_share(sold, total_tax)

        ads_spent_now = float(ads_now.get("spent", 0.0) or 0.0)
        sold_view = allocate_ads_by_article(sold_view, ads_alloc_now.get("by_article", {}))

        # spend_click –∏–∑ –æ—Ç—á—ë—Ç–∞ Performance (products json): MoneySpentFromCPC –ø–æ SKU
        with st.spinner("Performance API: –∑–∞–≥—Ä—É–∂–∞—é —Ä–µ–∫–ª–∞–º—É (—Ä–∞—Å—Ö–æ–¥—ã –ø–æ SKU)‚Ä¶"):
            try:
                _perf_map_raw = load_perf_spend_click_by_sku(d_from.strftime("%Y-%m-%d"), d_to.strftime("%Y-%m-%d"))
            except Exception:
                _perf_map_raw = {}

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á–∏ SKU (int) –∏ –∑–Ω–∞—á–µ–Ω–∏—è (float), —á—Ç–æ–±—ã –º–∞–ø–ø–∏–Ω–≥ –Ω–µ –¥–∞–≤–∞–ª 0 –∏–∑‚Äë–∑–∞ —Ç–∏–ø–æ–≤
        _perf_map = {}
        try:
            for k, v in (_perf_map_raw or {}).items():
                ks = str(k).strip()
                if ks.endswith(".0"):
                    ks = ks[:-2]
                if ks:
                    _perf_map[int(ks)] = float(v or 0.0)
        except Exception:
            _perf_map = {}

        if not _perf_map:
            st.caption("Performance API: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä–µ–∫–ª–∞–º–µ ‚Äî –∫–æ–ª–æ–Ω–∫–∞ –±—É–¥–µ—Ç 0.")

        sold_view["ads_spend_click"] = (
            pd.to_numeric(
                sold_view["sku"].astype(str).str.replace(r"[^\d]", "", regex=True),
                errors="coerce"
            )
            .fillna(0)
            .astype(int)
            .map(_perf_map)
            .fillna(0.0)
        )

        # –û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤—ã—Ä—É—á–∫–µ SKU
        opex_period = opex_sum_period(df_opex, d_from, d_to)
        sold_view = allocate_cost_by_share(sold_view, opex_period, "opex_total")

        # –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –Ω–æ–≤—ã–º —Ñ–æ—Ä–º—É–ª–∞–º
        sold_view = compute_profitability(sold_view)

        show = sold_view.copy()
        show = show.rename(columns={
            "article": "–ê—Ä—Ç–∏–∫—É–ª",
            "sku": "SKU",
            "name": "–ù–∞–∑–≤–∞–Ω–∏–µ",
            "qty_orders": "–ó–∞–∫–∞–∑—ã, —à—Ç",
            "qty_returns": "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç",
            "qty_buyout": "–í—ã–∫—É–ø, —à—Ç",
            "accruals_net": "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ",
            "commission": "–ö–æ–º–∏—Å—Å–∏—è, ‚ÇΩ",
            "logistics": "–£—Å–ª—É–≥–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞, ‚ÇΩ",
            "acquiring": "–≠–∫–≤–∞–π—Ä–∏–Ω–≥, ‚ÇΩ",
            "sale_costs": "–†–∞—Å—Ö–æ–¥—ã Ozon, ‚ÇΩ",
            "ads_total": "–†–µ–∫–ª–∞–º–∞ (–∫–ª–∏–∫), ‚ÇΩ",
            "ads_spend_click": "–†–µ–∫–ª–∞–º–∞ (–∑–∞–∫–∞–∑), ‚ÇΩ",
            "cogs_unit": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç, ‚ÇΩ",
            "cogs_total": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ, ‚ÇΩ",
            "tax_total": "–ù–∞–ª–æ–≥, ‚ÇΩ",
            "opex_total": "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã, ‚ÇΩ",
            "profit_before_tax_opex": "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ",
            "profit_before_tax_opex_per_unit": "–ü—Ä–∏–±—ã–ª—å/—à—Ç, ‚ÇΩ",
            "profit": "–ü—Ä–∏–±—ã–ª—å (—á–∏—Å—Ç–∞—è), ‚ÇΩ",
            "profit_per_unit": "–ü—Ä–∏–±—ã–ª—å/—à—Ç (—á–∏—Å—Ç–∞—è), ‚ÇΩ",
            "margin_%": "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %",
            "roi_%": "ROI, %",
        })


        # === –î–æ–ø. –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≤–∏—Ç—Ä–∏–Ω—ã (–∫–∞–∫ –Ω–∞ Ozon) ===
        show["% –≤—ã–∫—É–ø–∞"] = show.apply(
            lambda r: (float(r.get("–í—ã–∫—É–ø, —à—Ç", 0)) / float(r.get("–ó–∞–∫–∞–∑—ã, —à—Ç", 0)) * 100.0)
            if float(r.get("–ó–∞–∫–∞–∑—ã, —à—Ç", 0) or 0) else 0.0,
            axis=1,
        )
        show["–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏, ‚ÇΩ"] = show.apply(
            lambda r: (float(r.get("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", 0)) / float(r.get("–í—ã–∫—É–ø, —à—Ç", 0)))
            if float(r.get("–í—ã–∫—É–ø, —à—Ç", 0) or 0) else 0.0,
            axis=1,
        )
        show["–î–†–†, %"] = show.apply(
            lambda r: (float(r.get("–†–µ–∫–ª–∞–º–∞ (–∫–ª–∏–∫), ‚ÇΩ", 0)) / float(r.get("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", 0)) * 100.0)
            if float(r.get("–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", 0) or 0) else 0.0,
            axis=1,
        )

        # –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        cols = [
            "–ê—Ä—Ç–∏–∫—É–ª","SKU","–ù–∞–∑–≤–∞–Ω–∏–µ",
            "–ó–∞–∫–∞–∑—ã, —à—Ç","–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç","–í—ã–∫—É–ø, —à—Ç","% –≤—ã–∫—É–ø–∞",
            "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ","–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏, ‚ÇΩ","–î–†–†, %",
            "–ö–æ–º–∏—Å—Å–∏—è, ‚ÇΩ","–£—Å–ª—É–≥–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞, ‚ÇΩ","–≠–∫–≤–∞–π—Ä–∏–Ω–≥, ‚ÇΩ","–†–∞—Å—Ö–æ–¥—ã Ozon, ‚ÇΩ","–†–µ–∫–ª–∞–º–∞ (–∫–ª–∏–∫), ‚ÇΩ","–†–µ–∫–ª–∞–º–∞ (–∑–∞–∫–∞–∑), ‚ÇΩ",
            "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç, ‚ÇΩ","–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ, ‚ÇΩ","–ù–∞–ª–æ–≥, ‚ÇΩ","–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã, ‚ÇΩ",
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ","–ü—Ä–∏–±—ã–ª—å/—à—Ç, ‚ÇΩ","–ü—Ä–∏–±—ã–ª—å (—á–∏—Å—Ç–∞—è), ‚ÇΩ","–ü—Ä–∏–±—ã–ª—å/—à—Ç (—á–∏—Å—Ç–∞—è), ‚ÇΩ",
            "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %","ROI, %"
        ]
        # 1) –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –≤ —Å–ø–∏—Å–∫–µ –∫–æ–ª–æ–Ω–æ–∫ (–≤–∞–∂–Ω–æ!)
        cols = list(dict.fromkeys(cols))
        
        # 2) –î–æ–∑–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω—É–ª—è–º–∏
        for c in cols:
            if c not in show.columns:
                show[c] = 0.0
        
        # 3) –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –µ—â—ë —Ä–∞–∑ —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ (–Ω–∞ –≤—Å—è–∫–∏–π)
        show = show[cols].copy()
        show = show.loc[:, ~show.columns.duplicated()].copy()

        # 4) SKU –¥–µ—Ä–∂–∏–º —á–∏—Å–ª–æ–º (int) ‚Äî –±–µ–∑ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö SKU
        if "SKU" in show.columns:
            show["SKU"] = pd.to_numeric(show["SKU"], errors="coerce").fillna(0).astype(int)
            # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º SKU –±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π —Ç—ã—Å—è—á
            show["SKU"] = show["SKU"].astype(str)

        # 5) –ß–∏—Å–ª–æ–≤—ã–µ —Ü–µ–ª—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        int_cols = ["–ó–∞–∫–∞–∑—ã, —à—Ç", "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç", "–í—ã–∫—É–ø, —à—Ç"]
        for c in int_cols:
            if c in show.columns:
                show[c] = pd.to_numeric(show[c], errors="coerce").fillna(0).astype(int)
        
        # 6) –î–µ–Ω–µ–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (float)
        money_cols = [
            "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ", "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏, ‚ÇΩ", "–ö–æ–º–∏—Å—Å–∏—è, ‚ÇΩ", "–£—Å–ª—É–≥–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞, ‚ÇΩ",
            "–†–∞—Å—Ö–æ–¥—ã Ozon, ‚ÇΩ", "–†–µ–∫–ª–∞–º–∞ (–∫–ª–∏–∫), ‚ÇΩ", "–†–µ–∫–ª–∞–º–∞ (–∑–∞–∫–∞–∑), ‚ÇΩ",
            "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç, ‚ÇΩ", "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ, ‚ÇΩ",
            "–ù–∞–ª–æ–≥, ‚ÇΩ", "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã, ‚ÇΩ",
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ", "–ü—Ä–∏–±—ã–ª—å/—à—Ç, ‚ÇΩ", "–ü—Ä–∏–±—ã–ª—å (—á–∏—Å—Ç–∞—è), ‚ÇΩ", "–ü—Ä–∏–±—ã–ª—å/—à—Ç (—á–∏—Å—Ç–∞—è), ‚ÇΩ",
        ]
        for c in money_cols:
            if c in show.columns:
                show[c] = pd.to_numeric(show[c], errors="coerce").fillna(0.0)

        pct_cols = ["% –≤—ã–∫—É–ø–∞","–î–†–†, %","–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %","ROI, %"]
        for c in pct_cols:
            show[c] = pd.to_numeric(show[c], errors="coerce").fillna(0.0)



        # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä—è–¥–∫–∞/–≤–∏–¥–∏–º–æ—Å—Ç–∏ –∫–æ–ª–æ–Ω–æ–∫ (–ø—Ä–æ—Å—Ç–æ–µ —Ä–µ—à–µ–Ω–∏–µ –±–µ–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤) ---
        # –í–∞–∂–Ω–æ: –≤ Streamlit –Ω–µ—Ç drag&drop –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫ –≤ st.dataframe,
        # –ø–æ—ç—Ç–æ–º—É –¥–µ–ª–∞–µ–º –ª—ë–≥–∫–∏–π UI: –≤—ã–±—Ä–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É –∏ –¥–≤–∏–≥–∞—Ç—å –≤–≤–µ—Ä—Ö/–≤–Ω–∏–∑ + —Å–∫—Ä—ã–≤–∞—Ç—å.
        default_cols = list(show.columns)
        order_key = "soldsku_col_order"
        hide_key = "soldsku_col_hidden"

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–ø–æ—Ä—è–¥–æ–∫/—Å–∫—Ä—ã—Ç—ã–µ) –≤ URL query params,
        # —á—Ç–æ–±—ã –ø–µ—Ä–µ–∂–∏–≤–∞–ª–æ F5 –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞—Ö–æ–¥ –ø–æ —Å—Å—ã–ª–∫–µ.
        qp_order_key = "soldsku_cols"
        qp_hide_key = "soldsku_hide"

        def _qp_get_one(key: str) -> str:
            """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ–º query param –∫–∞–∫ —Å—Ç—Ä–æ–∫—É (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π Streamlit)."""
            try:
                # Streamlit 1.30+: st.query_params
                qp = getattr(st, "query_params", None)
                if qp is not None:
                    v = qp.get(key)
                    if isinstance(v, list):
                        return str(v[0]) if v else ""
                    return str(v) if v is not None else ""
            except Exception:
                pass

            try:
                # –°—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏: experimental_get_query_params
                qp2 = st.experimental_get_query_params()
                v = qp2.get(key, [])
                return str(v[0]) if v else ""
            except Exception:
                return ""

        def _qp_set(**kwargs):
            """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–∏—à–µ–º query params (—Å—Ç–∞—Ä–∞—è/–Ω–æ–≤–∞—è API)."""
            try:
                qp = getattr(st, "query_params", None)
                if qp is not None:
                    for k, v in kwargs.items():
                        qp[k] = v
                    return
            except Exception:
                pass
            try:
                st.experimental_set_query_params(**kwargs)
            except Exception:
                pass

        # 1) –ü—Ä–æ–±—É–µ–º –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫/—Å–∫—Ä—ã—Ç—ã–µ –∏–∑ URL (–ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç F5)
        qp_cols = _qp_get_one(qp_order_key).strip()
        qp_hide = _qp_get_one(qp_hide_key).strip()
        if qp_cols and (order_key not in st.session_state):
            cols = [c for c in qp_cols.split(",") if c]
            st.session_state[order_key] = cols
        if qp_hide and (hide_key not in st.session_state):
            hidden = [c for c in qp_hide.split(",") if c]
            st.session_state[hide_key] = hidden

        if order_key not in st.session_state or not isinstance(st.session_state[order_key], list):
            st.session_state[order_key] = default_cols
        if hide_key not in st.session_state or not isinstance(st.session_state[hide_key], list):
            st.session_state[hide_key] = []

        # –µ—Å–ª–∏ –ø–æ—è–≤–∏–ª–∏—Å—å/–∏—Å—á–µ–∑–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º
        cur = [c for c in st.session_state[order_key] if c in default_cols]
        for c in default_cols:
            if c not in cur:
                cur.append(c)
        st.session_state[order_key] = cur
        st.session_state[hide_key] = [c for c in st.session_state[hide_key] if c in default_cols]

        # –î–µ—Ä–∂–∏–º –±–ª–æ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–æ–ª–æ–Ω–æ–∫ –æ—Ç–∫—Ä—ã—Ç—ã–º –ø–æ—Å–ª–µ –∫–ª–∏–∫–æ–≤ (Streamlit –¥–µ–ª–∞–µ—Ç rerun)
        if "soldsku_cols_expanded" not in st.session_state:
            st.session_state["soldsku_cols_expanded"] = True
        if "soldsku_last_col" not in st.session_state:
            st.session_state["soldsku_last_col"] = ""

        with st.expander("‚öôÔ∏è –ö–æ–ª–æ–Ω–∫–∏ —Ç–∞–±–ª–∏—Ü—ã", expanded=False):
            colA, colB, colC = st.columns([2.2, 1.2, 1.6])

            with colA:
                # –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü, —á—Ç–æ–±—ã –ø–æ—Å–ª–µ rerun –Ω–µ —Å–±–∏–≤–∞–ª–æ—Å—å
                _last = st.session_state.get("soldsku_col_picked")
                _idx = 0
                try:
                    if _last in st.session_state[order_key]:
                        _idx = st.session_state[order_key].index(_last)
                except Exception:
                    _idx = 0

                picked = st.selectbox(
                    "–ö–æ–ª–æ–Ω–∫–∞",
                    options=st.session_state[order_key],
                    index=_idx if st.session_state[order_key] else 0,
                    key="soldsku_col_picked",
                )

            with colB:
                left = st.button("‚¨ÖÔ∏è –í–ª–µ–≤–æ", use_container_width=True)
                right = st.button("‚û°Ô∏è –í–ø—Ä–∞–≤–æ", use_container_width=True)

            with colC:
                c1, c2 = st.columns([1.2, 1.0])
                with c1:
                    if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", use_container_width=True):
                        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫/—Å–∫—Ä—ã—Ç—ã–µ –≤ URL (–ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç F5)
                        try:
                            order_str = ",".join(st.session_state[order_key])
                            hide_str = ",".join(st.session_state[hide_key])
                            _qp_set(**{qp_order_key: order_str, qp_hide_key: hide_str})
                            st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
                        except Exception:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ URL")
                with c2:
                    if st.button("‚Ü©Ô∏è –°–±—Ä–æ—Å–∏—Ç—å", use_container_width=True):
                        st.session_state[order_key] = default_cols
                        st.session_state[hide_key] = []
                        try:
                            _qp_set(**{qp_order_key: "", qp_hide_key: ""})
                        except Exception:
                            pass
                        st.rerun()

            if picked and (left or right):
                st.session_state["soldsku_cols_expanded"] = True
                st.session_state["soldsku_last_col"] = picked
                cols = st.session_state[order_key]
                i = cols.index(picked)
                j = i - 1 if left else i + 1
                if 0 <= j < len(cols):
                    cols[i], cols[j] = cols[j], cols[i]
                    st.session_state[order_key] = cols
                    # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ URL, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∂–∏–≤–∞–ª–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    try:
                        _qp_set(**{qp_order_key: ",".join(st.session_state[order_key]), qp_hide_key: ",".join(st.session_state[hide_key])})
                    except Exception:
                        pass
                    st.rerun()

            st.session_state[hide_key] = st.multiselect(
                "–°–∫—Ä—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏",
                options=st.session_state[order_key],
                default=st.session_state[hide_key],
                key="soldsku_col_hidden_ui",
            )

        visible_cols = [c for c in st.session_state[order_key] if c not in set(st.session_state[hide_key])]
        if visible_cols:
            show = show[visible_cols]

        st.dataframe(
            show,
            use_container_width=True,
            hide_index=True,
            column_config={
                "–ó–∞–∫–∞–∑—ã, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
                "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
                "–í—ã–∫—É–ø, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
                **{c: st.column_config.NumberColumn(format="%.0f") for c in money_cols},
                "% –≤—ã–∫—É–ø–∞": st.column_config.NumberColumn(format="%.0f%%"),
                "–î–†–†, %": st.column_config.NumberColumn(format="%.1f%%"),
                "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %": st.column_config.NumberColumn(format="%.1f%%"),
                "ROI, %": st.column_config.NumberColumn(format="%.1f%%"),
            }
        )

        st.download_button(
            "–°–∫–∞—á–∞—Ç—å XLSX (—Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö SKU)",
            data=export_soldsku_xlsx(show),
            file_name=f"ozon_soldsku_{d_from.strftime('%Y-%m-%d')}_{d_to.strftime('%Y-%m-%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )





# ================== TAB 4 (OPEX) ==================
with tab4:
    st.subheader("–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã")
    st.caption("–†—É—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã (–Ω–µ –∏–∑ Ozon). –û–Ω–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ –ø—Ä–∏–±—ã–ª–∏ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ SKU –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤—ã—Ä—É—á–∫–µ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")

    opex = load_opex()
    types_saved = load_opex_types()

    st.markdown("### –î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥")

    c1, c2, c3, c4 = st.columns([1.2, 3.0, 1.2, 1.3])

    with c1:
        st.markdown("**–î–∞—Ç–∞**")
        new_date = st.date_input(
            "–î–∞—Ç–∞",
            value=date.today(),
            key="opex_new_date",
            label_visibility="collapsed",
        )

    with c2:
        st.markdown("**–¢–∏–ø**")
        types_saved = load_opex_types()
        options = (types_saved or []) + ["‚ûï –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–∏–ø"]

        sel = st.selectbox(
            "–¢–∏–ø",
            options=options,
            index=None,  # –≤–∞–∂–Ω–æ: –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            placeholder="–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Ä–∞—Å—Ö–æ–¥–∞‚Ä¶",
            key="opex_type_select",
            label_visibility="collapsed",
        )

        if sel == "‚ûï –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–∏–ø":
            new_type = st.text_input(
                "–ù–æ–≤—ã–π —Ç–∏–ø",
                value="",
                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ó–∞—Ä–ø–ª–∞—Ç–∞, –ê—Ä–µ–Ω–¥–∞‚Ä¶",
                key="opex_new_type_manual",
                label_visibility="collapsed",
            ).strip()
        else:
            new_type = (sel or "").strip()

    with c3:
        st.markdown("**–°—É–º–º–∞, ‚ÇΩ**")
        new_amount = st.number_input(
            "–°—É–º–º–∞, ‚ÇΩ",
            min_value=0.0,
            value=0.0,
            step=100.0,
            key="opex_new_amount",
            label_visibility="collapsed",
        )

        with c4:
            st.markdown("&nbsp;")  # —Å–æ–∑–¥–∞—ë–º ‚Äú—Å—Ç—Ä–æ–∫—É‚Äù –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–æ–∫, —á—Ç–æ–±—ã –∫–Ω–æ–ø–∫–∞ —Å—Ç–∞–ª–∞ –Ω–∞ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å
            add_exp = st.button("–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥", key="opex_add_btn", use_container_width=True)

    if add_exp:
        t = (new_type or "").strip()
        if float(new_amount or 0) <= 0:
            st.warning("–°—É–º–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 0.")
        elif not t:
            st.warning("–£–∫–∞–∂–∏ —Ç–∏–ø —Ä–∞—Å—Ö–æ–¥–∞.")
        else:
            types_saved = load_opex_types()
            if t not in types_saved:
                types_saved.append(t)
                save_opex_types(types_saved)

            row = pd.DataFrame([{"date": new_date, "type": t, "amount": float(new_amount)}])
            opex2 = pd.concat([opex, row], ignore_index=True)
            save_opex(opex2)
            st.success("–†–∞—Å—Ö–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ω.")
            st.rerun()

    st.divider()

    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞–º–∏ (—É–¥–∞–ª–µ–Ω–∏–µ/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ)
    with st.expander("–®–∞–±–ª–æ–Ω—ã —Ç–∏–ø–æ–≤ —Ä–∞—Å—Ö–æ–¥–æ–≤", expanded=False):
        types_saved = load_opex_types()
        if not types_saved:
            st.info("–®–∞–±–ª–æ–Ω–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç. –î–æ–±–∞–≤—å —Ä–∞—Å—Ö–æ–¥ —Å –Ω–æ–≤—ã–º —Ç–∏–ø–æ–º ‚Äî –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—è–≤–∏—Ç—Å—è –≤ —à–∞–±–ª–æ–Ω–∞—Ö.")
        else:
            tpl_df = pd.DataFrame({"–¢–∏–ø": types_saved, "–£–¥–∞–ª–∏—Ç—å": [False] * len(types_saved)})
            tpl_edit = st.data_editor(
                tpl_df,
                use_container_width=True,
                hide_index=True,
                num_rows="fixed",
                column_config={
                    "–¢–∏–ø": st.column_config.TextColumn(),
                    "–£–¥–∞–ª–∏—Ç—å": st.column_config.CheckboxColumn(width="small"),
                },
                key="opex_tpl_editor",
            )

            csave, cdel = st.columns([1.2, 1.6])
            with csave:
                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω—ã", key="opex_tpl_apply_btn", use_container_width=True):
                    df = tpl_edit.copy()
                    df["–¢–∏–ø"] = df["–¢–∏–ø"].fillna("").astype(str).str.strip()
                    df = df[df["–¢–∏–ø"] != ""].copy()
                    df = df[df["–£–¥–∞–ª–∏—Ç—å"] != True].copy()
                    save_opex_types(df["–¢–∏–ø"].tolist())
                    st.success("–®–∞–±–ª–æ–Ω—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
                    st.rerun()
            with cdel:
                if st.button("–£–¥–∞–ª–∏—Ç—å –æ—Ç–º–µ—á–µ–Ω–Ω—ã–µ", key="opex_tpl_del_btn", use_container_width=True):
                    df = tpl_edit.copy()
                    df["–¢–∏–ø"] = df["–¢–∏–ø"].fillna("").astype(str).str.strip()
                    df = df[df["–¢–∏–ø"] != ""].copy()
                    df = df[df["–£–¥–∞–ª–∏—Ç—å"] != True].copy()
                    save_opex_types(df["–¢–∏–ø"].tolist())
                    st.success("–£–¥–∞–ª–µ–Ω–æ.")
                    st.rerun()

    st.markdown("### –°–ø–∏—Å–æ–∫ —Ä–∞—Å—Ö–æ–¥–æ–≤ (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ / —É–¥–∞–ª–µ–Ω–∏–µ)")

    opex = load_opex()
    # --- —Ñ–∏–ª—å—Ç—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å—ë –≤—Ä–µ–º—è) ---
    if "opex_filter_year" not in st.session_state:
        st.session_state["opex_filter_year"] = "–í—Å–µ –≤—Ä–µ–º—è"
    if "opex_filter_month" not in st.session_state:
        st.session_state["opex_filter_month"] = "–í–µ—Å—å –≥–æ–¥"

    years = sorted({d.year for d in opex["date"].dropna()}, reverse=True) if not opex.empty else []
    year_options = ["–í—Å–µ –≤—Ä–µ–º—è"] + [str(y) for y in years]
    # –µ—Å–ª–∏ –≤ session_state –∑–Ω–∞—á–µ–Ω–∏–µ –≥–æ–¥–∞ –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
    if st.session_state.get("opex_filter_year") not in year_options:
        st.session_state["opex_filter_year"] = "–í—Å–µ –≤—Ä–µ–º—è"

    cfy, cfm, cfr = st.columns([1.0, 1.0, 1.0])
    with cfy:
        sel_year_lbl = st.selectbox("–ì–æ–¥", options=year_options, key="opex_filter_year")
    with cfm:
        if sel_year_lbl != "–í—Å–µ –≤—Ä–µ–º—è":
            yy = int(sel_year_lbl)
            months_av = sorted({d.month for d in opex["date"].dropna() if d.year == yy})
            month_options = ["–í–µ—Å—å –≥–æ–¥"] + [month_name_ru(m) for m in months_av]
        else:
            month_options = ["–í–µ—Å—å –≥–æ–¥"]
        # –µ—Å–ª–∏ –≤ session_state –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞ –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
        if st.session_state.get("opex_filter_month") not in month_options:
            st.session_state["opex_filter_month"] = month_options[0]
        sel_month_lbl = st.selectbox("–ú–µ—Å—è—Ü", options=month_options, key="opex_filter_month")
    with cfr:
        def _opex_reset_period():
            st.session_state["opex_filter_year"] = "–í—Å–µ –≤—Ä–µ–º—è"
            st.session_state["opex_filter_month"] = "–í–µ—Å—å –≥–æ–¥"
        st.button("–°–±—Ä–æ—Å–∏—Ç—å –ø–µ—Ä–∏–æ–¥", key="opex_filter_reset", on_click=_opex_reset_period)

    # –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
    opex_show = opex.copy()
    if sel_year_lbl != "–í—Å–µ –≤—Ä–µ–º—è":
        yy = int(sel_year_lbl)
        opex_show = opex_show[opex_show["date"].apply(lambda d: hasattr(d, "year") and d.year == yy)].copy()
        if sel_month_lbl != "–í–µ—Å—å –≥–æ–¥":
            mm = {month_name_ru(i): i for i in range(1, 13)}.get(sel_month_lbl)
            if mm:
                opex_show = opex_show[opex_show["date"].apply(lambda d: hasattr(d, "month") and d.month == mm)].copy()

    opex_show = opex_show.sort_values(["date", "type"], ascending=[False, True]).reset_index(drop=True)

    total_all = float(pd.to_numeric(opex["amount"], errors="coerce").fillna(0.0).sum()) if not opex.empty else 0.0
    st.markdown(f"**–°—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è:** {money(total_all)}")

    if opex.empty:
        st.info("–ü–æ–∫–∞ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π.")
    else:
        view = opex_show.copy()
        view["delete"] = False
        view = view[["delete", "date", "type", "amount"]].rename(columns={
            "delete": "–£–¥–∞–ª–∏—Ç—å",
            "date": "–î–∞—Ç–∞",
            "type": "–¢–∏–ø",
            "amount": "–°—É–º–º–∞, ‚ÇΩ",
        })

        edited = st.data_editor(
            view,
            use_container_width=True,
            hide_index=True,
            num_rows="fixed",
            column_config={
                "–£–¥–∞–ª–∏—Ç—å": st.column_config.CheckboxColumn(width="small"),
                "–î–∞—Ç–∞": st.column_config.DateColumn(format="YYYY-MM-DD"),
                "–¢–∏–ø": st.column_config.TextColumn(),
                "–°—É–º–º–∞, ‚ÇΩ": st.column_config.NumberColumn(format="%.0f"),
            },
            key="opex_editor",
        )

        csave, cexp = st.columns([1.6, 6.4])

        with csave:
            if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key="opex_save_btn", use_container_width=True):
                df = edited.copy()
                df = df[df["–£–¥–∞–ª–∏—Ç—å"] != True].copy()

                df["–î–∞—Ç–∞"] = pd.to_datetime(df["–î–∞—Ç–∞"], errors="coerce").dt.date
                df["–¢–∏–ø"] = df["–¢–∏–ø"].fillna("").astype(str).str.strip()
                df["–°—É–º–º–∞, ‚ÇΩ"] = pd.to_numeric(df["–°—É–º–º–∞, ‚ÇΩ"], errors="coerce").fillna(0.0)

                df = df.dropna(subset=["–î–∞—Ç–∞"]).copy()
                df = df[df["–¢–∏–ø"] != ""].copy()

                df2 = df.rename(columns={"–î–∞—Ç–∞": "date", "–¢–∏–ø": "type", "–°—É–º–º–∞, ‚ÇΩ": "amount"})[["date", "type", "amount"]]
                save_opex(df2)

                st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
                st.rerun()

        with cexp:
            st.download_button(
                "–°–∫–∞—á–∞—Ç—å XLSX",
                data=export_soldsku_xlsx(opex.rename(columns={"date": "–î–∞—Ç–∞", "type": "–¢–∏–ø", "amount": "–°—É–º–º–∞, ‚ÇΩ"})),
                file_name="ozon_opex.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )


# ================== TAB 2 (MONTHS) ==================
with tab2:
    st.subheader("–ü–æ–º–µ—Å—è—á–Ω–∞—è —Å–≤–æ–¥–∫–∞")

    import calendar as _cal

    def _fmt_int(x):
        try:
            return f"{int(round(float(x))):,}".replace(",", " ")
        except Exception:
            return "0"

    def fmt_money2(x):
        return f"{_fmt_int(x)} ‚ÇΩ"

    def fmt_pct2(x, digits=1):
        try:
            v = float(x) * 100.0 if abs(float(x)) <= 1.0 else float(x)
            return f"{v:.{digits}f}%"
        except Exception:
            return "0.0%"

    def month_label(ym: str) -> str:
        y, m = ym.split("-")
        m_i = int(m)
        ru_months = ["–Ø–Ω–≤–∞—Ä—å","–§–µ–≤—Ä–∞–ª—å","–ú–∞—Ä—Ç","–ê–ø—Ä–µ–ª—å","–ú–∞–π","–ò—é–Ω—å","–ò—é–ª—å","–ê–≤–≥—É—Å—Ç","–°–µ–Ω—Ç—è–±—Ä—å","–û–∫—Ç—è–±—Ä—å","–ù–æ—è–±—Ä—å","–î–µ–∫–∞–±—Ä—å"]
        return f"{ru_months[m_i-1]} {y}"

    def month_start_end(year: int, month: int):
        start = date(year, month, 1)
        last_day = _cal.monthrange(year, month)[1]
        end = date(year, month, last_day)
        return start, end

    st.caption("Ozon API –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –æ—á–µ—Ä–µ–¥–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏ –≤ –æ–¥–∏–Ω –º–µ—Å—è—Ü.")

    y_l, m_l = last_closed_month(date.today())
    last_closed = date(y_l, m_l, 1)
    default_from = (last_closed.replace(day=1) - timedelta(days=365)).replace(day=1)

    c1, c2 = st.columns(2)
    with c1:
        m_from_dt = st.date_input("–ú–µ—Å—è—Ü —Å", default_from, key="m_from_dt")
    with c2:
        m_to_dt = st.date_input("–ú–µ—Å—è—Ü –ø–æ", last_closed, key="m_to_dt")

    m_from_dt = m_from_dt.replace(day=1)
    m_to_dt = m_to_dt.replace(day=1)

    if m_from_dt > m_to_dt:
        st.error("–ú–µ—Å—è—Ü '—Å' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –º–µ—Å—è—Ü–∞ '–ø–æ'.")
        st.stop()

    months = []
    cur = m_from_dt
    while cur <= m_to_dt:
        months.append(cur.strftime("%Y-%m"))
        if cur.month == 12:
            cur = cur.replace(year=cur.year + 1, month=1, day=1)
        else:
            cur = cur.replace(month=cur.month + 1, day=1)

    def month_metrics(df_ops_m: pd.DataFrame) -> dict:
        sku_ops = df_ops_m[df_ops_m["sku"].notna()].copy()

        sales_accr = float(sku_ops[sku_ops["type"].eq("orders")]["accruals_for_sale"].sum())
        returns_accr = float(sku_ops[sku_ops["type"].eq("returns")]["accruals_for_sale"].sum())
        revenue_net = sales_accr + returns_accr

        orders_qty = int(round(float(sku_ops[sku_ops["type"].eq("orders")].get("qty", 0).sum()))) if "qty" in sku_ops.columns else 0
        returns_qty = int(round(float(sku_ops[sku_ops["type"].eq("returns")].get("qty", 0).sum()))) if "qty" in sku_ops.columns else 0
        bought_qty = max(orders_qty - returns_qty, 0)
        buyout_pct = (bought_qty / orders_qty * 100.0) if orders_qty else 0.0

        commission_sum = float((-sku_ops["sale_commission"]).clip(lower=0).sum())
        commission_pct = (commission_sum / revenue_net * 100.0) if revenue_net else 0.0

        logistic_sum = float((-sku_ops["services_sum"]).clip(lower=0).sum())
        logistic_avg = (logistic_sum / bought_qty) if bought_qty else 0.0
        logistic_pct = (logistic_sum / revenue_net * 100.0) if revenue_net else 0.0

        over = df_ops_m[df_ops_m["sku"].isna()].copy()
        storage_fbo = float((-over[over["type_name"].eq("–£—Å–ª—É–≥–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ")]["amount"]).clip(lower=0).sum())
        storage_pct = (storage_fbo / revenue_net * 100.0) if revenue_net else 0.0

        reviews_cost = float((-over[over["type_name"].str.contains("–ë–∞–ª–ª—ã –∑–∞ –æ—Ç–∑—ã–≤—ã", case=False, na=False)]["amount"]).clip(lower=0).sum())
        reviews_pct = (reviews_cost / revenue_net * 100.0) if revenue_net else 0.0

        mask_known = (
            over["type_name"].eq("–£—Å–ª—É–≥–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ")
            | over["type_name"].str.contains("–ë–∞–ª–ª—ã –∑–∞ –æ—Ç–∑—ã–≤—ã", case=False, na=False)
        )
        other_expenses = float((-over[~mask_known]["amount"]).clip(lower=0).sum())
        other_expenses_pct = (other_expenses / revenue_net * 100.0) if revenue_net else 0.0

        compensations = float((over[over["type_name"].str.contains("–ö–æ–º–ø–µ–Ω—Å–∞—Ü", case=False, na=False)]["amount"]).sum())
        fines = float((-over[over["type_name"].str.contains("—à—Ç—Ä–∞—Ñ", case=False, na=False)]["amount"]).clip(lower=0).sum())
        paid_accept = float((-over[over["type_name"].str.contains("–ü–ª–∞—Ç–Ω", case=False, na=False)]["amount"]).clip(lower=0).sum())
        adjustments = float((over[over["type_name"].str.contains("–ö–æ—Ä—Ä–µ–∫—Ç", case=False, na=False)]["amount"]).sum())

        total_ozon_exp = commission_sum + logistic_sum + storage_fbo + reviews_cost + other_expenses
        share_ozon = (total_ozon_exp / revenue_net * 100.0) if revenue_net else 0.0

        taxes = revenue_net * 0.06 if revenue_net else 0.0
        to_pay = float(sku_ops["amount"].sum())

        profit = revenue_net - total_ozon_exp - taxes
        profit_pct_price = (profit / revenue_net * 100.0) if revenue_net else 0.0

        days_in_month = 30
        if not df_ops_m.empty:
            s = str(df_ops_m.iloc[0].get("operation_date", ""))[:10]
            try:
                dt0 = datetime.strptime(s, "%Y-%m-%d").date()
                days_in_month = _cal.monthrange(dt0.year, dt0.month)[1]
            except Exception:
                pass

        weeks = max(round(days_in_month / 7.0, 2), 1.0)
        profit_week = profit / weeks if weeks else profit
        avg_price = (revenue_net / bought_qty) if bought_qty else 0.0

        return {
            "–ö–æ–ª-–≤–æ –∑–∞–∫–∞–∑–æ–≤": orders_qty,
            "–í—ã–∫—É–ø–ª–µ–Ω–æ —à—Ç.": bought_qty,
            "% –≤—ã–∫—É–ø–∞": buyout_pct,

            "–í—ã—Ä—É—á–∫–∞ —Å —É—á–µ—Ç–æ–º –≤–æ–∑–≤—Ä–∞—Ç–æ–≤": revenue_net,
            "–°—Ä. —Ü–µ–Ω–∞": avg_price,

            "–û–±—â–∏–µ —Ä–∞—Å—Ö–æ–¥—ã Ozon": total_ozon_exp,
            "–ö–æ–º–∏—Å—Å–∏—è": commission_sum,
            "% –∫–æ–º–∏—Å—Å–∏–∏ –æ—Ç –≤—ã—Ä—É—á–∫–∏": commission_pct,

            "–õ–æ–≥–∏—Å—Ç–∏–∫–∞": logistic_sum,
            "–°—Ä. –ª–æ–≥–∏—Å—Ç–∏–∫–∞": logistic_avg,
            "% –õ–æ–≥–∏—Å—Ç–∏–∫–∏": logistic_pct,

            "–•—Ä–∞–Ω–µ–Ω–∏–µ": storage_fbo,
            "% —Ö—Ä–∞–Ω–µ–Ω–∏—è": storage_pct,

            "–û—Ç–∑—ã–≤—ã –∑–∞ –±–∞–ª–ª—ã": reviews_cost,
            "% –æ—Ç–∑—ã–≤–æ–≤ –∑–∞ –±–∞–ª–ª—ã": reviews_pct,

            "–ü—Ä–æ—á–∏–µ —Ä–∞—Å—Ö–æ–¥—ã": other_expenses,
            "% –ø—Ä–æ—á–∏—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤": other_expenses_pct,

            "–ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏": compensations,
            "–®—Ç—Ä–∞—Ñ—ã": fines,
            "–ü–ª–∞—Ç–Ω–∞—è –ø—Ä–∏–µ–º–∫–∞": paid_accept,
            "–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏": adjustments,

            "–î–æ–ª—è Ozon, %": share_ozon,
            "–ù–∞–ª–æ–≥–∏": taxes,
            "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é": to_pay,

            "–ü—Ä–∏–±—ã–ª—å": profit,
            "% –ø—Ä–∏–±—ã–ª–∏ –≤ –≤—ã—Ä—É—á–∫–µ": profit_pct_price,

            "–ö–æ–ª-–≤–æ –Ω–µ–¥–µ–ª—å": weeks,
            "–ü—Ä–∏–±—ã–ª—å —Å—Ä–µ–¥–Ω–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è": profit_week,
        }

    @st.cache_data(ttl=3600)
    def load_ops_month(year: int, month: int):
        d1, d2 = month_start_end(year, month)
        try:
            return client.fetch_finance_transactions(d1.strftime("%Y-%m-%d"), d2.strftime("%Y-%m-%d")), "", ""
        except Exception as e:
            title, details = _humanize_ozon_error(e)
            return [], title, details

    month_rows = []
    progress = st.progress(0, text="–°—á–∏—Ç–∞—é –º–µ—Å—è—Ü—ã‚Ä¶")
    for i, ym in enumerate(months, start=1):
        y, mo = map(int, ym.split("-"))
        ops_m, ops_m_err_title, ops_m_err_details = load_ops_month(y, mo)
        if ops_m_err_title:
            _block_with_retry(ops_m_err_title, ops_m_err_details, cache_clear_fn=load_ops_month.clear)
        df_ops_m = ops_to_df(ops_m)
        met = month_metrics(df_ops_m)
        # –û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã –∑–∞ –º–µ—Å—è—Ü (–∏–∑ —Ç–∞–±–∞ "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã")
        d1_m, d2_m = month_start_end(y, mo)
        met["–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã"] = opex_sum_period(df_opex, d1_m, d2_m)
        met["YM"] = ym
        month_rows.append(met)
        progress.progress(i / len(months), text=f"–°—á–∏—Ç–∞—é –º–µ—Å—è—Ü—ã‚Ä¶ {i}/{len(months)}")
    progress.empty()

    df_month = pd.DataFrame(month_rows).sort_values(["YM"]).reset_index(drop=True)
    df_month["–ú–µ—Å—è—Ü"] = df_month["YM"].apply(month_label)

    st.markdown("### –°—Ä–∞–≤–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤")

    month_options = df_month["–ú–µ—Å—è—Ü"].tolist()
    default_sel = month_options[-3:] if len(month_options) >= 3 else month_options
    key_ms = "months_compare_sel"
    if key_ms not in st.session_state:
        st.session_state[key_ms] = default_sel

    b1, b2, _ = st.columns([1.4, 1.1, 3.5])
    with b1:
        if st.button("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ –º–µ—Å—è—Ü—ã", use_container_width=True, key="btn_months_all"):
            st.session_state[key_ms] = month_options[:]
    with b2:
        if st.button("–°–Ω—è—Ç—å –≤—ã–±–æ—Ä", use_container_width=True, key="btn_months_clear"):
            st.session_state[key_ms] = []

    sel_months = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Å—è—Ü—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", options=month_options, key=key_ms)

    df_view = df_month.copy()
    if sel_months:
        df_view = df_view[df_view["–ú–µ—Å—è—Ü"].isin(sel_months)].copy()

    metric_cols = [c for c in df_view.columns if c not in ("YM", "–ú–µ—Å—è—Ü")]
    pivot = (
        df_view.set_index("–ú–µ—Å—è—Ü")[metric_cols]
        .T
        .reset_index()
        .rename(columns={"index": "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"})
    )

    percent_metrics = {
        "% –≤—ã–∫—É–ø–∞",
        "% –∫–æ–º–∏—Å—Å–∏–∏ –æ—Ç –≤—ã—Ä—É—á–∫–∏",
        "% –õ–æ–≥–∏—Å—Ç–∏–∫–∏",
        "% —Ö—Ä–∞–Ω–µ–Ω–∏—è",
        "% –æ—Ç–∑—ã–≤–æ–≤ –∑–∞ –±–∞–ª–ª—ã",
        "% –ø—Ä–æ—á–∏—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤",
        "–î–æ–ª—è Ozon, %",
        "% –ø—Ä–∏–±—ã–ª–∏ –≤ –≤—ã—Ä—É—á–∫–µ",
    }
    int_metrics = {"–ö–æ–ª-–≤–æ –∑–∞–∫–∞–∑–æ–≤", "–í—ã–∫—É–ø–ª–µ–Ω–æ —à—Ç."}

    def format_row(row):
        name = row["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"]
        for col in row.index:
            if col == "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å":
                continue
            v = row[col]
            if name in percent_metrics:
                row[col] = fmt_pct2(v, 1)
            elif name in int_metrics:
                row[col] = _fmt_int(v)
            elif name in {"–ö–æ–ª-–≤–æ –Ω–µ–¥–µ–ª—å"}:
                try:
                    row[col] = f"{float(v):.1f}"
                except Exception:
                    row[col] = "0.0"
            else:
                row[col] = fmt_money2(v)
        return row

    pivot_pretty = pivot.apply(format_row, axis=1)
    st.markdown("### –ü–æ–º–µ—Å—è—á–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    st.dataframe(
    pivot_pretty,
    use_container_width=True,
    hide_index=True
    )

    def export_monthly_xlsx(df_rows: pd.DataFrame, df_pivot_pretty: pd.DataFrame) -> bytes:
        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as w:
            df_rows.to_excel(w, index=False, sheet_name="Monthly_rows_raw")
            df_pivot_pretty.to_excel(w, index=False, sheet_name="Monthly_pivot_pretty")
        return bio.getvalue()

    st.download_button(
        "–°–∫–∞—á–∞—Ç—å XLSX (–ø–æ–º–µ—Å—è—á–Ω–∞—è —Å–≤–æ–¥–∫–∞)",
        data=export_monthly_xlsx(df_view, pivot_pretty),
        file_name="ozon_monthly_summary.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )



# ================== TAB 3 (ABC) ==================
with tab3:
    st.subheader("ABC-–∞–Ω–∞–ª–∏–∑ –º–∞–≥–∞–∑–∏–Ω–∞")

    import calendar as _cal2
    import io

    def _fmt_int(x):
        try:
            return f"{int(round(float(x))):,}".replace(",", " ")
        except Exception:
            return "0"

    def _fmt_money(x):
        try:
            return f"{float(x):,.0f} ‚ÇΩ".replace(",", " ")
        except Exception:
            return "0 ‚ÇΩ"

    def month_start_end(year: int, month: int):
        start = date(year, month, 1)
        last_day = _cal2.monthrange(year, month)[1]
        return start, date(year, month, last_day)

    def closed_months_until_today():
        y_last, m_last = last_closed_month(date.today())
        out = []
        y = 2020
        m = 1
        while (y < y_last) or (y == y_last and m <= m_last):
            out.append((y, m))
            if m == 12:
                y += 1
                m = 1
            else:
                m += 1
        return out

    def closed_quarters_for_year(year: int, closed_set):
        q_map = {1: [1,2,3], 2: [4,5,6], 3: [7,8,9], 4: [10,11,12]}
        res = []
        for q, mm in q_map.items():
            if all((year, m) in closed_set for m in mm):
                res.append(q)
        return res

    def abc_class_from_metric(df: pd.DataFrame, col: str):
        s = df[col].fillna(0).astype(float)
        total = float(s.sum())
        if total <= 0:
            return pd.Series(["C"] * len(df), index=df.index)
        share = s / total
        cum = share.cumsum()
        return cum.apply(lambda x: "A" if x <= 0.8 else "B" if x <= 0.95 else "C")

    @st.cache_data(ttl=3600)
    def load_ops_month_abc(y: int, m: int):
        d1, d2 = month_start_end(y, m)
        try:
            return client.fetch_finance_transactions(d1.strftime("%Y-%m-%d"), d2.strftime("%Y-%m-%d")), "", ""
        except Exception as e:
            title, details = _humanize_ozon_error(e)
            return [], title, details

    closed = closed_months_until_today()
    closed_set = set(closed)
    years = sorted({y for y, _ in closed}, reverse=True)
    if not years:
        st.info("–ù–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –º–µ—Å—è—Ü–µ–≤.")
        st.stop()

    colA, colB, colC = st.columns([1.1, 1.2, 2.2])
    with colA:
        mode = st.radio("–ü–µ—Ä–∏–æ–¥", ["–ú–µ—Å—è—Ü—ã", "–ö–≤–∞—Ä—Ç–∞–ª—ã"], horizontal=True, key="abc_mode")
    with colB:
        sel_year = st.selectbox("–ì–æ–¥", years, index=0, key="abc_year")
    with colC:
        only_profit = st.checkbox("–¢–æ–ª—å–∫–æ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ SKU", value=False, key="abc_only_profit")

    months_in_year = [(y, m) for (y, m) in closed if y == sel_year]
    month_options = [month_name_ru(m) for (y, m) in months_in_year]
    month_map = {month_name_ru(m): (y, m) for (y, m) in months_in_year}

    q_list = closed_quarters_for_year(sel_year, closed_set)
    q_options = [f"{q} –∫–≤." for q in q_list]
    q_to_months = {
        f"{q} –∫–≤.": [(sel_year, mm) for mm in ([1,2,3] if q==1 else [4,5,6] if q==2 else [7,8,9] if q==3 else [10,11,12])]
        for q in q_list
    }

    selected_months = []
    chosen_labels = []
    chosen_q = []

    if mode == "–ú–µ—Å—è—Ü—ã":
        if not month_options:
            st.info("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–¥ –Ω–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –º–µ—Å—è—Ü–µ–≤.")
            st.stop()

        key_ms = "abc_months_sel"
        if key_ms not in st.session_state:
            st.session_state[key_ms] = month_options[:]

        b1, b2, _ = st.columns([1.6, 1.2, 3.2])
        with b1:
            if st.button("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ –∑–∞–∫—Ä—ã—Ç—ã–µ –º–µ—Å—è—Ü—ã", use_container_width=True, key="abc_btn_all_m"):
                st.session_state[key_ms] = month_options[:]
        with b2:
            if st.button("–°–Ω—è—Ç—å –≤—ã–±–æ—Ä", use_container_width=True, key="abc_btn_clear_m"):
                st.session_state[key_ms] = []

        chosen_labels = st.multiselect("–ú–µ—Å—è—Ü—ã (–∑–∞–∫—Ä—ã—Ç—ã–µ)", options=month_options, key=key_ms)
        selected_months = [month_map[x] for x in chosen_labels if x in month_map]
    else:
        if not q_options:
            st.info("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–¥ –Ω–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –∫–≤–∞—Ä—Ç–∞–ª–æ–≤.")
            st.stop()

        key_q = "abc_quarters_sel"
        if key_q not in st.session_state:
            st.session_state[key_q] = q_options[:]

        b1, b2, _ = st.columns([1.6, 1.2, 3.2])
        with b1:
            if st.button("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ –∑–∞–∫—Ä—ã—Ç—ã–µ –∫–≤–∞—Ä—Ç–∞–ª—ã", use_container_width=True, key="abc_btn_all_q"):
                st.session_state[key_q] = q_options[:]
        with b2:
            if st.button("–°–Ω—è—Ç—å –≤—ã–±–æ—Ä", use_container_width=True, key="abc_btn_clear_q"):
                st.session_state[key_q] = []

        chosen_q = st.multiselect("–ö–≤–∞—Ä—Ç–∞–ª—ã (–∑–∞–∫—Ä—ã—Ç—ã–µ)", options=q_options, key=key_q)
        months_flat = []
        for qlbl in chosen_q:
            months_flat.extend(q_to_months.get(qlbl, []))
        selected_months = sorted(set(months_flat), key=lambda x: (x[0], x[1]))

    if not selected_months:
        st.warning("–í—ã–±–µ—Ä–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –º–µ—Å—è—Ü/–∫–≤–∞—Ä—Ç–∞–ª.")
        st.stop()

    dfs = []
    p = st.progress(0, text="–ó–∞–≥—Ä—É–∂–∞—é –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Å—è—Ü–∞–º‚Ä¶")
    for i, (yy, mm) in enumerate(selected_months, 1):
        _ops_m, _err_t, _err_d = load_ops_month_abc(yy, mm)
        if _err_t:
            _block_with_retry(_err_t, _err_d, cache_clear_fn=load_ops_month_abc.clear)
        dfs.append(ops_to_df(_ops_m))
        p.progress(i / len(selected_months), text=f"–ó–∞–≥—Ä—É–∂–∞—é –æ–ø–µ—Ä–∞—Ü–∏–∏‚Ä¶ {i}/{len(selected_months)}")
    p.empty()

    # ================== ABC: —Å—á–∏—Ç–∞–µ–º "–ø–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω—É—é" –ø—Ä–∏–±—ã–ª—å –∫–∞–∫ –≤ TAB1 ==================
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –º–µ—Å—è—Ü—ã
    df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

    # –ü–µ—Ä–∏–æ–¥ ABC (–Ω—É–∂–µ–Ω –¥–ª—è —Ä–µ–∫–ª–∞–º—ã –∏ –æpex)
    d_from_abc = None
    d_to_abc = None
    for (yy, mm) in selected_months:
        a, b = month_start_end(yy, mm)
        d_from_abc = a if d_from_abc is None else min(d_from_abc, a)
        d_to_abc = b if d_to_abc is None else max(d_to_abc, b)
    if d_from_abc is None or d_to_abc is None:
        st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä–∏–æ–¥ ABC.")
        st.stop()

    # 1) –ë–µ—Ä—ë–º —Ç—É –∂–µ SKU-—Ç–∞–±–ª–∏—Ü—É, —á—Ç–æ –∏ –≤ TAB1 (—Ç–∞–º —É–∂–µ –µ—Å—Ç—å –∫–æ–º–∏—Å—Å–∏–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞/COGS/–∞—Ä—Ç–∏–∫—É–ª—ã)
    analytics_abc_df, _, _ = load_analytics_range(d_from_abc.strftime("%Y-%m-%d"), d_to_abc.strftime("%Y-%m-%d"))
    sold_abc = build_sold_sku_table(df, cogs_df, analytics_abc_df)
    if sold_abc is None or sold_abc.empty:
        st.info("–ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ SKU –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        st.stop()

    # 2) –ù–∞–ª–æ–≥ 6% —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤—ã—Ä—É—á–∫–µ SKU (–∫–∞–∫ –≤ TAB1)
    total_tax_abc = float(sold_abc["accruals_net"].sum()) * 0.06
    sold_abc = allocate_tax_by_share(sold_abc, total_tax_abc)

    # 3) –†–µ–∫–ª–∞–º–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–£ –ñ–ï –ª–æ–≥–∏–∫—É, —á—Ç–æ –∏ –≤ TAB1
    # (–±–µ—Ä—ë–º –æ–±—â–∏–π —Ä–∞—Å—Ö–æ–¥ –Ω–∞ —Ä–µ–∫–ª–∞–º—É –∏–∑ Performance summary –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –≤—ã—Ä—É—á–∫–µ SKU)
    ads_alloc_abc = load_ads_spend_by_article(
        d_from_abc.strftime("%Y-%m-%d"),
        d_to_abc.strftime("%Y-%m-%d"),
    )
    sold_abc = allocate_ads_by_article(sold_abc, ads_alloc_abc.get("by_article", {}))

    # 4) –û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤—ã—Ä—É—á–∫–µ SKU (–∫–∞–∫ –≤ TAB1)
    opex_period_abc = opex_sum_period(df_opex, d_from_abc, d_to_abc)
    sold_abc = allocate_cost_by_share(sold_abc, opex_period_abc, "opex_total")

    # 5) –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–∏–±—ã–ª—å (—Ç–∞ –∂–µ —Ñ–æ—Ä–º—É–ª–∞, —á—Ç–æ –∏ –≤ TAB1)
    sold_abc = compute_profitability(sold_abc)

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ñ–æ—Ä–º–∞—Ç—É, –∫–æ—Ç–æ—Ä—ã–π –¥–∞–ª—å—à–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç ABC (qty/accruals/profit)
    g = sold_abc.rename(columns={
        "qty_buyout": "buyout_qty",
        "accruals_net": "accruals",
    }).copy()

    # —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ —Ç–∏–ø–æ–≤
    g["buyout_qty"] = pd.to_numeric(g.get("buyout_qty", 0), errors="coerce").fillna(0).astype(int)
    g["accruals"] = pd.to_numeric(g.get("accruals", 0.0), errors="coerce").fillna(0.0)
    g["profit"] = pd.to_numeric(g.get("profit", 0.0), errors="coerce").fillna(0.0)

    # –≤ TAB3 –Ω–∏–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è name, sku, article
    if "name" not in g.columns:
        g["name"] = ""
    if "article" not in g.columns:
        g["article"] = ""
    g["article"] = g["article"].fillna("").astype(str)

    if only_profit:
        g = g[g["profit"] > 0].copy()

    if g.empty:
        st.info("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å SKU.")
        st.stop()

    g_buy = g.sort_values("buyout_qty", ascending=False).copy()
    g_buy["grp_buyout"] = abc_class_from_metric(g_buy, "buyout_qty")

    g_turn = g.sort_values("accruals", ascending=False).copy()
    g_turn["grp_turn"] = abc_class_from_metric(g_turn, "accruals")

    g_prof = g.sort_values("profit", ascending=False).copy()
    g_prof["grp_profit"] = abc_class_from_metric(g_prof, "profit")

    g_res = g.merge(g_buy[["sku","grp_buyout"]], on="sku", how="left")
    g_res = g_res.merge(g_turn[["sku","grp_turn"]], on="sku", how="left")
    g_res = g_res.merge(g_prof[["sku","grp_profit"]], on="sku", how="left")
    g_res["–ò–¢–û–ì–û"] = g_res["grp_buyout"].fillna("C") + g_res["grp_turn"].fillna("C") + g_res["grp_profit"].fillna("C")

    view = g_res.rename(columns={
        "sku": "SKU",
        "article": "–ê—Ä—Ç–∏–∫—É–ª",
        "name": "–¢–æ–≤–∞—Ä",
        "buyout_qty": "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç",
        "accruals": "–û–±–æ—Ä–æ—Ç, ‚ÇΩ",
        "profit": "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ",
        "grp_buyout": "–ì—Ä—É–ø–ø–∞ –ø–æ –≤—ã–∫—É–ø—É",
        "grp_turn": "–ì—Ä—É–ø–ø–∞ –ø–æ –æ–±–æ—Ä–æ—Ç—É",
        "grp_profit": "–ì—Ä—É–ø–ø–∞ –ø—Ä–∏–±—ã–ª—å"
    }).copy()

    # —ç–∫—Å–ø–æ—Ä—Ç (—Å—ã—Ä—ã–µ —á–∏—Å–ª–∞)
    export_df = view.copy()
    for col in ["–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç", "–û–±–æ—Ä–æ—Ç", "–ü—Ä–∏–±—ã–ª—å"]:
        if col in export_df.columns:
            export_df[col] = pd.to_numeric(export_df[col], errors="coerce")
    if "SKU" in export_df.columns:
        export_df["SKU"] = pd.to_numeric(export_df["SKU"], errors="coerce").astype("Int64")

    # –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
    # –∫–æ–ª-–≤–æ: int, –¥–µ–Ω—å–≥–∏: float
    if "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç" in view.columns:
        view["–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç"] = pd.to_numeric(view["–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç"], errors="coerce").fillna(0).astype(int)
    if "–û–±–æ—Ä–æ—Ç, ‚ÇΩ" in view.columns:
        view["–û–±–æ—Ä–æ—Ç, ‚ÇΩ"] = pd.to_numeric(view["–û–±–æ—Ä–æ—Ç, ‚ÇΩ"], errors="coerce").fillna(0.0)
    if "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ" in view.columns:
        view["–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ"] = pd.to_numeric(view["–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ"], errors="coerce").fillna(0.0)

    # –ø–µ—Ä–µ–¥ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º (—á—Ç–æ–±—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –±—ã–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π)
    view["SKU"] = pd.to_numeric(view["SKU"], errors="coerce").fillna(0).astype(int)

    st.dataframe(
        view[[
            "–ê—Ä—Ç–∏–∫—É–ª", "SKU", "–¢–æ–≤–∞—Ä",
            "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç", "–ì—Ä—É–ø–ø–∞ –ø–æ –≤—ã–∫—É–ø—É",
            "–û–±–æ—Ä–æ—Ç, ‚ÇΩ", "–ì—Ä—É–ø–ø–∞ –ø–æ –æ–±–æ—Ä–æ—Ç—É",
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ", "–ì—Ä—É–ø–ø–∞ –ø—Ä–∏–±—ã–ª—å", "–ò–¢–û–ì–û"
        ]],
        use_container_width=True,
        hide_index=True,
        column_config={
            "SKU": st.column_config.NumberColumn(format="%.0f"),  # üëà –∫–ª—é—á–µ–≤–æ–µ: –±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
            "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
            "–û–±–æ—Ä–æ—Ç, ‚ÇΩ": st.column_config.NumberColumn(format="%.0f"),
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ": st.column_config.NumberColumn(format="%.0f"),
        },
    )

    # ===== –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è XLSX (—Å–Ω–∏–∑—É —Å–ª–µ–≤–∞) =====
    def _period_label(mode, chosen_labels, chosen_q, sel_year):
        if mode == "–ú–µ—Å—è—Ü—ã":
            return f"{sel_year}_" + "-".join(chosen_labels) if chosen_labels else str(sel_year)
        else:
            return f"{sel_year}_" + "-".join(chosen_q) if chosen_q else str(sel_year)

    period_label = _period_label(mode, chosen_labels, chosen_q, sel_year)

    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        export_df.to_excel(writer, index=False, sheet_name="ABC")
    buf.seek(0)

    btn_col, _ = st.columns([1, 6])
    with btn_col:
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å XLSX",
            data=buf,
            file_name=f"ABC_{period_label}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
