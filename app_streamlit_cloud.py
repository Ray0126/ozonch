import os
import io
import time
import json
import requests
import zipfile
import re
import streamlit as st
import pandas as pd
from datetime import date, timedelta, datetime
from dotenv import load_dotenv
import sys
from pathlib import Path

# ================== AUTH ==================
APP_PASSWORD = os.getenv("APP_PASSWORD")

if "auth_ok" not in st.session_state:
    st.session_state.auth_ok = False

if not st.session_state.auth_ok:
    st.markdown(
        """
        <style>
        .auth-box {
            max-width: 420px;
            margin: 120px auto;
            padding: 30px;
            border-radius: 12px;
            background: #1f1f24;
            box-shadow: 0 0 30px rgba(0,0,0,0.4);
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    with st.container():
        st.markdown('<div class="auth-box">', unsafe_allow_html=True)
        st.markdown("## üîê –í—Ö–æ–¥ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")

        with st.form("login_form"):
            pwd = st.text_input(
                "–ü–∞—Ä–æ–ª—å",
                type="password",
                placeholder="–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å",
            )
            submitted = st.form_submit_button("–í–æ–π—Ç–∏")

        if submitted:
            if pwd == APP_PASSWORD:
                st.session_state.auth_ok = True
                st.rerun()
            else:
                st.error("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–æ–ª—å")

        st.markdown("</div>", unsafe_allow_html=True)

    st.stop()


BASE_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(BASE_DIR / "src"))

from ozon_client import OzonSellerClient, last_closed_month


# ================== CONFIG ==================
st.set_page_config(
    layout="wide",
    page_title="–û—Ü–∏—Ñ—Ä–æ–≤–∫–∞ Ozon",
    initial_sidebar_state="collapsed",
)
import sys
from pathlib import Path

def resource_path(rel: str) -> str:
    # –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –≤ exe: —Ñ–∞–π–ª—ã –ª–µ–∂–∞—Ç –≤ _MEIPASS
    if hasattr(sys, "_MEIPASS"):
        return str(Path(sys._MEIPASS) / rel)
    # –ø—Ä–∏ –æ–±—ã—á–Ω–æ–º –∑–∞–ø—É—Å–∫–µ: —Ä—è–¥–æ–º —Å app.py
    return str(Path(__file__).resolve().parent / rel)

def _get_setting(name: str, default: str = "") -> str:
    """–ë–µ—Ä—ë–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑:
    1) –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    2) Streamlit secrets (–¥–ª—è Streamlit Cloud)
    3) default
    """
    v = os.getenv(name)
    if v is not None and str(v).strip() != "":
        return str(v).strip()
    try:
        # st.secrets –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω–æ/–≤ exe
        if hasattr(st, "secrets") and name in st.secrets:
            return str(st.secrets.get(name)).strip()
    except Exception:
        pass
    return default

# –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞/EXE: –º–æ–∂–Ω–æ –¥–µ—Ä–∂–∞—Ç—å .env —Ä—è–¥–æ–º, –Ω–æ –≤ –æ–±–ª–∞–∫–µ –µ–≥–æ –Ω–µ –±—É–¥–µ—Ç.
try:
    load_dotenv(resource_path(".env"), override=False)
except Exception:
    pass

# --- –ú–∏–Ω–∏-–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –ø–∞—Ä–æ–ª—é (–µ—Å–ª–∏ APP_PASSWORD –∑–∞–¥–∞–Ω) ---
APP_PASSWORD = _get_setting("APP_PASSWORD", "").strip()
if APP_PASSWORD:
    if not st.session_state.get("auth_ok"):
        with st.sidebar:
            st.markdown("### –î–æ—Å—Ç—É–ø")
            pw = st.text_input("–ü–∞—Ä–æ–ª—å", type="password", key="app_password_input")
            if pw and pw == APP_PASSWORD:
                st.session_state["auth_ok"] = True
                st.rerun()
        st.stop()

# --- Ozon Seller API ---
client_id = _get_setting("OZON_CLIENT_ID", "")
api_key = _get_setting("OZON_API_KEY", "")
if not client_id or not api_key:
    st.error("–ù–µ—Ç OZON_CLIENT_ID / OZON_API_KEY (–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ Streamlit secrets).")
    st.stop()

client = OzonSellerClient(client_id, api_key)

# --- Supabase (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è COGS/OPEX –≤ –æ–±–ª–∞–∫–µ) ---
SUPABASE_URL = _get_setting("SUPABASE_URL", "")
SUPABASE_SERVICE_ROLE_KEY = _get_setting("SUPABASE_SERVICE_ROLE_KEY", "")
SUPABASE_SCHEMA = _get_setting("SUPABASE_SCHEMA", "public") or "public"
USE_SUPABASE = bool(SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY)

def _sb_headers() -> dict:
    h = {
        "apikey": SUPABASE_SERVICE_ROLE_KEY,
        "Authorization": f"Bearer {SUPABASE_SERVICE_ROLE_KEY}",
        "Content-Type": "application/json",
    }
    # –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –Ω–µ public —Å—Ö–µ–º—É ‚Äî Supabase REST —Ç—Ä–µ–±—É–µ—Ç —É–∫–∞–∑–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª—å
    if SUPABASE_SCHEMA and SUPABASE_SCHEMA != "public":
        h["Accept-Profile"] = SUPABASE_SCHEMA
        h["Content-Profile"] = SUPABASE_SCHEMA
    return h

def _sb_url(table: str) -> str:
    base = SUPABASE_URL.rstrip("/")
    return f"{base}/rest/v1/{table}"

def _sb_fetch(table: str, select: str = "*", limit: int = 10000) -> pd.DataFrame:
    # –ø—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö —Ç–∞–±–ª–∏—Ü)
    params = {"select": select, "limit": str(limit)}
    r = requests.get(_sb_url(table), headers=_sb_headers(), params=params, timeout=30)
    if r.status_code >= 300:
        raise RuntimeError(f"Supabase fetch {table}: {r.status_code} {r.text}")
    data = r.json() if r.text else []
    return pd.DataFrame(data)

def _sb_replace_all(table: str, rows: list[dict], delete_filter: str) -> None:
    # 1) –æ—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–æ —Ñ–∏–ª—å—Ç—Ä—É
    r_del = requests.delete(_sb_url(table) + f"?{delete_filter}", headers=_sb_headers(), timeout=30)
    if r_del.status_code >= 300:
        raise RuntimeError(f"Supabase delete {table}: {r_del.status_code} {r_del.text}")
    # 2) –≤—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
    if rows:
        r_ins = requests.post(
            _sb_url(table),
            headers={**_sb_headers(), "Prefer": "return=minimal"},
            data=json.dumps(rows, ensure_ascii=False),
            timeout=30,
        )
        if r_ins.status_code >= 300:
            raise RuntimeError(f"Supabase insert {table}: {r_ins.status_code} {r_ins.text}")


# ================== PERF API (ADS) ==================
class OzonPerfClient:
    """
    Ozon Performance API (ADS) ‚Äî —Ä–∞–±–æ—á–∏–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç CSV.

    - campaigns: GET /api/client/campaign (JSON)
    - daily:     GET /api/client/statistics/daily (CSV, sep=';', decimal=',')

    –í–ê–ñ–ù–û:
    - campaignIds –Ω–µ–ª—å–∑—è —Å–ª–∞—Ç—å —Å—Ç—Ä–æ–∫–æ–π "1,2,3"
      –ù—É–∂–Ω–æ campaignIds=1&campaignIds=2 (requests —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫)
    """

    def __init__(self, client_id: str, client_secret: str, base_url: str = "https://api-performance.ozon.ru"):
        self.client_id = str(client_id).strip()
        self.client_secret = str(client_secret).strip()
        self.base_url = base_url.rstrip("/")
        self._token = None
        self._token_ts = 0.0
        self._token_ttl = 50 * 60  # 50 –º–∏–Ω
        self._last_debug = {}

    # ----------------- token -----------------
    def _request_json(self, method: str, path: str, *, headers=None, params=None, json_body=None, timeout=30) -> dict:
        url = self.base_url + path
        h = {
            "Accept": "application/json",
            "Content-Type": "application/json",
            "User-Agent": "ozon-ads-dashboard/1.0",
        }
        if headers:
            h.update(headers)

        r = requests.request(method=method.upper(), url=url, headers=h, params=params, json=json_body, timeout=timeout)

        if r.status_code < 200 or r.status_code >= 300:
            raise RuntimeError(f"{r.status_code} {path}: {r.text}")

        try:
            return r.json()
        except Exception:
            # –∏–Ω–æ–≥–¥–∞ JSON –±–µ–∑ content-type
            raise RuntimeError(f"–û–∂–∏–¥–∞–ª JSON, –Ω–æ –ø—Ä–∏—à–ª–æ –Ω–µ JSON: {r.text[:1000]}")

    def _get_token_uncached(self) -> str:
        data = self._request_json(
            "POST",
            "/api/client/token",
            json_body={
                "client_id": int(self.client_id) if self.client_id.isdigit() else self.client_id,
                "client_secret": self.client_secret,
                "grant_type": "client_credentials",
            },
        )
        token = data.get("access_token")
        if not token:
            raise RuntimeError(f"–ù–µ –ø–æ–ª—É—á–∏–ª access_token. –û—Ç–≤–µ—Ç: {data}")
        return token

    def get_token(self) -> str:
        now = time.time()
        if self._token and (now - self._token_ts) < self._token_ttl:
            return self._token
        token = self._get_token_uncached()
        self._token = token
        self._token_ts = now
        return token
        
import zipfile

class OzonPerfClient:
    # ... (–≤—Å—ë —á—Ç–æ —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å)

    def _request_bytes(self, method: str, path: str, *, headers=None, params=None, json_body=None, timeout=60) -> bytes:
        url = self.base_url + path
        h = {
            "Accept": "*/*",
            "Content-Type": "application/json",
            "User-Agent": "ozon-ads-dashboard/1.0",
        }
        if headers:
            h.update(headers)

        r = requests.request(method=method.upper(), url=url, headers=h, params=params, json=json_body, timeout=timeout)
        if r.status_code < 200 or r.status_code >= 300:
            raise RuntimeError(f"{r.status_code} {path}: {r.text}")
        return r.content

    def _submit_statistics(self, date_from: str, date_to: str, campaign_ids: list[int]) -> str:
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        payload = {
            "campaigns": [str(int(x)) for x in (campaign_ids or [])],
            "dateFrom": date_from,
            "dateTo": date_to,
            "groupBy": "NO_GROUP_BY",
        }

        data = self._request_json("POST", "/api/client/statistics", headers=headers, json_body=payload, timeout=60)
        # –≤ –¥–æ–∫–∞—Ö –ø–æ–ª–µ "UUID", –Ω–æ –∏–Ω–æ–≥–¥–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å "uuid"
        uuid = data.get("UUID") or data.get("uuid") or data.get("Uuid")
        if not uuid:
            raise RuntimeError(f"–ù–µ –ø–æ–ª—É—á–∏–ª UUID –∏–∑ /api/client/statistics. –û—Ç–≤–µ—Ç: {data}")
        return str(uuid)

    def _try_download_report(self, uuid: str) -> bytes:
        """
        –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç —Ä–∞–∑–Ω—ã–º–∏ –ø—É—Ç—è–º–∏ (—É —Ä–∞–∑–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤/–≤–µ—Ä—Å–∏–π API –±—ã–≤–∞–µ—Ç –ø–æ-—Ä–∞–∑–Ω–æ–º—É).
        """
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        candidates = [
            ("/api/client/statistics/report", {"UUID": uuid}),
            ("/api/client/statistics/report", {"uuid": uuid}),
            (f"/api/client/statistics/{uuid}/report", None),
            (f"/api/client/statistics/{uuid}/download", None),
            (f"/api/client/statistics/download/{uuid}", None),
        ]

        last_err = None
        for path, params in candidates:
            try:
                return self._request_bytes("GET", path, headers=headers, params=params, timeout=120)
            except Exception as e:
                last_err = e

        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ UUID={uuid}. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_err}")

    def _wait_until_ready_and_download(self, uuid: str, max_wait_sec: int = 120) -> bytes:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç: –∂–¥—ë–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å, –ø–æ—Ç–æ–º —Å–∫–∞—á–∏–≤–∞–µ–º.
        –ï—Å–ª–∏ —Å—Ç–∞—Ç—É—Å-—ç–Ω–¥–ø–æ–∏–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/–Ω–µ–ø–æ–Ω—è—Ç–µ–Ω ‚Äî –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ —Å–∫–∞—á–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑.
        """
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        # –≤–æ–∑–º–æ–∂–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã —Å—Ç–∞—Ç—É—Å–∞ (fallback)
        status_candidates = [
            (f"/api/client/statistics/{uuid}", None),
            ("/api/client/statistics", {"UUID": uuid}),
            ("/api/client/statistics/status", {"UUID": uuid}),
            ("/api/client/statistics/status", {"uuid": uuid}),
        ]

        t0 = time.time()
        attempt = 0
        while True:
            attempt += 1

            # 1) –ø—Ä–æ–±—É–µ–º —Å—Ç–∞—Ç—É—Å
            for path, params in status_candidates:
                try:
                    data = self._request_json("GET", path, headers=headers, params=params, timeout=30)
                    # —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: status/state/ready
                    stt = str(data.get("status") or data.get("state") or data.get("Status") or "").lower()
                    if stt in ("done", "ready", "success", "completed", "finish", "finished"):
                        return self._try_download_report(uuid)
                    if stt in ("error", "failed", "fail"):
                        raise RuntimeError(f"–û—Ç—á—ë—Ç —É–ø–∞–ª –≤ —Å—Ç–∞—Ç—É—Å–µ ERROR: {data}")
                except Exception:
                    pass

            # 2) –µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å (—á–∞—Å—Ç–æ —É–∂–µ –≥–æ—Ç–æ–≤–æ)
            try:
                return self._try_download_report(uuid)
            except Exception:
                pass

            if time.time() - t0 >= max_wait_sec:
                raise RuntimeError("–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–∞ Performance (/api/client/statistics).")

            time.sleep(2.0)

    @staticmethod
    def _parse_stats_file_bytes(content: bytes) -> list[pd.DataFrame]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ DataFrame.
        –£–º–µ–µ—Ç:
        - CSV
        - ZIP (–Ω–µ—Å–∫–æ–ª—å–∫–æ CSV)
        - –ø—Ä–æ–ø—É—Å–∫ "—Ç–∏—Ç—É–ª—å–Ω–æ–π" –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ ("–û—Ç—á–µ—Ç –ø–æ ...")
        - fallback –Ω–∞ —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ (\t –∏ ;)
        - fallback –Ω–∞ cp1251
        """
        import zipfile
    
        def _decode(raw: bytes) -> str:
            for enc in ("utf-8-sig", "utf-8", "cp1251"):
                try:
                    return raw.decode(enc, errors="strict")
                except Exception:
                    pass
            return raw.decode("utf-8", errors="ignore")
    
        def _read_csv_text(txt: str) -> pd.DataFrame:
            txt = (txt or "").lstrip("\ufeff").strip()
            if not txt:
                return pd.DataFrame()
    
            lines = txt.splitlines()
            # –µ—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî "–û—Ç—á–µ—Ç ...", –∞ —à–∞–ø–∫–∞ –Ω–∞ 2-–π —Å—Ç—Ä–æ–∫–µ
            skip1 = False
            if lines and ("–æ—Ç—á–µ—Ç" in lines[0].lower() or "–æ—Ç—á—ë—Ç" in lines[0].lower()):
                skip1 = True
    
            # –ø—Ä–æ–±—É–µ–º —Ç–∞–±—ã, –ø–æ—Ç–æ–º ;
            for sep in ("\t", ";"):
                try:
                    df = pd.read_csv(
                        io.StringIO(txt),
                        sep=sep,
                        dtype=str,
                        keep_default_na=False,
                        skiprows=1 if skip1 else 0,
                    )
                    # –µ—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ 1 –∫–æ–ª–æ–Ω–∫–∞ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –±–µ–∑ skiprows (–∏–Ω–æ–≥–¥–∞ –æ—Ç—á—ë—Ç –±–µ–∑ —Ç–∏—Ç—É–ª–∞)
                    if len(df.columns) <= 1 and skip1:
                        df = pd.read_csv(
                            io.StringIO(txt),
                            sep=sep,
                            dtype=str,
                            keep_default_na=False,
                            skiprows=0,
                        )
                    # –µ—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ 1 –∫–æ–ª–æ–Ω–∫–∞ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–µ —Ç–æ—Ç sep
                    if len(df.columns) > 1:
                        return df
                except Exception:
                    pass
    
            # –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å
            try:
                return pd.read_csv(io.StringIO(txt), dtype=str, keep_default_na=False)
            except Exception:
                return pd.DataFrame()
    
        if not content:
            return []
    
        # ZIP?
        if content[:2] == b"PK":
            dfs = []
            with zipfile.ZipFile(io.BytesIO(content)) as z:
                for name in z.namelist():
                    if not name.lower().endswith(".csv"):
                        continue
                    raw = z.read(name)
                    txt = _decode(raw)
                    df = _read_csv_text(txt)
                    if df is not None and not df.empty:
                        dfs.append(df)
            return dfs
    
        # CSV
        txt = _decode(content)
        df = _read_csv_text(txt)
        return [df] if df is not None and not df.empty else []
    
        @staticmethod
        def _num_from_any(x) -> float:
            s = str(x or "").strip()
            if not s:
                return 0.0
            s = s.replace("\u00a0", " ").replace(" ", "")
            s = s.replace(",", ".")
            try:
                return float(s)
            except Exception:
                return 0.0

    @staticmethod
    def _digits(x) -> str:
        return "".join(ch for ch in str(x or "") if ch.isdigit())

    def fetch_ads_spend_by_sku(self, date_from: str, date_to: str) -> dict[int, float]:
        """
        –†–µ–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã –ø–æ –∫–∞–∂–¥–æ–º—É SKU –∏–∑ –æ—Ç—á—ë—Ç–æ–≤ Performance:
        —Å—É–º–º–∏—Ä—É–µ—Ç "–†–∞—Å—Ö–æ–¥" –ø–æ Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏–Ω–∞—á–µ –ø–æ Ozon ID.
        """
        if not self.client_id or not self.client_secret:
            return {}

        # –∫–∞–º–ø–∞–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è —Å –ø–µ—Ä–∏–æ–¥–æ–º
        camp_ids = self.campaign_ids_overlapping(date_from, date_to, limit=300)
        if not camp_ids:
            return {}

        uuid = self._submit_statistics(date_from, date_to, camp_ids)
        blob = self._wait_until_ready_and_download(uuid, max_wait_sec=180)

        dfs = self._parse_stats_file_bytes(blob)
        if not dfs:
            return {}

        spend_by_sku: dict[int, float] = {}

        for df in dfs:
            if df is None or df.empty:
                continue
            cols = [str(c).strip() for c in df.columns]
            df.columns = cols

            # –∏—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ (–∫–∞–∫ –≤ —Ç–≤–æ—ë–º –ø—Ä–∏–º–µ—Ä–µ –æ—Ç—á—ë—Ç–∞)
            # "Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞" + "–†–∞—Å—Ö–æ–¥, ?"
            col_pid = None
            for cand in ["Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞", "Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ ", "Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞\t"]:
                if cand in df.columns:
                    col_pid = cand
                    break
            if col_pid is None:
                # fallback
                for cand in ["Ozon ID", "OzonID", "SKU", "sku"]:
                    if cand in df.columns:
                        col_pid = cand
                        break

            col_spent = None
            for cand in ["–†–∞—Å—Ö–æ–¥, ‚ÇΩ", "–†–∞—Å—Ö–æ–¥, ?", "–†–∞—Å—Ö–æ–¥", "Cost", "Spent"]:
                if cand in df.columns:
                    col_spent = cand
                    break

            if not col_pid or not col_spent:
                continue

            for _, r in df.iterrows():
                sku_raw = self._digits(r.get(col_pid))
                if not sku_raw:
                    continue
                try:
                    sku = int(sku_raw)
                except Exception:
                    continue
                spent = self._num_from_any(r.get(col_spent))
                if spent:
                    spend_by_sku[sku] = float(spend_by_sku.get(sku, 0.0) + spent)

                # 1) –°–Ω–∞—á–∞–ª–∞ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ sku
        keys = list(spend_by_sku.keys())
        if not keys:
            return {}
        
        # –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å SKU –∏–∑ –æ–ø–µ—Ä–∞—Ü–∏–π (–±—ã—Å—Ç—Ä–æ, –±–µ–∑ API)
        # –±–µ—Ä—ë–º –Ω–µ–±–æ–ª—å—à—É—é –≤—ã–±–æ—Ä–∫—É –∏ —Å—á–∏—Ç–∞–µ–º, —Å–∫–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        # (–º—ã –Ω–µ –∑–Ω–∞–µ–º sold_skus –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Å–∞, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–≤–µ—Ä–∏–º —á–µ—Ä–µ–∑ "—Ä–∞–∑—É–º–Ω—ã–π" –ø—Ä–∏–∑–Ω–∞–∫: sku –æ–±—ã—á–Ω–æ 7-9 —Ü–∏—Ñ—Ä,
        # product_id —á–∞—Å—Ç–æ —Ç–æ–∂–µ, —Ç–∞–∫ —á—Ç–æ –ª—É—á—à–µ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ —Ç–∞–±–∞ ‚Äî –Ω–∏–∂–µ –±—É–¥–µ—Ç 100% –≤–∞—Ä–∏–∞–Ω—Ç)
        
        return spend_by_sku


    # ----------------- helpers -----------------
    @staticmethod
    def _safe_date10(s: str):
        try:
            s10 = str(s)[:10]
            return datetime.strptime(s10, "%Y-%m-%d").date()
        except Exception:
            return None

    @staticmethod
    def _iter_chunks(d1: date, d2: date, max_days: int = 62):
        cur = d1
        while cur <= d2:
            chunk_to = min(cur + timedelta(days=max_days - 1), d2)
            yield cur, chunk_to
            cur = chunk_to + timedelta(days=1)

    def last_debug(self) -> dict:
        return self._last_debug or {}
    @staticmethod
    def _humanize_error(msg: str) -> str:
        m = (msg or "").strip()

        # –°–∞–º–∞—è —á–∞—Å—Ç–∞—è: –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–µ—Ä–∏–æ–¥–∞
        if "max statistics period" in m and "62" in m:
            return (
                "Performance API: –≤—ã–±—Ä–∞–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n\n"
                "‚ö†Ô∏è Ozon –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –≤—ã–≥—Ä—É–∑–∫—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∫–ª–∞–º—ã –º–∞–∫—Å–∏–º—É–º **62 –¥–Ω—è** –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å.\n"
                "–°–æ–∫—Ä–∞—Ç–∏ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ 30‚Äì60 –¥–Ω–µ–π) ‚Äî –∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ä–µ–∫–ª–∞–º—ã –ø–æ—è–≤—è—Ç—Å—è.\n\n"
                "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –ø—Ä–æ–¥–∞–∂–∏/–ø—Ä–∏–±—ã–ª—å –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º —Å—á–∏—Ç–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –∏ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∏ –Ω–∞ –±–æ–ª—å—à–æ–º –ø–µ—Ä–∏–æ–¥–µ."
            )

        # –ù–∞ –±—É–¥—É—â–µ–µ ‚Äî –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω/–¥–æ—Å—Ç—É–ø
        if "401" in m or "unauthorized" in m.lower():
            return (
                "Performance API: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ (401).\n\n"
                "–ü—Ä–æ–≤–µ—Ä—å PERF_CLIENT_ID / PERF_CLIENT_SECRET –≤ .env –∏ –ø—Ä–∞–≤–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."
            )

        return f"Performance API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {m}"
    def product_ids_to_sku_map(product_ids: list[int]) -> dict[int, int]:
        """
        product_id -> sku (–±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π sku –∏–∑ –º–∞—Å—Å–∏–≤–∞ sku)
        """
        if not product_ids:
            return {}
    
        url = "https://api-seller.ozon.ru/v2/product/info/list"
        headers = {"Client-Id": str(client_id), "Api-Key": str(api_key)}
    
        out = {}
        CHUNK = 900  # –±–µ–∑–æ–ø–∞—Å–Ω–æ
        for i in range(0, len(product_ids), CHUNK):
            chunk = product_ids[i:i+CHUNK]
            body = {"filter": {"product_id": chunk}, "last_id": 0, "limit": len(chunk)}
            r = requests.post(url, headers=headers, json=body, timeout=60)
            if r.status_code != 200:
                continue
            data = r.json() or {}
            items = data.get("result", {}).get("items", []) or []
            for it in items:
                pid = it.get("product_id")
                skus = it.get("sku") or []
                if pid and skus:
                    try:
                        out[int(pid)] = int(skus[0])
                    except Exception:
                        pass
        return out

    # ----------------- campaigns -----------------
    def list_campaigns(self) -> list[dict]:
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        data = self._request_json("GET", "/api/client/campaign", headers=headers)

        if isinstance(data, list):
            return data

        for k in ("list", "result", "campaigns", "items", "data", "rows"):
            if isinstance(data, dict) and isinstance(data.get(k), list):
                return data[k]

        return []

    def campaign_ids_overlapping(self, date_from_str: str, date_to_str: str, limit: int = 300) -> list[int]:
        d_from = self._safe_date10(date_from_str)
        d_to = self._safe_date10(date_to_str)
        camps = self.list_campaigns()

        ids: list[int] = []
        for c in camps:
            cid = c.get("id")
            if cid is None:
                continue

            c_from = self._safe_date10(c.get("fromDate") or c.get("dateFrom") or c.get("date_from") or "")
            c_to = self._safe_date10(c.get("toDate") or c.get("dateTo") or c.get("date_to") or "")

            ok = True
            if d_from and d_to and (c_from or c_to):
                left = c_from or d_from
                right = c_to or d_to
                ok = not (right < d_from or left > d_to)

            if ok:
                try:
                    ids.append(int(cid))
                except Exception:
                    pass

            if len(ids) >= limit:
                break

        return ids

    # ----------------- daily CSV -----------------
    @staticmethod
    def _parse_csv_semicolon(text: str) -> pd.DataFrame:
        cleaned = (text or "").lstrip("\ufeff").strip()
        if not cleaned:
            return pd.DataFrame()

        df = pd.read_csv(
            io.StringIO(cleaned),
            sep=";",
            dtype=str,
            keep_default_na=False,
        )

        # –ü—Ä–∏–≤–æ–¥–∏–º —á–∏—Å–ª–∞: "1 234,56" -> 1234.56
        for col in df.columns:
            s = df[col].astype(str)
            if s.str.contains(r"\d", regex=True).any():
                s2 = (
                    s.str.replace("\u00a0", "", regex=False)
                     .str.replace(" ", "", regex=False)
                     .str.replace(",", ".", regex=False)
                )
                df[col] = pd.to_numeric(s2, errors="ignore")

        return df

    @staticmethod
    def _norm_col(s: str) -> str:
        return str(s).strip().lower().replace("\u00a0", " ").replace("  ", " ")

    @staticmethod
    def _pick_num(df: pd.DataFrame, candidates: list[str]) -> float:
        cols_l = {._norm_col(c): c for c in df.columns}
        for name in candidates:
            key = ._norm_col(name)
            if key in cols_l:
                v = pd.to_numeric(df[cols_l[key]], errors="coerce").fillna(0).sum()
                try:
                    return float(v)
                except Exception:
                    return 0.0
        return 0.0

    @staticmethod
    def _pick_int(df: pd.DataFrame, candidates: list[str]) -> int:
        return int(round(._pick_num(df, candidates)))

    def fetch_statistics_daily(self, date_from_str: str, date_to_str: str, campaign_ids: list[int]) -> tuple[dict, dict]:
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        # params: –µ—Å–ª–∏ ids –ø—É—Å—Ç—ã–µ ‚Äî –ø—Ä–æ–±—É–µ–º –±–µ–∑ campaignIds (—É —Ç–µ–±—è —Ç–∞–∫ —Ä–µ–∞–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–ª–æ)
        params: dict = {"dateFrom": date_from_str, "dateTo": date_to_str}

        ids = [int(x) for x in (campaign_ids or []) if str(x).isdigit()]
        if ids:
            # –ö–õ–Æ–ß–ï–í–û–ï: —Å–ø–∏—Å–æ–∫ -> campaignIds=1&campaignIds=2...
            params["campaignIds"] = ids[:200]

        url = self.base_url + "/api/client/statistics/daily"

        r = requests.get(
            url,
            headers={
                "Authorization": f"Bearer {token}",
                "Accept": "*/*",
                "User-Agent": "ozon-ads-dashboard/1.0",
            },
            params=params,
            timeout=60
        )

        meta = {
            "ok_variant": {"method": "GET", "path": "/api/client/statistics/daily", "params": params},
            "status_code": r.status_code,
            "content_type": r.headers.get("Content-Type", ""),
            "url": r.url,
        }

        if r.status_code != 200:
            raise RuntimeError(f"{r.status_code} /api/client/statistics/daily: {r.text}")

        df = self._parse_csv_semicolon(r.text)

        # --- –ú–ï–¢–†–ò–ö–ò –ò–ó –¢–í–û–ï–ì–û CSV (—Ä—É—Å—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏) ---
        spent = self._pick_num(df, ["–†–∞—Å—Ö–æ–¥, ‚ÇΩ", "–†–∞—Å—Ö–æ–¥", "–ó–∞—Ç—Ä–∞—Ç—ã", "Cost", "Spent"])
        revenue = self._pick_num(df, ["–ó–∞–∫–∞–∑—ã, ‚ÇΩ", "–ó–∞–∫–∞–∑—ã ‚ÇΩ", "–í—ã—Ä—É—á–∫–∞", "–û–±–æ—Ä–æ—Ç", "Revenue"])
        orders = self._pick_int(df, ["–ó–∞–∫–∞–∑—ã, —à—Ç.", "–ó–∞–∫–∞–∑—ã, —à—Ç", "–ó–∞–∫–∞–∑—ã —à—Ç", "Orders", "Orders count"])
        clicks = self._pick_num(df, ["–ö–ª–∏–∫–∏", "Clicks"])
        shows = self._pick_num(df, ["–ü–æ–∫–∞–∑—ã", "Impressions", "Shows"])

        drr = (spent / revenue * 100.0) if revenue else 0.0
        cpc = (spent / clicks) if clicks else 0.0
        ctr = (clicks / shows * 100.0) if shows else 0.0

        dbg = {
            **meta,
            "rows_count": int(len(df)),
            "columns": [str(c) for c in df.columns],
            "head": df.head(5).to_dict(orient="records") if not df.empty else [],
        }

        metrics = {"spent": spent, "revenue": revenue, "orders": orders, "clicks": float(clicks), "shows": float(shows), "drr": drr, "cpc": cpc, "ctr": ctr}
        return metrics, dbg
    # ================== NEW: ASYNC STATISTICS REPORT (spend by promoted sku) ==================
    def _request_raw(self, method: str, path: str, *, headers=None, params=None, json_body=None, timeout=60):
        url = self.base_url + path
        h = {"User-Agent": "ozon-ads-dashboard/1.0"}
        if headers:
            h.update(headers)
        r = requests.request(method=method.upper(), url=url, headers=h, params=params, json=json_body, timeout=timeout)
        return r

    def _parse_money_ru(self, x):
        # "1 234,56" -> 1234.56
        if x is None:
            return 0.0
        s = str(x).strip()
        if not s:
            return 0.0
        s = s.replace("\u00a0", " ").replace(" ", "")
        s = s.replace(",", ".")
        try:
            return float(s)
        except Exception:
            # –∏–Ω–æ–≥–¥–∞ –ø–æ–ø–∞–¥–∞–µ—Ç—Å—è –º—É—Å–æ—Ä —Ç–∏–ø–∞ "‚Äî"
            return 0.0

    def _detect_delimiter(self, text: str) -> str:
        # –≤ –ø—Ä–∏–º–µ—Ä–µ –∏–∑ Ozon —Ç–∞–±—ã, –Ω–æ —á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç ;  ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –æ–±–∞
        head = (text or "")[:2000]
        if head.count("\t") >= head.count(";"):
            return "\t"
        return ";"

    def _read_csv_any(self, raw: bytes) -> pd.DataFrame:
        # –ø—Ä–æ–±—É–µ–º utf-8-sig, –ø–æ—Ç–æ–º cp1251
        for enc in ("utf-8-sig", "utf-8", "cp1251"):
            try:
                txt = raw.decode(enc, errors="strict")
                txt = txt.lstrip("\ufeff")
                if not txt.strip():
                    continue
                sep = self._detect_delimiter(txt)
                df = pd.read_csv(io.StringIO(txt), sep=sep, dtype=str, keep_default_na=False)
                df.columns = [str(c).strip() for c in df.columns]
                return df
            except Exception:
                pass

        # –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å
        txt = raw.decode("utf-8", errors="ignore").lstrip("\ufeff")
        sep = self._detect_delimiter(txt)
        df = pd.read_csv(io.StringIO(txt), sep=sep, dtype=str, keep_default_na=False)
        df.columns = [str(c).strip() for c in df.columns]
        return df

    def _extract_spend_map_from_df(self, df: pd.DataFrame) -> dict[int, float]:
        """
        –ò—â–µ–º:
          - –∫–æ–ª–æ–Ω–∫—É —Å –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º—ã–º —Ç–æ–≤–∞—Ä–æ–º: "Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞" (—ç—Ç–æ –∏ –µ—Å—Ç—å SKU/ID —Ç–æ–≤–∞—Ä–∞)
          - –∫–æ–ª–æ–Ω–∫—É —Ä–∞—Å—Ö–æ–¥–∞: "–†–∞—Å—Ö–æ–¥, ‚ÇΩ" / "–†–∞—Å—Ö–æ–¥" / "Cost" / "Spent" / "–†–∞—Å—Ö–æ–¥, ?"
        –°—É–º–º–∏—Ä—É–µ–º —Ä–∞—Å—Ö–æ–¥ –ø–æ –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–º—É ID.
        """
        if df is None or df.empty:
            return {}

        cols = {str(c).strip().lower(): c for c in df.columns}

        def find_col(cands):
            for cand in cands:
                key = cand.lower()
                for k, orig in cols.items():
                    if key == k:
                        return orig
            # –º—è–≥–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—é
            for cand in cands:
                key = cand.lower()
                for k, orig in cols.items():
                    if key in k:
                        return orig
            return None

        sku_col = find_col([
            "ozon id –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞",
            "ozon id promoted product",
            "promoted product",
            "–ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞",
        ])

        spend_col = find_col([
            "—Ä–∞—Å—Ö–æ–¥, ‚ÇΩ",
            "—Ä–∞—Å—Ö–æ–¥",
            "spent",
            "cost",
            "—Ä–∞—Å—Ö–æ–¥, ?",
        ])

        if not sku_col or not spend_col:
            return {}

        out: dict[int, float] = {}

        s_sku = df[sku_col].astype(str).str.replace(r"[^\d]", "", regex=True)
        s_spend = df[spend_col].astype(str)

        for a, b in zip(s_sku.tolist(), s_spend.tolist()):
            if not a:
                continue
            try:
                sku = int(a)
            except Exception:
                continue
            spend = self._parse_money_ru(b)
            if spend:
                out[sku] = out.get(sku, 0.0) + float(spend)

        return out

    def fetch_ads_spend_by_sku_report(self, date_from: str, date_to: str, campaign_ids: list[int]) -> tuple[dict[int, float], dict]:
        """
        –î–µ–ª–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–∞–º–ø–∞–Ω–∏—è–º,
        —Å–∫–∞—á–∏–≤–∞–µ—Ç CSV –∏–ª–∏ ZIP –∏ —Å–æ–±–∏—Ä–∞–µ—Ç spend_map –ø–æ Ozon ID –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º–æ–≥–æ —Ç–æ–≤–∞—Ä–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (spend_map, debug)
        """
        token = self.get_token()
        headers = {"Authorization": f"Bearer {token}"}

        ids = [int(x) for x in (campaign_ids or []) if str(x).isdigit()]
        if not ids:
            return {}, {"error": "no campaign ids"}

        # 1) submit
        submit_body = {
            "campaigns": [str(x) for x in ids],
            "dateFrom": date_from,
            "dateTo": date_to,
            "groupBy": "NO_GROUP_BY",
        }

        r0 = self._request_raw("POST", "/api/client/statistics", headers=headers, json_body=submit_body, timeout=60)
        dbg = {
            "submit_status": r0.status_code,
            "submit_text": (r0.text or "")[:500],
            "campaigns_count": len(ids),
        }
        if r0.status_code >= 300:
            return {}, {**dbg, "error": f"submit failed: {r0.status_code}"}

        try:
            js = r0.json()
        except Exception:
            return {}, {**dbg, "error": "submit not json"}

        uuid = js.get("UUID") or js.get("uuid") or js.get("result") or js.get("id")
        dbg["uuid"] = uuid
        if not uuid:
            return {}, {**dbg, "error": f"no uuid in response: {js}"}

        # 2) poll status (—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –≤ –¥–æ–∫–µ –∏–Ω–æ–≥–¥–∞ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è ‚Äî –¥–µ–ª–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫)
        # –≤–∞—Ä–∏–∞–Ω—Ç—ã: /api/client/statistics/state?UUID=..., /api/client/statistics/{uuid}, /api/client/statistics/status?UUID=...
        status_variants = [
            ("/api/client/statistics/state", {"UUID": uuid}),
            (f"/api/client/statistics/{uuid}", None),
            ("/api/client/statistics/status", {"UUID": uuid}),
        ]

        state = None
        for _ in range(30):  # –¥–æ ~30*2—Å–µ–∫ = 60 —Å–µ–∫
            time.sleep(2)
            got = None
            got_dbg = []
            for path, params in status_variants:
                rr = self._request_raw("GET", path, headers=headers, params=params, timeout=30)
                got_dbg.append({"path": path, "code": rr.status_code, "text": (rr.text or "")[:200]})
                if rr.status_code < 300:
                    # –ø—Ä–æ–±—É–µ–º json
                    try:
                        got = rr.json()
                        break
                    except Exception:
                        # –∏–Ω–æ–≥–¥–∞ —Å—Ç–∞—Ç—É—Å –º–æ–∂–µ—Ç –±—ã—Ç—å plain text
                        got = {"raw": rr.text}
                        break
            dbg["status_checks"] = got_dbg
            if got is None:
                continue

            # –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è —Å—Ç–∞—Ç—É—Å–∞
            state = got.get("state") or got.get("status") or got.get("State") or got.get("Status") or got.get("raw")
            dbg["state_last"] = state

            s = str(state).lower()
            if any(x in s for x in ("ok", "done", "success", "ready", "completed", "–≥–æ—Ç–æ–≤")):
                break
            if any(x in s for x in ("error", "failed", "fail", "–æ—à–∏–±")):
                return {}, {**dbg, "error": f"report failed state={state}"}

        # 3) download report (—Ç–æ–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤)
        download_variants = [
            ("/api/client/statistics/report", {"UUID": uuid}),
            ("/api/client/statistics/download", {"UUID": uuid}),
            (f"/api/client/statistics/{uuid}/report", None),
            (f"/api/client/statistics/{uuid}/download", None),
        ]

        blob = None
        dl_dbg = []
        for path, params in download_variants:
            rr = self._request_raw("GET", path, headers=headers, params=params, timeout=120)
            dl_dbg.append({"path": path, "code": rr.status_code, "ct": rr.headers.get("Content-Type", ""), "len": len(rr.content or b"")})
            if rr.status_code < 300 and rr.content:
                blob = rr.content
                dbg["download_used"] = path
                dbg["download_ct"] = rr.headers.get("Content-Type", "")
                break
        dbg["download_attempts"] = dl_dbg

        if not blob:
            return {}, {**dbg, "error": "download failed (no blob)"}

        # 4) parse (ZIP or CSV)
        spend_map: dict[int, float] = {}

        is_zip = False
        ct = (dbg.get("download_ct") or "").lower()
        if "zip" in ct:
            is_zip = True
        if blob[:2] == b"PK":
            is_zip = True

        if is_zip:
            try:
                with zipfile.ZipFile(io.BytesIO(blob), "r") as z:
                    names = [n for n in z.namelist() if n.lower().endswith(".csv")]
                    dbg["zip_files"] = names[:30]
                    for n in names:
                        raw = z.read(n)
                        df = self._read_csv_any(raw)
                        part = self._extract_spend_map_from_df(df)
                        for k, v in part.items():
                            spend_map[k] = spend_map.get(k, 0.0) + float(v)
            except Exception as e:
                return {}, {**dbg, "error": f"zip parse failed: {e}"}
        else:
            try:
                df = self._read_csv_any(blob)
                dbg["csv_cols"] = df.columns.tolist()
                part = self._extract_spend_map_from_df(df)
                spend_map.update(part)
            except Exception as e:
                return {}, {**dbg, "error": f"csv parse failed: {e}"}

        dbg["spend_map_size"] = len(spend_map)
        dbg["spend_map_sample"] = list(spend_map.items())[:20]

        return spend_map, dbg

    def fetch_shop_summary(self, date_from_str: str, date_to_str: str) -> tuple[dict, str, dict]:
        base = {"spent": 0.0, "revenue": 0.0, "orders": 0, "drr": 0.0, "cpc": 0.0, "ctr": 0.0}

        try:
            d1 = self._safe_date10(date_from_str)
            d2 = self._safe_date10(date_to_str)
            if not d1 or not d2:
                return base, "Performance API: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –ø–µ—Ä–∏–æ–¥–∞.", {"error": "bad dates"}

            # ids –∫–∞–∫ —Ä–∞–Ω—å—à–µ
            ids = self.campaign_ids_overlapping(date_from_str, date_to_str, limit=300)

            totals = {
                "spent": 0.0,
                "revenue": 0.0,
                "orders": 0,
                "clicks": 0.0,
                "shows": 0.0,
            }

            chunks_info = []
            errors = []

            for a, b in self._iter_chunks(d1, d2, max_days=62):
                a_s = a.strftime("%Y-%m-%d")
                b_s = b.strftime("%Y-%m-%d")

                try:
                    m, dbg = self.fetch_statistics_daily(a_s, b_s, ids)

                    # —Å—É–º–º–∏—Ä—É–µ–º "—Å—ã—Ä—ã–µ" –∏—Ç–æ–≥–∏
                    totals["spent"] += float(m.get("spent", 0.0))
                    totals["revenue"] += float(m.get("revenue", 0.0))
                    totals["orders"] += int(m.get("orders", 0) or 0)

                    # clicks/shows –±–µ—Ä–µ–º –∏–∑ dbg? —É –Ω–∞—Å –æ–Ω–∏ –≤ metrics —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω—ã —Ç–æ–ª—å–∫–æ –∫–∞–∫ cpc/ctr,
                    # –ø–æ—ç—Ç–æ–º—É –ª—É—á—à–µ –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –≤–Ω—É—Ç—Ä–∏ fetch_statistics_daily –∏ –≤–µ—Ä–Ω—É—Ç—å clicks/shows —Ç–æ–∂–µ.
                    # –ù–æ —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å, –∏–∑–≤–ª–µ—á—ë–º –∏–∑ df —á–µ—Ä–µ–∑ dbg –Ω–µ–ª—å–∑—è.
                    # => –†–µ—à–µ–Ω–∏–µ: –î–û–ë–ê–í–ò –≤ metrics –Ω–∏–∂–µ clicks/shows. (—Å–º. –º–∏–Ω–∏-–ø—Ä–∞–≤–∫—É ‚Ññ2.1)
                    totals["clicks"] += float(m.get("clicks", 0.0))
                    totals["shows"] += float(m.get("shows", 0.0))

                    chunks_info.append({"from": a_s, "to": b_s, "rows": int(dbg.get("rows_count", 0))})
                except Exception as e:
                    errors.append({"from": a_s, "to": b_s, "error": str(e)})

            # –µ—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–º–æ–≥–ª–∏ –ø–æ–ª—É—á–∏—Ç—å
            if totals["spent"] == 0 and totals["revenue"] == 0 and totals["orders"] == 0 and not chunks_info:
                note = self._humanize_error(errors[0]["error"]) if errors else "Performance API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
                dbg = {"error": "all chunks failed", "errors": errors, "chunks": chunks_info}
                self._last_debug = dbg
                return base, note, dbg

            # –ø–µ—Ä–µ—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –æ—Ç –∏—Ç–æ–≥–æ–≤
            spent = totals["spent"]
            revenue = totals["revenue"]
            orders = totals["orders"]
            clicks = totals["clicks"]
            shows = totals["shows"]

            drr = (spent / revenue * 100.0) if revenue else 0.0
            cpc = (spent / clicks) if clicks else 0.0
            ctr = (clicks / shows * 100.0) if shows else 0.0

            metrics = {"spent": spent, "revenue": revenue, "orders": orders, "drr": drr, "cpc": cpc, "ctr": ctr}

            note = ""
            if (d2 - d1).days + 1 > 62:
                note = f"Performance: –ø–µ—Ä–∏–æ–¥ –±–æ–ª—å—à–µ 62 –¥–Ω–µ–π ‚Äî –ø–æ—Å—á–∏—Ç–∞–Ω–æ —á–∞–Ω–∫–∞–º–∏ ({len(chunks_info)} –∑–∞–ø—Ä–æ—Å–æ–≤)."
            if errors:
                note = (note + "\n" if note else "") + f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å {len(errors)} —á–∞–Ω–∫–æ–≤ ‚Äî –∏—Ç–æ–≥ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º."

            dbg = {
                "campaign_ids_count": len(ids),
                "campaign_ids_sample": ids[:50],
                "chunks": chunks_info,
                "errors": errors,
                "dateFrom": date_from_str,
                "dateTo": date_to_str,
            }
            self._last_debug = dbg

            return metrics, note, dbg

        except Exception as e:
            msg = str(e)
            note = self._humanize_error(msg)
            dbg = {"error": msg}
            self._last_debug = dbg
            return base, note, dbg


perf_id = _get_setting("PERF_CLIENT_ID", "")
perf_secret = _get_setting("PERF_CLIENT_SECRET", "")
perf_client: OzonPerfClient | None = None
if perf_id and perf_secret:
    try:
        perf_client = OzonPerfClient(perf_id, perf_secret)
    except Exception:
        perf_client = None

st.title("–û—Ü–∏—Ñ—Ä–æ–≤–∫–∞ Ozon")

# ================== GLOBAL STYLES ==================
st.markdown(
    """
<style>
div[data-testid="stDateInput"] small { display: none !important; }

.ts-tile{
  border-radius: 14px;
  padding: 14px 16px 12px 16px;
  border: 2px solid rgba(0,0,0,0.2);
  background: rgba(255,255,255,0.06);
  min-height: 108px;
}
.ts-title{ font-size: 13px; opacity: 0.9; margin-bottom: 6px; }
.ts-value{ font-size: 26px; font-weight: 800; line-height: 1.05; }
.ts-delta{ margin-top: 6px; font-size: 13px; font-weight: 700; opacity: 0.95; }

.ts-good{ background: rgba(34,197,94,0.18); border-color: rgba(34,197,94,0.60); }
.ts-good .ts-delta{ color: rgba(34,197,94,1); }

.ts-bad{ background: rgba(239,68,68,0.18); border-color: rgba(239,68,68,0.60); }
.ts-bad .ts-delta{ color: rgba(239,68,68,1); }

.ts-neutral{ background: rgba(148,163,184,0.12); border-color: rgba(148,163,184,0.40); }
.ts-neutral .ts-delta{ color: rgba(148,163,184,1); }

@media (max-width: 900px){
  .ts-value{ font-size: 22px; }
  .ts-tile{ min-height: 98px; }
}
</style>
""",
    unsafe_allow_html=True,
)

st.markdown("""
<style>
/* –î–µ–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç/placeholder –≤ input –≤–∏–∑—É–∞–ª—å–Ω–æ –ø–æ —Ü–µ–Ω—Ç—Ä—É (–∑–∞ —Å—á—ë—Ç padding/line-height) */
div[data-testid="stTextInput"] input {
  padding-top: 0.55rem !important;
  padding-bottom: 0.55rem !important;
  line-height: 1.2 !important;
}

/* –ß—É—Ç—å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º selectbox, —á—Ç–æ–±—ã –æ–Ω –≤—ã–≥–ª—è–¥–µ–ª –∫–∞–∫ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è */
div[data-testid="stSelectbox"] div[role="combobox"] {
  padding-top: 0.45rem !important;
  padding-bottom: 0.45rem !important;
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* ===== OPEX: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω–ø—É—Ç—ã –≤ —Å—Ç—Ä–æ–∫–µ "–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥" ===== */

/* –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–ª–æ–Ω–æ–∫ –ø–æ –Ω–∏–∑—É */
div[data-testid="stHorizontalBlock"]{
  align-items: flex-end;
}

/* –¥–µ–ª–∞–µ–º –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –≤—ã—Å–æ—Ç—É –ø–æ–ª–µ–π –≤–≤–æ–¥–∞ (date/text/number) */
div[data-testid="stDateInput"] input,
div[data-testid="stTextInput"] input,
div[data-testid="stNumberInput"] input{
  height: 44px !important;
  line-height: 44px !important;
  padding-top: 0 !important;
  padding-bottom: 0 !important;
}

/* st_tags (baseweb tag input) ‚Äî —á—Ç–æ–±—ã –±—ã–ª —Ç–æ–π –∂–µ –≤—ã—Å–æ—Ç—ã */
div[data-baseweb="tag-input"]{
  min-height: 44px !important;
  align-items: center !important;
}
div[data-baseweb="tag-input"] > div{
  min-height: 44px !important;
  align-items: center !important;
}

/* –∫–Ω–æ–ø–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è ‚Äî –≤ —Ç—É –∂–µ –≤—ã—Å–æ—Ç—É */
button[kind="secondary"], button[kind="primary"]{
  height: 44px !important;
}
</style>
""", unsafe_allow_html=True)

# ================== HELPERS ==================
def money(x) -> str:
    try:
        return f"{float(x):,.0f} ‚ÇΩ".replace(",", " ")
    except Exception:
        return "0 ‚ÇΩ"

def _to_float(x):
    try:
        return float(x)
    except Exception:
        return 0.0

def _to_int(x):
    try:
        return int(float(x))
    except Exception:
        return 0

def to_cost(x: float) -> float:
    x = float(x or 0.0)
    return abs(x)

DATA_DIR = "data"
COGS_PATH = os.path.join(DATA_DIR, "cogs.csv")
OPEX_PATH = os.path.join(DATA_DIR, "opex.csv")
OPEX_TYPES_PATH = os.path.join(DATA_DIR, "opex_types.json")

def load_opex_types() -> list[str]:
    ensure_data_dir()
    if os.path.exists(OPEX_TYPES_PATH):
        try:
            with open(OPEX_TYPES_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            if isinstance(data, list):
                out = []
                for x in data:
                    s = str(x).strip()
                    if s:
                        out.append(s)
                return sorted(set(out), key=lambda s: s.lower())
        except Exception:
            pass
    return []

def save_opex_types(types: list[str]):
    ensure_data_dir()
    out = []
    for x in (types or []):
        s = str(x).strip()
        if s:
            out.append(s)
    out = sorted(set(out), key=lambda s: s.lower())
    with open(OPEX_TYPES_PATH, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)


def ensure_data_dir():
    os.makedirs(DATA_DIR, exist_ok=True)

# ================== COGS ==================
def normalize_cogs_upload(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame(columns=["article", "sku", "cogs"])

    df2 = df.copy()
    df2.columns = [str(c).strip() for c in df2.columns]

    sku_candidates = [c for c in df2.columns if c.lower() in ("sku", "item.sku", "–æ–∑–æ–Ω sku", "ozon sku")]
    if not sku_candidates:
        sku_candidates = [c for c in df2.columns if "sku" in c.lower()]
    sku_col = sku_candidates[0] if sku_candidates else None

    cogs_candidates = [c for c in df2.columns if c.lower() in ("—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Å–µ–±–µ—Å", "cogs", "cost", "cost_price", "costprice")]
    if not cogs_candidates:
        cogs_candidates = [c for c in df2.columns if "—Å–µ–±" in c.lower() or "cost" in c.lower()]
    cogs_col = cogs_candidates[0] if cogs_candidates else None

    art_candidates = [c for c in df2.columns if "–∞—Ä—Ç–∏–∫—É–ª" in c.lower() or "offer" in c.lower() or "article" in c.lower()]
    art_col = art_candidates[0] if art_candidates else None

    if sku_col is None or cogs_col is None:
        if df2.shape[1] >= 3:
            art_col = art_col or df2.columns[0]
            sku_col = sku_col or df2.columns[1]
            cogs_col = cogs_col or df2.columns[2]
        else:
            return pd.DataFrame(columns=["article", "sku", "cogs"])

    out = pd.DataFrame({
        "article": df2[art_col] if art_col in df2.columns else "",
        "sku": df2[sku_col],
        "cogs": df2[cogs_col],
    })

    out["sku"] = (
    out["sku"]
    .astype(str)
    .str.replace(r"[^\d]", "", regex=True)   # —É–±–∏—Ä–∞–µ–º –∑–∞–ø—è—Ç—ã–µ/–ø—Ä–æ–±–µ–ª—ã/–º—É—Å–æ—Ä
    )
    out["sku"] = pd.to_numeric(out["sku"], errors="coerce").astype("Int64")
    out["cogs"] = pd.to_numeric(out["cogs"], errors="coerce").fillna(0.0)
    out = out.dropna(subset=["sku"]).copy()
    out["sku"] = out["sku"].astype(int)
    out["article"] = out["article"].astype(str).fillna("")
    out = out[["article", "sku", "cogs"]].drop_duplicates(subset=["sku"], keep="last").sort_values("sku")
    return out

def load_cogs() -> pd.DataFrame:
    ensure_data_dir()
    # 1) Supabase –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–µ–µ
    if USE_SUPABASE:
        try:
            df = _sb_fetch("cogs", select="sku,article,cogs", limit=100000)
            if not df.empty:
                df.columns = [str(c).strip() for c in df.columns]
                if "article" not in df.columns:
                    df["article"] = ""
                df["sku"] = pd.to_numeric(df["sku"], errors="coerce").astype("Int64")
                df["cogs"] = pd.to_numeric(df["cogs"], errors="coerce").fillna(0.0)
                df = df.dropna(subset=["sku"]).copy()
                df["sku"] = df["sku"].astype(int)
                df["article"] = df["article"].fillna("").astype(str)
                df = df[["article","sku","cogs"]].drop_duplicates(subset=["sku"], keep="last").sort_values("sku")
                return df
        except Exception:
            pass
    if os.path.exists(COGS_PATH):
        try:
            df = pd.read_csv(COGS_PATH, encoding="utf-8-sig")
            df.columns = [str(c).strip() for c in df.columns]
            if "sku" not in df.columns or "cogs" not in df.columns:
                df = normalize_cogs_upload(df)
            else:
                if "article" not in df.columns:
                    df["article"] = ""
                df["sku"] = (
                    df["sku"]
                    .astype(str)
                    .str.replace(r"[^\d]", "", regex=True)
                )
                df["sku"] = pd.to_numeric(df["sku"], errors="coerce").astype("Int64")
                df["cogs"] = pd.to_numeric(df["cogs"], errors="coerce").fillna(0.0)
                df = df.dropna(subset=["sku"]).copy()
                df["sku"] = df["sku"].astype(int)
                df["article"] = df["article"].astype(str).fillna("")
                df = df[["article", "sku", "cogs"]].drop_duplicates(subset=["sku"], keep="last").sort_values("sku")
            return df
        except Exception:
            return pd.DataFrame(columns=["article", "sku", "cogs"])
    return pd.DataFrame(columns=["article", "sku", "cogs"])

def save_cogs(df: pd.DataFrame):
    ensure_data_dir()
    df2 = df.copy() if df is not None else pd.DataFrame(columns=["article","sku","cogs"])
    if "article" not in df2.columns:
        df2["article"] = ""
    if "cogs" not in df2.columns:
        df2["cogs"] = 0.0

    df2 = df2[["article", "sku", "cogs"]].copy()
    df2["sku"] = pd.to_numeric(df2["sku"], errors="coerce").astype("Int64")
    df2["cogs"] = pd.to_numeric(df2["cogs"], errors="coerce").fillna(0.0)
    df2 = df2.dropna(subset=["sku"]).copy()
    df2["sku"] = df2["sku"].astype(int)
    df2["article"] = df2["article"].astype(str).fillna("")
    df2 = df2.drop_duplicates(subset=["sku"], keep="last").sort_values("sku")

    # 1) Supabase
    if USE_SUPABASE:
        rows = df2[["sku", "article", "cogs"]].copy()
        payload = rows.to_dict(orient="records")
        _sb_replace_all("cogs", payload, "sku=gt.0")

    # 2) –õ–æ–∫–∞–ª—å–Ω–æ (fallback)
    df2.to_csv(COGS_PATH, index=False, encoding="utf-8-sig")


# ================== OPEX (Operational expenses) ==================
def _opex_empty() -> pd.DataFrame:
    return pd.DataFrame(columns=["date", "type", "amount"])

def load_opex() -> pd.DataFrame:
    ensure_data_dir()
    if os.path.exists(OPEX_PATH):
        try:
            df = pd.read_csv(OPEX_PATH, encoding="utf-8-sig")
            df.columns = [str(c).strip().lower() for c in df.columns]
            # –æ–∂–∏–¥–∞–µ–º: date, type, amount
            if "date" not in df.columns:
                # –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
                if "–¥–∞—Ç–∞" in df.columns:
                    df = df.rename(columns={"–¥–∞—Ç–∞": "date"})
            if "type" not in df.columns:
                for c in df.columns:
                    if "—Ç–∏–ø" in c or "category" in c:
                        df = df.rename(columns={c: "type"})
                        break
            if "amount" not in df.columns:
                for c in df.columns:
                    if "—Å—É–º–º" in c or "amount" in c:
                        df = df.rename(columns={c: "amount"})
                        break
            if not {"date","type","amount"}.issubset(set(df.columns)):
                return _opex_empty()
            df = df[["date","type","amount"]].copy()
            df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
            df["type"] = df["type"].fillna("").astype(str)
            df["amount"] = pd.to_numeric(df["amount"], errors="coerce").fillna(0.0)
            df = df.dropna(subset=["date"]).sort_values(["date","type"]).reset_index(drop=True)
            return df
        except Exception:
            return _opex_empty()
    return _opex_empty()

def save_opex(df: pd.DataFrame):
    ensure_data_dir()

    df2 = df.copy() if df is not None else _opex_empty()
    if df2.empty:
        df2 = _opex_empty()

    df2 = df2[["date","type","amount"]].copy()
    df2["date"] = pd.to_datetime(df2["date"], errors="coerce").dt.date
    df2["type"] = df2["type"].fillna("").astype(str)
    df2["amount"] = pd.to_numeric(df2["amount"], errors="coerce").fillna(0.0)
    df2 = df2.dropna(subset=["date"]).sort_values(["date","type"]).reset_index(drop=True)

    # 1) Supabase
    if USE_SUPABASE:
        rows = df2.copy()
        rows["date"] = pd.to_datetime(rows["date"], errors="coerce").dt.strftime("%Y-%m-%d")
        payload = rows.to_dict(orient="records")
        _sb_replace_all("opex", payload, "id=gt.0")

    # 2) –õ–æ–∫–∞–ª—å–Ω–æ
    out = df2.copy()
    out["date"] = out["date"].apply(lambda d: d.strftime("%Y-%m-%d") if hasattr(d, "strftime") else str(d))
    out.to_csv(OPEX_PATH, index=False, encoding="utf-8-sig")

def opex_sum_period(df_opex: pd.DataFrame, d_from: date, d_to: date) -> float:
    if df_opex is None or df_opex.empty:
        return 0.0
    mask = (df_opex["date"] >= d_from) & (df_opex["date"] <= d_to)
    return float(pd.to_numeric(df_opex.loc[mask, "amount"], errors="coerce").fillna(0.0).sum())


# --- Sidebar COGS ---
st.sidebar.header("–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (COGS)")
ensure_data_dir()

uploaded = st.sidebar.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ (–ê—Ä—Ç–∏–∫—É–ª / SKU / –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å)",
    type=["csv", "xlsx", "xls"],
    accept_multiple_files=False
)

# --- –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê SUPABASE (–≤—Ä–µ–º–µ–Ω–Ω–æ) ---
if USE_SUPABASE:
    st.sidebar.write("SUPABASE ON ‚úÖ")
else:
    st.sidebar.write("SUPABASE OFF ‚ùå (–Ω–µ—Ç SUPABASE_URL –∏–ª–∏ SUPABASE_SERVICE_ROLE_KEY)")

cogs_df = load_cogs()
df_opex = load_opex()

if uploaded is not None:
    try:
        if uploaded.name.lower().endswith(".csv"):
            tmp = pd.read_csv(uploaded, encoding="utf-8-sig")
        else:
            tmp = pd.read_excel(uploaded)

        cogs_df = normalize_cogs_upload(tmp)
        save_cogs(cogs_df)

        st.sidebar.success("–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
    except Exception as e:
        st.sidebar.error(f"–ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

# ================== OPS -> DF ==================
def ops_to_df(ops: list[dict]) -> pd.DataFrame:
    rows = []
    for op in ops:
        op_id = op.get("operation_id")
        op_group = op.get("type", "")
        op_code = op.get("operation_type", "")
        op_type_name = op.get("operation_type_name", "") or op_code
        op_date = op.get("operation_date", "")

        accruals_total = _to_float(op.get("accruals_for_sale", 0))
        commission_total = _to_float(op.get("sale_commission", 0))
        amount_total = _to_float(op.get("amount", 0))

        posting = op.get("posting") or {}
        posting_number = posting.get("posting_number", "")
        delivery_schema = posting.get("delivery_schema", "")

        items = op.get("items") or []
        services = op.get("services") or []
        services_sum_total = sum(_to_float(s.get("price", 0)) for s in services)

        base = {
            "operation_id": op_id,
            "operation_date": op_date,
            "type": op_group,
            "operation_type": op_code,
            "type_name": op_type_name,
            "posting_number": posting_number,
            "delivery_schema": delivery_schema,
        }

        if not items:
            rows.append({
                **base,
                "sku": None,
                "name": None,
                "qty": 0.0,
                "accruals_for_sale": accruals_total,
                "sale_commission": commission_total,
                "services_sum": services_sum_total,
                "amount": amount_total,
            })
            continue

        qtys = [max(_to_float(it.get("quantity", 1)), 0.0) for it in items]
        total_qty = sum(qtys) if qtys else 0.0
        if total_qty <= 0:
            total_qty = float(len(items))
            qtys = [1.0] * len(items)

        for it, q in zip(items, qtys):
            w = q / total_qty if total_qty else 0.0
            rows.append({
                **base,
                "sku": it.get("sku"),
                "name": it.get("name"),
                "qty": q,
                "accruals_for_sale": accruals_total * w,
                "sale_commission": commission_total * w,
                "services_sum": services_sum_total * w,
                "amount": amount_total * w,
            })

    df = pd.DataFrame(rows)
    for c in ["accruals_for_sale", "sale_commission", "services_sum", "amount", "qty"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)
    return df

# ================== MONTH-SAFE CHUNK LOADER ==================
def month_safe_chunks(d_from: date, d_to: date):
    cur = d_from
    while cur <= d_to:
        if cur.month == 12:
            next_month_start = date(cur.year + 1, 1, 1)
        else:
            next_month_start = date(cur.year, cur.month + 1, 1)
        month_end = next_month_start - timedelta(days=1)
        chunk_to = min(month_end, d_to)
        yield cur, chunk_to
        cur = chunk_to + timedelta(days=1)

@st.cache_data(ttl=600)
def load_ops_range(date_from_str: str, date_to_str: str) -> list[dict]:
    d1 = datetime.strptime(date_from_str, "%Y-%m-%d").date()
    d2 = datetime.strptime(date_to_str, "%Y-%m-%d").date()

    ops_all = []
    for a, b in month_safe_chunks(d1, d2):
        ops_part = client.fetch_finance_transactions(a.strftime("%Y-%m-%d"), b.strftime("%Y-%m-%d"))
        ops_all.extend(ops_part)
    return ops_all

@st.cache_data(ttl=600)
def load_ads_summary(date_from_str: str, date_to_str: str) -> dict:
    base = {"spent": 0.0, "revenue": 0.0, "orders": 0, "drr": 0.0, "cpc": 0.0, "ctr": 0.0, "_note": "", "_debug": {}}

    if perf_client is None:
        base["_note"] = "Performance: PERF_CLIENT_ID / PERF_CLIENT_SECRET –Ω–µ –∑–∞–¥–∞–Ω—ã."
        return base

    metrics, note, dbg = perf_client.fetch_shop_summary(date_from_str, date_to_str)
    out = {**metrics, "_note": note, "_debug": dbg}
    return out
    
@st.cache_data(ttl=3600)
def load_ads_spend_by_sku(date_from_str: str, date_to_str: str) -> dict:
    if perf_client is None:
        return {}
    try:
        return perf_client.fetch_ads_spend_by_sku(date_from_str, date_to_str)
    except Exception:
        return {}
# ================== SOLD SKU TABLE ==================
def build_sold_sku_table(df_ops: pd.DataFrame, cogs_df_local: pd.DataFrame) -> pd.DataFrame:
    sku_df = df_ops[df_ops["sku"].notna()].copy()
    if sku_df.empty:
        return pd.DataFrame()

    sku_df["sku"] = pd.to_numeric(sku_df["sku"], errors="coerce").astype("Int64")
    sku_df = sku_df.dropna(subset=["sku"]).copy()
    sku_df["sku"] = sku_df["sku"].astype(int)

    sku_df["commission_cost"] = (-sku_df["sale_commission"]).clip(lower=0.0)
    sku_df["services_cost"] = (-sku_df["services_sum"]).clip(lower=0.0)

    sku_df["qty_orders"] = sku_df.apply(lambda r: r["qty"] if r["type"] == "orders" else 0.0, axis=1)
    sku_df["qty_returns"] = sku_df.apply(lambda r: r["qty"] if r["type"] == "returns" else 0.0, axis=1)

    g = (
        sku_df.groupby(["sku", "name"], as_index=False, dropna=False)
        .agg(
            qty_orders=("qty_orders", "sum"),
            qty_returns=("qty_returns", "sum"),
            accruals_net=("accruals_for_sale", "sum"),
            amount_net=("amount", "sum"),
            commission=("commission_cost", "sum"),
            logistics=("services_cost", "sum"),
        )
    )

    g["qty_buyout"] = g["qty_orders"] - g["qty_returns"]
    g["sale_costs"] = g["commission"] + g["logistics"]

    if cogs_df_local is None or cogs_df_local.empty:
        g["article"] = ""
        g["cogs_unit"] = 0.0
    else:
        c2 = cogs_df_local.copy()
        c2["sku"] = pd.to_numeric(c2["sku"], errors="coerce").astype("Int64")
        c2 = c2.dropna(subset=["sku"]).copy()
        c2["sku"] = c2["sku"].astype(int)
        if "article" not in c2.columns:
            c2["article"] = ""
        if "cogs" not in c2.columns:
            c2["cogs"] = 0.0
        c2["cogs"] = pd.to_numeric(c2["cogs"], errors="coerce").fillna(0.0)
        c2 = c2[["sku", "article", "cogs"]].drop_duplicates(subset=["sku"], keep="last")
        g = g.merge(c2.rename(columns={"cogs": "cogs_unit"}), how="left", on="sku")
        g["article"] = g["article"].fillna("").astype(str)
        g["cogs_unit"] = pd.to_numeric(g["cogs_unit"], errors="coerce").fillna(0.0)


    # --- –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ ---
    try:
        known = g[(g["article"].astype(str).str.strip() != "") & g["name"].notna()].copy()
        if not known.empty:
            name_to_article = (
                known.assign(_a=known["article"].astype(str).str.strip())
                .groupby("name")["_a"]
                .agg(lambda s: s.value_counts().index[0])
            )
            mask_empty = g["article"].astype(str).str.strip() == ""
            g.loc[mask_empty, "article"] = (
                g.loc[mask_empty, "name"]
                .map(name_to_article)
                .apply(lambda a: f"–î—É–±–ª—å ({a})" if isinstance(a, str) and a.strip() else "")
            )
    except Exception:
        pass
    g["article"] = g["article"].fillna("").astype(str)

    g["cogs_total"] = (g["qty_buyout"].clip(lower=0.0) * g["cogs_unit"]).fillna(0.0)
    g = g.sort_values("accruals_net", ascending=False)
    return g

def allocate_tax_by_share(sku_table: pd.DataFrame, total_tax: float) -> pd.DataFrame:
    out = sku_table.copy()
    total_sales = out["accruals_net"].sum()
    out["tax_total"] = (out["accruals_net"] / total_sales) * float(total_tax) if total_sales and total_tax else 0.0
    return out

def allocate_cost_by_share(sku_table: pd.DataFrame, total_cost: float, out_col: str) -> pd.DataFrame:
    out = sku_table.copy()
    total_sales = float(out["accruals_net"].sum()) if "accruals_net" in out.columns else 0.0
    if total_sales and total_cost:
        out[out_col] = (out["accruals_net"] / total_sales) * float(total_cost)
    else:
        out[out_col] = 0.0
    return out


def compute_profitability(sku_table: pd.DataFrame) -> pd.DataFrame:
    out = sku_table.copy()

    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏
    for c in ["accruals_net", "sale_costs", "cogs_total", "tax_total", "qty_buyout", "cogs_unit"]:
        if c not in out.columns:
            out[c] = 0.0

    for c in ["ads_total", "opex_total"]:
        if c not in out.columns:
            out[c] = 0.0

    # –ø—Ä–∏–±—ã–ª—å –ø–æ –Ω–æ–≤–æ–π —Ñ–æ—Ä–º—É–ª–µ:
    # –í—ã—Ä—É—á–∫–∞ ‚àí –†–∞—Å—Ö–æ–¥—ã Ozon ‚àí –†–µ–∫–ª–∞–º–∞ ‚àí –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å ‚àí –ù–∞–ª–æ–≥ ‚àí –û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã
    out["profit"] = (
        pd.to_numeric(out["accruals_net"], errors="coerce").fillna(0.0)
        - pd.to_numeric(out["sale_costs"], errors="coerce").fillna(0.0)
        - pd.to_numeric(out.get("ads_total", 0.0), errors="coerce").fillna(0.0)
        - pd.to_numeric(out["cogs_total"], errors="coerce").fillna(0.0)
        - pd.to_numeric(out.get("tax_total", 0.0), errors="coerce").fillna(0.0)
        - pd.to_numeric(out.get("opex_total", 0.0), errors="coerce").fillna(0.0)
    )

    out["profit_per_unit"] = out.apply(
        lambda r: (float(r["profit"]) / float(r["qty_buyout"])) if float(r.get("qty_buyout", 0) or 0) > 0 else 0.0,
        axis=1,
    )

    out["margin_%"] = out.apply(
        lambda r: (float(r["profit"]) / float(r["accruals_net"]) * 100.0) if float(r.get("accruals_net", 0) or 0) else 0.0,
        axis=1,
    )

    # ROI –ø–æ –¢–ó: (–ü—Ä–∏–±—ã–ª—å –Ω–∞ 1 —à—Ç) / (–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç)
    out["roi_%"] = out.apply(
        lambda r: (float(r["profit_per_unit"]) / float(r.get("cogs_unit", 0) or 0) * 100.0) if float(r.get("cogs_unit", 0) or 0) > 0 else 0.0,
        axis=1,
    )

    return out

def export_soldsku_xlsx(df: pd.DataFrame) -> bytes:
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as w:
        df.to_excel(w, index=False, sheet_name="SoldSKU")
    return bio.getvalue()

# ================== TILE LOGIC ==================
def _delta_pct(cur, prev):
    prev = float(prev)
    cur = float(cur)
    if prev == 0:
        return None
    return (cur - prev) / abs(prev) * 100.0

def _tile_class(delta, is_expense: bool, good_when_up: bool = False):
    if delta is None:
        return "ts-neutral", "‚Äî"
    arrow = "‚ñ≤" if delta > 0 else "‚ñº"
    txt = f"{arrow} {delta:+.1f}%"
    if is_expense:
        if good_when_up:
            return ("ts-good" if delta > 0 else "ts-bad"), txt
        return ("ts-good" if delta < 0 else "ts-bad"), txt
    return ("ts-good" if delta > 0 else "ts-bad"), txt

def render_tiles(tiles: list[dict], cols_per_row: int = 4, row_gap_px: int = 16):
    for i in range(0, len(tiles), cols_per_row):
        row = tiles[i:i + cols_per_row]
        cols = st.columns(cols_per_row)
        for c, t in zip(cols, row):
            klass, delta_txt = _tile_class(t.get("delta"), t.get("is_expense", False), t.get("good_when_up", False))
            c.markdown(
                f"""
<div class="ts-tile {klass}">
  <div class="ts-title">{t.get("title","")}</div>
  <div class="ts-value">{t.get("value","")}</div>
  <div class="ts-delta">{delta_txt}</div>
</div>
""",
                unsafe_allow_html=True
            )
        if i + cols_per_row < len(tiles):
            st.markdown(f"<div style='height:{int(row_gap_px)}px'></div>", unsafe_allow_html=True)

# ================== KPI CORE ==================
STORAGE_FBO_TYPE_NAMES = {"–£—Å–ª—É–≥–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ"}

def calc_kpi(df_ops_local: pd.DataFrame, sold_local: pd.DataFrame):
    total_amount = df_ops_local["amount"].sum() if not df_ops_local.empty else 0.0
    sales_net = float(sold_local["accruals_net"].sum()) if sold_local is not None and not sold_local.empty else 0.0

    sum_sale_commission = df_ops_local["sale_commission"].sum() if not df_ops_local.empty else 0.0
    commission_cost = max(0.0, -float(sum_sale_commission))

    over_local = df_ops_local[df_ops_local["sku"].isna()].copy() if not df_ops_local.empty else pd.DataFrame(columns=["type_name", "amount"])
    storage_fbo_raw = 0.0
    if not over_local.empty:
        storage_fbo_raw = over_local[over_local["type_name"].astype(str).isin(STORAGE_FBO_TYPE_NAMES)]["amount"].sum()
    storage_fbo = to_cost(storage_fbo_raw)

    if sold_local is None or sold_local.empty:
        qty_orders = 0
        qty_returns = 0
        buyout_pct = 0.0
        total_tax = 0.0
        total_cogs = 0.0
        sale_costs = 0.0
    else:
        qty_orders = _to_int(sold_local["qty_orders"].sum())
        qty_returns = _to_int(sold_local["qty_returns"].sum())
        buyout_pct = ((qty_orders - qty_returns) / qty_orders * 100.0) if qty_orders else 0.0

        total_tax = float(sales_net) * 0.06

        tmp = allocate_tax_by_share(sold_local, total_tax)
        tmp = compute_profitability(tmp)
        total_cogs = float(tmp["cogs_total"].sum())
        sale_costs = float(sold_local["sale_costs"].sum())

    net_profit = float(total_amount) - float(total_cogs) - float(total_tax)
    profit_pct = (net_profit / sales_net * 100.0) if sales_net else 0.0

    return {
        "sales_net": float(sales_net),
        "qty_orders": int(qty_orders),
        "qty_returns": int(qty_returns),
        "buyout_pct": float(buyout_pct),
        "storage_fbo": float(storage_fbo),
        "sale_costs": float(to_cost(sale_costs)),
        "cogs": float(to_cost(total_cogs)),
        "tax": float(to_cost(total_tax)),
        "commission_cost": float(to_cost(commission_cost)),
        "amount_total": float(total_amount),
        "net_profit": float(net_profit),
        "profit_pct": float(profit_pct),
    }

def month_name_ru(m: int) -> str:
    names = ["", "–Ø–Ω–≤–∞—Ä—å","–§–µ–≤—Ä–∞–ª—å","–ú–∞—Ä—Ç","–ê–ø—Ä–µ–ª—å","–ú–∞–π","–ò—é–Ω—å","–ò—é–ª—å","–ê–≤–≥—É—Å—Ç","–°–µ–Ω—Ç—è–±—Ä—å","–û–∫—Ç—è–±—Ä—å","–ù–æ—è–±—Ä—å","–î–µ–∫–∞–±—Ä—å"]
    return names[m] if 1 <= m <= 12 else str(m)

# ================== UI ==================
tab1, tab2, tab3, tab4 = st.tabs(["–û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏", "–°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º", "AB–°-–∞–Ω–∞–ª–∏–∑", "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã"])

# ================== TAB 1 ==================
with tab1:
    st.subheader("–°–≤–æ–¥–∫–∞ –º–∞–≥–∞–∑–∏–Ω–∞ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥")

    today = date.today()
    yesterday = today - timedelta(days=1)

    presets = ["–ü–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π", "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π", "–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π"]
    preset = st.selectbox("–ü–µ—Ä–∏–æ–¥", presets, index=2)

    def compute_range_from_preset(p: str):
        if p == "–ü–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å":
            return (yesterday, yesterday)
        if p == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π":
            return (yesterday - timedelta(days=6), yesterday)
        if p == "–ü–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π":
            return (yesterday - timedelta(days=29), yesterday)
        return (yesterday - timedelta(days=29), yesterday)

    d_from, d_to = compute_range_from_preset(preset)

    if preset == "–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π":
        c1, c2 = st.columns(2)
        with c1:
            d_from = st.date_input("–î–∞—Ç–∞ —Å", value=d_from)
        with c2:
            d_to = st.date_input("–î–∞—Ç–∞ –ø–æ", value=d_to)
    else:
        st.caption(f"–í—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥: {d_from.strftime('%Y-%m-%d')} ‚Äî {d_to.strftime('%Y-%m-%d')}")

    if d_from > d_to:
        st.warning("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –±–æ–ª—å—à–µ –¥–∞—Ç—ã –∫–æ–Ω—Ü–∞ ‚Äî –ø–æ–ø—Ä–∞–≤—å –ø–µ—Ä–∏–æ–¥.")
        st.stop()

    days_len = (d_to - d_from).days + 1
    prev_to = d_from - timedelta(days=1)
    prev_from = prev_to - timedelta(days=days_len - 1)
    st.caption(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥ {prev_from.strftime('%Y-%m-%d')} ‚Äî {prev_to.strftime('%Y-%m-%d')}")

    ops_now = load_ops_range(d_from.strftime("%Y-%m-%d"), d_to.strftime("%Y-%m-%d"))
    df_ops = ops_to_df(ops_now)

    df_ops_prev = pd.DataFrame(columns=df_ops.columns)
    if prev_from <= prev_to:
        ops_prev = load_ops_range(prev_from.strftime("%Y-%m-%d"), prev_to.strftime("%Y-%m-%d"))
        df_ops_prev = ops_to_df(ops_prev)

    sold = build_sold_sku_table(df_ops, cogs_df)
    sold_prev = build_sold_sku_table(df_ops_prev, cogs_df) if not df_ops_prev.empty else pd.DataFrame()

    k = calc_kpi(df_ops, sold)
    k_prev = calc_kpi(df_ops_prev, sold_prev)

    ads_now = load_ads_summary(d_from.strftime("%Y-%m-%d"), d_to.strftime("%Y-%m-%d"))
    ads_prev = load_ads_summary(prev_from.strftime("%Y-%m-%d"), prev_to.strftime("%Y-%m-%d"))
    # ---- ROAS ----
    def calc_roas(ads: dict) -> float:
        spent = float(ads.get("spent", 0) or 0)
        revenue = float(ads.get("revenue", 0) or 0)
        return (revenue / spent) if spent > 0 else 0.0

    roas_now = calc_roas(ads_now)
    roas_prev = calc_roas(ads_prev)


    # ---- OPEX (—Ä—É—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã) ----
    opex_now = opex_sum_period(df_opex, d_from, d_to)
    opex_prev = opex_sum_period(df_opex, prev_from, prev_to)

    # note –æ—Ç Performance –ø–æ–∫–∞–∑—ã–≤–∞–µ–º, –Ω–æ –ù–ï –∑–∞–≤—è–∑—ã–≤–∞–µ–º –Ω–∞ –Ω–µ–≥–æ –ª–æ–≥–∏–∫—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    ads_tiles = []

    # note –º–æ–∂–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ
    if ads_now.get("_note"):
        st.info(ads_now["_note"])

    # ads_tiles —Ñ–æ—Ä–º–∏—Ä—É–µ–º –í–°–ï–ì–î–ê
    ads_tiles = [
        {"title": "–†–∞—Å—Ö–æ–¥ –Ω–∞ —Ä–µ–∫–ª–∞–º—É", "value": money(ads_now.get("spent", 0.0)),
         "delta": _delta_pct(_to_float(ads_now.get("spent", 0.0)), _to_float(ads_prev.get("spent", 0.0))),
         "is_expense": True},

        {"title": "–í—ã—Ä—É—á–∫–∞ —Å —Ä–µ–∫–ª–∞–º—ã", "value": money(ads_now.get("revenue", 0.0)),
         "delta": _delta_pct(_to_float(ads_now.get("revenue", 0.0)), _to_float(ads_prev.get("revenue", 0.0))),
         "is_expense": False},

        {"title": "–ó–∞–∫–∞–∑—ã —Å —Ä–µ–∫–ª–∞–º—ã", "value": f'{_to_int(ads_now.get("orders", 0))} —à—Ç',
         "delta": _delta_pct(_to_float(ads_now.get("orders", 0)), _to_float(ads_prev.get("orders", 0))),
         "is_expense": False},

        {"title": "DRR", "value": f'{_to_float(ads_now.get("drr", 0.0)):.1f}%',
         "delta": _delta_pct(_to_float(ads_now.get("drr", 0.0)), _to_float(ads_prev.get("drr", 0.0))),
         "is_expense": True},

        {"title": "ROAS", "value": f'x{roas_now:.2f}',
         "delta": _delta_pct(roas_now, roas_prev),
         "is_expense": False},

        {"title": "CPC", "value": f'{_to_float(ads_now.get("cpc", 0.0)):.1f} ‚ÇΩ',
         "delta": _delta_pct(_to_float(ads_now.get("cpc", 0.0)), _to_float(ads_prev.get("cpc", 0.0))),
         "is_expense": True},

        {"title": "CTR", "value": f'{_to_float(ads_now.get("ctr", 0.0)):.2f}%',
         "delta": _delta_pct(_to_float(ads_now.get("ctr", 0.0)), _to_float(ads_prev.get("ctr", 0.0))),
         "is_expense": False},
    ]

    sales_tile_value = (
        f'{money(k["sales_net"])} / {k["qty_orders"]} —à—Ç'
        if k["qty_orders"]
        else money(k["sales_net"])
    )

    # --- –ø–µ—Ä–µ—Å—á—ë—Ç KPI –ø–æ –Ω–æ–≤—ã–º —Ñ–æ—Ä–º—É–ª–∞–º (—É—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∫–ª–∞–º—É + –æ–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã) ---
    ads_spent_now = float(ads_now.get("spent", 0.0) or 0.0)
    ads_spent_prev = float(ads_prev.get("spent", 0.0) or 0.0)

    net_profit_now = float(k["sales_net"]) - float(k["sale_costs"]) - ads_spent_now - float(k["cogs"]) - float(k["tax"]) - float(opex_now)
    net_profit_prev = float(k_prev["sales_net"]) - float(k_prev["sale_costs"]) - ads_spent_prev - float(k_prev["cogs"]) - float(k_prev["tax"]) - float(opex_prev)

    margin_now = (net_profit_now / float(k["sales_net"]) * 100.0) if float(k["sales_net"]) else 0.0
    margin_prev = (net_profit_prev / float(k_prev["sales_net"]) * 100.0) if float(k_prev["sales_net"]) else 0.0

    roi_now = (net_profit_now / float(k["cogs"]) * 100.0) if float(k["cogs"]) else 0.0
    roi_prev = (net_profit_prev / float(k_prev["cogs"]) * 100.0) if float(k_prev["cogs"]) else 0.0

    sales_tile_value = f'{money(k["sales_net"])} / {k["qty_orders"]} —à—Ç' if k["qty_orders"] else money(k["sales_net"])
    commission_delta = _delta_pct(k["commission_cost"], k_prev["commission_cost"])

    tiles = [
        {"title": "–ü—Ä–æ–¥–∞–∂–∏", "value": sales_tile_value, "delta": _delta_pct(k["sales_net"], k_prev["sales_net"]), "is_expense": False},
        {"title": "–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å", "value": money(net_profit_now), "delta": _delta_pct(net_profit_now, net_profit_prev), "is_expense": False},
        {"title": "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å", "value": f"{margin_now:.1f}%", "delta": _delta_pct(margin_now, margin_prev), "is_expense": False},
        {"title": "ROI", "value": f"{roi_now:.1f}%", "delta": _delta_pct(roi_now, roi_prev), "is_expense": False},

        {"title": "% –≤—ã–∫—É–ø–∞", "value": f'{k["buyout_pct"]:.1f}%', "delta": _delta_pct(k["buyout_pct"], k_prev["buyout_pct"]), "is_expense": False},
        {"title": "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç", "value": str(k["qty_returns"]), "delta": _delta_pct(k["qty_returns"], k_prev["qty_returns"]), "is_expense": True},
        {"title": "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã", "value": money(opex_now), "delta": _delta_pct(opex_now, opex_prev), "is_expense": True},
        {"title": "–†–∞—Å—Ö–æ–¥—ã –Ω–∞ –ø—Ä–æ–¥–∞–∂—É", "value": money(k["sale_costs"]), "delta": _delta_pct(k["sale_costs"], k_prev["sale_costs"]), "is_expense": True},

        {"title": "–•—Ä–∞–Ω–µ–Ω–∏–µ (FBO)", "value": money(k["storage_fbo"]), "delta": _delta_pct(k["storage_fbo"], k_prev["storage_fbo"]), "is_expense": True},
        {"title": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂", "value": money(k["cogs"]), "delta": _delta_pct(k["cogs"], k_prev["cogs"]), "is_expense": True, "good_when_up": True},
        {"title": "–ù–∞–ª–æ–≥–∏/–ö–æ–º–∏—Å—Å–∏—è", "value": f'{money(k["tax"])} / {money(k["commission_cost"])}', "delta": commission_delta, "is_expense": True},
        {"title": "–†–µ–∫–ª–∞–º–∞ (—Ä–∞—Å—Ö–æ–¥)", "value": money(ads_spent_now), "delta": _delta_pct(ads_spent_now, ads_spent_prev), "is_expense": True},
    ]

    st.markdown("### –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    render_tiles(tiles, cols_per_row=4)

    st.markdown("### –†–µ–∫–ª–∞–º–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
    render_tiles(ads_tiles, cols_per_row=4)

    st.divider()

    over = df_ops[df_ops["sku"].isna()].copy()
    with st.expander("–î–µ—Ç–∞–ª–∏", expanded=False):
        st.markdown("**–î–∞–Ω–Ω—ã–µ –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º**")
        if over.empty:
            st.info("–ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π –±–µ–∑ SKU –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ.")
        else:
            over_g = (
                over.groupby("type_name", as_index=False)
                .agg(amount=("amount", "sum"))
                .sort_values("amount")
            )
            over_g = over_g.rename(columns={"type_name": "–¢–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏", "amount": "–ó–Ω–∞—á–µ–Ω–∏–µ"}).copy()
            # –æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ —á–∏—Å–ª–æ–º ‚Äî —á—Ç–æ–±—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
            over_g["–ó–Ω–∞—á–µ–Ω–∏–µ"] = pd.to_numeric(over_g["–ó–Ω–∞—á–µ–Ω–∏–µ"], errors="coerce").fillna(0.0)
            st.dataframe(
                over_g,
                use_container_width=True,
                hide_index=True,
                column_config={"–ó–Ω–∞—á–µ–Ω–∏–µ": st.column_config.NumberColumn(format="%.0f")},
            )

    st.markdown("## –°–ø–∏—Å–æ–∫ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö SKU ")
if sold is None or sold.empty:
    st.warning("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ—Ç SKU-–æ–ø–µ—Ä–∞—Ü–∏–π (items[].sku).")
else:
    total_tax = float(sold["accruals_net"].sum()) * 0.06

    # 1) –Ω–∞–ª–æ–≥
    sold_view = allocate_tax_by_share(sold, total_tax)

    # 2) —Ä–µ–∫–ª–∞–º–∞ ‚Äî –ø—Ä—è–º–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ SKU -> spend
    spend_map = load_ads_spend_by_sku(
        d_from.strftime("%Y-%m-%d"),
        d_to.strftime("%Y-%m-%d"),
    )

    sold_view["sku"] = pd.to_numeric(sold_view["sku"], errors="coerce").fillna(0).astype(int)
    sold_view["ads_total"] = sold_view["sku"].map(spend_map).fillna(0.0)
    st.write("ADS TOTAL SUM:", float(sold_view["ads_total"].sum()))

    with st.expander("DEBUG: —Ä–µ–∫–ª–∞–º–∞ –ø–æ SKU", expanded=False):
        st.write("spend_map size:", len(spend_map))
        st.write("spend_map sample:", list(spend_map.items())[:10])
        st.write("nonzero ads_total:", int((sold_view["ads_total"] > 0).sum()))

    # 3) –û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
    opex_period = opex_sum_period(df_opex, d_from, d_to)
    sold_view = allocate_cost_by_share(sold_view, opex_period, "opex_total")

    # 4) –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    sold_view = compute_profitability(sold_view)

    # 5) DEBUG (—Ç–æ–ª—å–∫–æ –≤—ã–≤–æ–¥, –±–µ–∑ —Ä–∞—Å—á—ë—Ç–æ–≤!)
    with st.expander("DEBUG: —Ä–µ–∫–ª–∞–º–∞ –ø–æ SKU", expanded=False):
        st.write("spend_map size:", len(spend_map))
        st.write("spend_map sample:", list(spend_map.items())[:10])
        st.write("direct nonzero cnt:", nonzero_cnt)
        if nonzero_cnt == 0 and spend_map:
            st.write("pid_to_sku sample:", list(pid_to_sku.items())[:10])
            st.write("spend_by_sku sample:", list(spend_by_sku.items())[:10])


        show = sold_view.copy()
        show = show.rename(columns={
            "article": "–ê—Ä—Ç–∏–∫—É–ª",
            "sku": "SKU",
            "name": "–ù–∞–∑–≤–∞–Ω–∏–µ",
            "qty_orders": "–ó–∞–∫–∞–∑—ã, —à—Ç",
            "qty_returns": "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç",
            "qty_buyout": "–í—ã–∫—É–ø, —à—Ç",
            "accruals_net": "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ",
            "commission": "–ö–æ–º–∏—Å—Å–∏—è, ‚ÇΩ",
            "logistics": "–£—Å–ª—É–≥–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞, ‚ÇΩ",
            "sale_costs": "–†–∞—Å—Ö–æ–¥—ã Ozon, ‚ÇΩ",
            "ads_total": "–†–µ–∫–ª–∞–º–∞, ‚ÇΩ",
            "cogs_unit": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç, ‚ÇΩ",
            "cogs_total": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ, ‚ÇΩ",
            "tax_total": "–ù–∞–ª–æ–≥, ‚ÇΩ",
            "opex_total": "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã, ‚ÇΩ",
            "profit": "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ",
            "profit_per_unit": "–ü—Ä–∏–±—ã–ª—å –Ω–∞ 1 —à—Ç, ‚ÇΩ",
            "margin_%": "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %",
            "roi_%": "ROI, %",
        })

        # –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        cols = [
            "–ê—Ä—Ç–∏–∫—É–ª","SKU","–ù–∞–∑–≤–∞–Ω–∏–µ",
            "–ó–∞–∫–∞–∑—ã, —à—Ç","–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç","–í—ã–∫—É–ø, —à—Ç",
            "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ",
            "–ö–æ–º–∏—Å—Å–∏—è, ‚ÇΩ","–£—Å–ª—É–≥–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞, ‚ÇΩ","–†–∞—Å—Ö–æ–¥—ã Ozon, ‚ÇΩ",
            "–†–µ–∫–ª–∞–º–∞, ‚ÇΩ",
            "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç, ‚ÇΩ","–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ, ‚ÇΩ",
            "–ù–∞–ª–æ–≥, ‚ÇΩ",
            "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã, ‚ÇΩ",
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ","–ü—Ä–∏–±—ã–ª—å –Ω–∞ 1 —à—Ç, ‚ÇΩ","–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %","ROI, %"
        ]
        for c in cols:
            if c not in show.columns:
                show[c] = 0.0
        show = show[cols].copy()
        show["SKU"] = pd.to_numeric(show["SKU"], errors="coerce").fillna(0).astype(int).astype(str)
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ => –æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Ç–∏–ø—ã
        # –ß–∏—Å–ª–∞ –ø—Ä–∏–≤–æ–¥–∏–º, –Ω–æ –ù–ï —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫–∏
        int_cols = ["–ó–∞–∫–∞–∑—ã, —à—Ç","–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç","–í—ã–∫—É–ø, —à—Ç"]
        for c in int_cols:
            show[c] = pd.to_numeric(show[c], errors="coerce").fillna(0).astype(int)

        money_cols = [
            "–í—ã—Ä—É—á–∫–∞, ‚ÇΩ","–ö–æ–º–∏—Å—Å–∏—è, ‚ÇΩ","–£—Å–ª—É–≥–∏/–ª–æ–≥–∏—Å—Ç–∏–∫–∞, ‚ÇΩ","–†–∞—Å—Ö–æ–¥—ã Ozon, ‚ÇΩ","–†–µ–∫–ª–∞–º–∞, ‚ÇΩ",
            "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å 1 —à—Ç, ‚ÇΩ","–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ, ‚ÇΩ","–ù–∞–ª–æ–≥, ‚ÇΩ","–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã, ‚ÇΩ",
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ","–ü—Ä–∏–±—ã–ª—å –Ω–∞ 1 —à—Ç, ‚ÇΩ",
        ]
        for c in money_cols:
            show[c] = pd.to_numeric(show[c], errors="coerce").fillna(0.0)

        pct_cols = ["–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %","ROI, %"]
        for c in pct_cols:
            show[c] = pd.to_numeric(show[c], errors="coerce").fillna(0.0)

        st.dataframe(
            show,
            use_container_width=True,
            hide_index=True,
            column_config={
                "–ó–∞–∫–∞–∑—ã, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
                "–í–æ–∑–≤—Ä–∞—Ç—ã, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
                "–í—ã–∫—É–ø, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
                **{c: st.column_config.NumberColumn(format="%.0f") for c in money_cols},
                "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å, %": st.column_config.NumberColumn(format="%.1f"),
                "ROI, %": st.column_config.NumberColumn(format="%.1f"),
            }
        )

        st.download_button(
            "–°–∫–∞—á–∞—Ç—å XLSX (—Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö SKU)",
            data=export_soldsku_xlsx(show),
            file_name=f"ozon_soldsku_{d_from.strftime('%Y-%m-%d')}_{d_to.strftime('%Y-%m-%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )





# ================== TAB 4 (OPEX) ==================
with tab4:
    st.subheader("–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã")
    st.caption("–†—É—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã (–Ω–µ –∏–∑ Ozon). –û–Ω–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ –ø—Ä–∏–±—ã–ª–∏ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø–æ SKU –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤—ã—Ä—É—á–∫–µ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")

    opex = load_opex()
    types_saved = load_opex_types()

    st.markdown("### –î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥")

    c1, c2, c3, c4 = st.columns([1.2, 3.0, 1.2, 1.3])

    with c1:
        st.markdown("**–î–∞—Ç–∞**")
        new_date = st.date_input(
            "–î–∞—Ç–∞",
            value=date.today(),
            key="opex_new_date",
            label_visibility="collapsed",
        )

    with c2:
        st.markdown("**–¢–∏–ø**")
        types_saved = load_opex_types()
        options = (types_saved or []) + ["‚ûï –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–∏–ø"]

        sel = st.selectbox(
            "–¢–∏–ø",
            options=options,
            index=None,  # –≤–∞–∂–Ω–æ: –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            placeholder="–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Ä–∞—Å—Ö–æ–¥–∞‚Ä¶",
            key="opex_type_select",
            label_visibility="collapsed",
        )

        if sel == "‚ûï –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π —Ç–∏–ø":
            new_type = st.text_input(
                "–ù–æ–≤—ã–π —Ç–∏–ø",
                value="",
                placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ó–∞—Ä–ø–ª–∞—Ç–∞, –ê—Ä–µ–Ω–¥–∞‚Ä¶",
                key="opex_new_type_manual",
                label_visibility="collapsed",
            ).strip()
        else:
            new_type = (sel or "").strip()

    with c3:
        st.markdown("**–°—É–º–º–∞, ‚ÇΩ**")
        new_amount = st.number_input(
            "–°—É–º–º–∞, ‚ÇΩ",
            min_value=0.0,
            value=0.0,
            step=100.0,
            key="opex_new_amount",
            label_visibility="collapsed",
        )

        with c4:
            st.markdown("&nbsp;")  # —Å–æ–∑–¥–∞—ë–º ‚Äú—Å—Ç—Ä–æ–∫—É‚Äù –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–æ–∫, —á—Ç–æ–±—ã –∫–Ω–æ–ø–∫–∞ —Å—Ç–∞–ª–∞ –Ω–∞ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å
            add_exp = st.button("–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—Ö–æ–¥", key="opex_add_btn", use_container_width=True)

    if add_exp:
        t = (new_type or "").strip()
        if float(new_amount or 0) <= 0:
            st.warning("–°—É–º–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ 0.")
        elif not t:
            st.warning("–£–∫–∞–∂–∏ —Ç–∏–ø —Ä–∞—Å—Ö–æ–¥–∞.")
        else:
            types_saved = load_opex_types()
            if t not in types_saved:
                types_saved.append(t)
                save_opex_types(types_saved)

            row = pd.DataFrame([{"date": new_date, "type": t, "amount": float(new_amount)}])
            opex2 = pd.concat([opex, row], ignore_index=True)
            save_opex(opex2)
            st.success("–†–∞—Å—Ö–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ω.")
            st.rerun()

    st.divider()

    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞–º–∏ (—É–¥–∞–ª–µ–Ω–∏–µ/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ)
    with st.expander("–®–∞–±–ª–æ–Ω—ã —Ç–∏–ø–æ–≤ —Ä–∞—Å—Ö–æ–¥–æ–≤", expanded=False):
        types_saved = load_opex_types()
        if not types_saved:
            st.info("–®–∞–±–ª–æ–Ω–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç. –î–æ–±–∞–≤—å —Ä–∞—Å—Ö–æ–¥ —Å –Ω–æ–≤—ã–º —Ç–∏–ø–æ–º ‚Äî –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—è–≤–∏—Ç—Å—è –≤ —à–∞–±–ª–æ–Ω–∞—Ö.")
        else:
            tpl_df = pd.DataFrame({"–¢–∏–ø": types_saved, "–£–¥–∞–ª–∏—Ç—å": [False] * len(types_saved)})
            tpl_edit = st.data_editor(
                tpl_df,
                use_container_width=True,
                hide_index=True,
                num_rows="fixed",
                column_config={
                    "–¢–∏–ø": st.column_config.TextColumn(),
                    "–£–¥–∞–ª–∏—Ç—å": st.column_config.CheckboxColumn(width="small"),
                },
                key="opex_tpl_editor",
            )

            csave, cdel = st.columns([1.2, 1.6])
            with csave:
                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω—ã", key="opex_tpl_apply_btn", use_container_width=True):
                    df = tpl_edit.copy()
                    df["–¢–∏–ø"] = df["–¢–∏–ø"].fillna("").astype(str).str.strip()
                    df = df[df["–¢–∏–ø"] != ""].copy()
                    df = df[df["–£–¥–∞–ª–∏—Ç—å"] != True].copy()
                    save_opex_types(df["–¢–∏–ø"].tolist())
                    st.success("–®–∞–±–ª–æ–Ω—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã.")
                    st.rerun()
            with cdel:
                if st.button("–£–¥–∞–ª–∏—Ç—å –æ—Ç–º–µ—á–µ–Ω–Ω—ã–µ", key="opex_tpl_del_btn", use_container_width=True):
                    df = tpl_edit.copy()
                    df["–¢–∏–ø"] = df["–¢–∏–ø"].fillna("").astype(str).str.strip()
                    df = df[df["–¢–∏–ø"] != ""].copy()
                    df = df[df["–£–¥–∞–ª–∏—Ç—å"] != True].copy()
                    save_opex_types(df["–¢–∏–ø"].tolist())
                    st.success("–£–¥–∞–ª–µ–Ω–æ.")
                    st.rerun()

    st.markdown("### –°–ø–∏—Å–æ–∫ —Ä–∞—Å—Ö–æ–¥–æ–≤ (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ / —É–¥–∞–ª–µ–Ω–∏–µ)")

    opex = load_opex()
    # --- —Ñ–∏–ª—å—Ç—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å—ë –≤—Ä–µ–º—è) ---
    if "opex_filter_year" not in st.session_state:
        st.session_state["opex_filter_year"] = "–í—Å–µ –≤—Ä–µ–º—è"
    if "opex_filter_month" not in st.session_state:
        st.session_state["opex_filter_month"] = "–í–µ—Å—å –≥–æ–¥"

    years = sorted({d.year for d in opex["date"].dropna()}, reverse=True) if not opex.empty else []
    year_options = ["–í—Å–µ –≤—Ä–µ–º—è"] + [str(y) for y in years]
    # –µ—Å–ª–∏ –≤ session_state –∑–Ω–∞—á–µ–Ω–∏–µ –≥–æ–¥–∞ –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
    if st.session_state.get("opex_filter_year") not in year_options:
        st.session_state["opex_filter_year"] = "–í—Å–µ –≤—Ä–µ–º—è"

    cfy, cfm, cfr = st.columns([1.0, 1.0, 1.0])
    with cfy:
        sel_year_lbl = st.selectbox("–ì–æ–¥", options=year_options, key="opex_filter_year")
    with cfm:
        if sel_year_lbl != "–í—Å–µ –≤—Ä–µ–º—è":
            yy = int(sel_year_lbl)
            months_av = sorted({d.month for d in opex["date"].dropna() if d.year == yy})
            month_options = ["–í–µ—Å—å –≥–æ–¥"] + [month_name_ru(m) for m in months_av]
        else:
            month_options = ["–í–µ—Å—å –≥–æ–¥"]
        # –µ—Å–ª–∏ –≤ session_state –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞ –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
        if st.session_state.get("opex_filter_month") not in month_options:
            st.session_state["opex_filter_month"] = month_options[0]
        sel_month_lbl = st.selectbox("–ú–µ—Å—è—Ü", options=month_options, key="opex_filter_month")
    with cfr:
        def _opex_reset_period():
            st.session_state["opex_filter_year"] = "–í—Å–µ –≤—Ä–µ–º—è"
            st.session_state["opex_filter_month"] = "–í–µ—Å—å –≥–æ–¥"
        st.button("–°–±—Ä–æ—Å–∏—Ç—å –ø–µ—Ä–∏–æ–¥", key="opex_filter_reset", on_click=_opex_reset_period)

    # –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
    opex_show = opex.copy()
    if sel_year_lbl != "–í—Å–µ –≤—Ä–µ–º—è":
        yy = int(sel_year_lbl)
        opex_show = opex_show[opex_show["date"].apply(lambda d: hasattr(d, "year") and d.year == yy)].copy()
        if sel_month_lbl != "–í–µ—Å—å –≥–æ–¥":
            mm = {month_name_ru(i): i for i in range(1, 13)}.get(sel_month_lbl)
            if mm:
                opex_show = opex_show[opex_show["date"].apply(lambda d: hasattr(d, "month") and d.month == mm)].copy()

    opex_show = opex_show.sort_values(["date", "type"], ascending=[False, True]).reset_index(drop=True)

    total_all = float(pd.to_numeric(opex["amount"], errors="coerce").fillna(0.0).sum()) if not opex.empty else 0.0
    st.markdown(f"**–°—É–º–º–∞ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤ –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è:** {money(total_all)}")

    if opex.empty:
        st.info("–ü–æ–∫–∞ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π.")
    else:
        view = opex_show.copy()
        view["delete"] = False
        view = view[["delete", "date", "type", "amount"]].rename(columns={
            "delete": "–£–¥–∞–ª–∏—Ç—å",
            "date": "–î–∞—Ç–∞",
            "type": "–¢–∏–ø",
            "amount": "–°—É–º–º–∞, ‚ÇΩ",
        })

        edited = st.data_editor(
            view,
            use_container_width=True,
            hide_index=True,
            num_rows="fixed",
            column_config={
                "–£–¥–∞–ª–∏—Ç—å": st.column_config.CheckboxColumn(width="small"),
                "–î–∞—Ç–∞": st.column_config.DateColumn(format="YYYY-MM-DD"),
                "–¢–∏–ø": st.column_config.TextColumn(),
                "–°—É–º–º–∞, ‚ÇΩ": st.column_config.NumberColumn(format="%.0f"),
            },
            key="opex_editor",
        )

        csave, cexp = st.columns([1.6, 6.4])

        with csave:
            if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key="opex_save_btn", use_container_width=True):
                df = edited.copy()
                df = df[df["–£–¥–∞–ª–∏—Ç—å"] != True].copy()

                df["–î–∞—Ç–∞"] = pd.to_datetime(df["–î–∞—Ç–∞"], errors="coerce").dt.date
                df["–¢–∏–ø"] = df["–¢–∏–ø"].fillna("").astype(str).str.strip()
                df["–°—É–º–º–∞, ‚ÇΩ"] = pd.to_numeric(df["–°—É–º–º–∞, ‚ÇΩ"], errors="coerce").fillna(0.0)

                df = df.dropna(subset=["–î–∞—Ç–∞"]).copy()
                df = df[df["–¢–∏–ø"] != ""].copy()

                df2 = df.rename(columns={"–î–∞—Ç–∞": "date", "–¢–∏–ø": "type", "–°—É–º–º–∞, ‚ÇΩ": "amount"})[["date", "type", "amount"]]
                save_opex(df2)

                st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
                st.rerun()

        with cexp:
            st.download_button(
                "–°–∫–∞—á–∞—Ç—å XLSX",
                data=export_soldsku_xlsx(opex.rename(columns={"date": "–î–∞—Ç–∞", "type": "–¢–∏–ø", "amount": "–°—É–º–º–∞, ‚ÇΩ"})),
                file_name="ozon_opex.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )


# ================== TAB 2 (MONTHS) ==================
with tab2:
    st.subheader("–ü–æ–º–µ—Å—è—á–Ω–∞—è —Å–≤–æ–¥–∫–∞")

    import calendar as _cal

    def _fmt_int(x):
        try:
            return f"{int(round(float(x))):,}".replace(",", " ")
        except Exception:
            return "0"

    def fmt_money2(x):
        return f"{_fmt_int(x)} ‚ÇΩ"

    def fmt_pct2(x, digits=1):
        try:
            v = float(x) * 100.0 if abs(float(x)) <= 1.0 else float(x)
            return f"{v:.{digits}f}%"
        except Exception:
            return "0.0%"

    def month_label(ym: str) -> str:
        y, m = ym.split("-")
        m_i = int(m)
        ru_months = ["–Ø–Ω–≤–∞—Ä—å","–§–µ–≤—Ä–∞–ª—å","–ú–∞—Ä—Ç","–ê–ø—Ä–µ–ª—å","–ú–∞–π","–ò—é–Ω—å","–ò—é–ª—å","–ê–≤–≥—É—Å—Ç","–°–µ–Ω—Ç—è–±—Ä—å","–û–∫—Ç—è–±—Ä—å","–ù–æ—è–±—Ä—å","–î–µ–∫–∞–±—Ä—å"]
        return f"{ru_months[m_i-1]} {y}"

    def month_start_end(year: int, month: int):
        start = date(year, month, 1)
        last_day = _cal.monthrange(year, month)[1]
        end = date(year, month, last_day)
        return start, end

    st.caption("Ozon API –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –æ—á–µ—Ä–µ–¥–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏ –≤ –æ–¥–∏–Ω –º–µ—Å—è—Ü.")

    y_l, m_l = last_closed_month(date.today())
    last_closed = date(y_l, m_l, 1)
    default_from = (last_closed.replace(day=1) - timedelta(days=365)).replace(day=1)

    c1, c2 = st.columns(2)
    with c1:
        m_from_dt = st.date_input("–ú–µ—Å—è—Ü —Å", default_from, key="m_from_dt")
    with c2:
        m_to_dt = st.date_input("–ú–µ—Å—è—Ü –ø–æ", last_closed, key="m_to_dt")

    m_from_dt = m_from_dt.replace(day=1)
    m_to_dt = m_to_dt.replace(day=1)

    if m_from_dt > m_to_dt:
        st.error("–ú–µ—Å—è—Ü '—Å' –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –º–µ—Å—è—Ü–∞ '–ø–æ'.")
        st.stop()

    months = []
    cur = m_from_dt
    while cur <= m_to_dt:
        months.append(cur.strftime("%Y-%m"))
        if cur.month == 12:
            cur = cur.replace(year=cur.year + 1, month=1, day=1)
        else:
            cur = cur.replace(month=cur.month + 1, day=1)

    def month_metrics(df_ops_m: pd.DataFrame) -> dict:
        sku_ops = df_ops_m[df_ops_m["sku"].notna()].copy()

        sales_accr = float(sku_ops[sku_ops["type"].eq("orders")]["accruals_for_sale"].sum())
        returns_accr = float(sku_ops[sku_ops["type"].eq("returns")]["accruals_for_sale"].sum())
        revenue_net = sales_accr + returns_accr

        orders_qty = int(round(float(sku_ops[sku_ops["type"].eq("orders")].get("qty", 0).sum()))) if "qty" in sku_ops.columns else 0
        returns_qty = int(round(float(sku_ops[sku_ops["type"].eq("returns")].get("qty", 0).sum()))) if "qty" in sku_ops.columns else 0
        bought_qty = max(orders_qty - returns_qty, 0)
        buyout_pct = (bought_qty / orders_qty * 100.0) if orders_qty else 0.0

        commission_sum = float((-sku_ops["sale_commission"]).clip(lower=0).sum())
        commission_pct = (commission_sum / revenue_net * 100.0) if revenue_net else 0.0

        logistic_sum = float((-sku_ops["services_sum"]).clip(lower=0).sum())
        logistic_avg = (logistic_sum / bought_qty) if bought_qty else 0.0
        logistic_pct = (logistic_sum / revenue_net * 100.0) if revenue_net else 0.0

        over = df_ops_m[df_ops_m["sku"].isna()].copy()
        storage_fbo = float((-over[over["type_name"].eq("–£—Å–ª—É–≥–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ")]["amount"]).clip(lower=0).sum())
        storage_pct = (storage_fbo / revenue_net * 100.0) if revenue_net else 0.0

        reviews_cost = float((-over[over["type_name"].str.contains("–ë–∞–ª–ª—ã –∑–∞ –æ—Ç–∑—ã–≤—ã", case=False, na=False)]["amount"]).clip(lower=0).sum())
        reviews_pct = (reviews_cost / revenue_net * 100.0) if revenue_net else 0.0

        mask_known = (
            over["type_name"].eq("–£—Å–ª—É–≥–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å–∫–ª–∞–¥–µ")
            | over["type_name"].str.contains("–ë–∞–ª–ª—ã –∑–∞ –æ—Ç–∑—ã–≤—ã", case=False, na=False)
        )
        other_expenses = float((-over[~mask_known]["amount"]).clip(lower=0).sum())
        other_expenses_pct = (other_expenses / revenue_net * 100.0) if revenue_net else 0.0

        compensations = float((over[over["type_name"].str.contains("–ö–æ–º–ø–µ–Ω—Å–∞—Ü", case=False, na=False)]["amount"]).sum())
        fines = float((-over[over["type_name"].str.contains("—à—Ç—Ä–∞—Ñ", case=False, na=False)]["amount"]).clip(lower=0).sum())
        paid_accept = float((-over[over["type_name"].str.contains("–ü–ª–∞—Ç–Ω", case=False, na=False)]["amount"]).clip(lower=0).sum())
        adjustments = float((over[over["type_name"].str.contains("–ö–æ—Ä—Ä–µ–∫—Ç", case=False, na=False)]["amount"]).sum())

        total_ozon_exp = commission_sum + logistic_sum + storage_fbo + reviews_cost + other_expenses
        share_ozon = (total_ozon_exp / revenue_net * 100.0) if revenue_net else 0.0

        taxes = revenue_net * 0.06 if revenue_net else 0.0
        to_pay = float(sku_ops["amount"].sum())

        profit = revenue_net - total_ozon_exp - taxes
        profit_pct_price = (profit / revenue_net * 100.0) if revenue_net else 0.0

        days_in_month = 30
        if not df_ops_m.empty:
            s = str(df_ops_m.iloc[0].get("operation_date", ""))[:10]
            try:
                dt0 = datetime.strptime(s, "%Y-%m-%d").date()
                days_in_month = _cal.monthrange(dt0.year, dt0.month)[1]
            except Exception:
                pass

        weeks = max(round(days_in_month / 7.0, 2), 1.0)
        profit_week = profit / weeks if weeks else profit
        avg_price = (revenue_net / bought_qty) if bought_qty else 0.0

        return {
            "–ö–æ–ª-–≤–æ –∑–∞–∫–∞–∑–æ–≤": orders_qty,
            "–í—ã–∫—É–ø–ª–µ–Ω–æ —à—Ç.": bought_qty,
            "% –≤—ã–∫—É–ø–∞": buyout_pct,

            "–í—ã—Ä—É—á–∫–∞ —Å —É—á–µ—Ç–æ–º –≤–æ–∑–≤—Ä–∞—Ç–æ–≤": revenue_net,
            "–°—Ä. —Ü–µ–Ω–∞": avg_price,

            "–û–±—â–∏–µ —Ä–∞—Å—Ö–æ–¥—ã Ozon": total_ozon_exp,
            "–ö–æ–º–∏—Å—Å–∏—è": commission_sum,
            "% –∫–æ–º–∏—Å—Å–∏–∏ –æ—Ç –≤—ã—Ä—É—á–∫–∏": commission_pct,

            "–õ–æ–≥–∏—Å—Ç–∏–∫–∞": logistic_sum,
            "–°—Ä. –ª–æ–≥–∏—Å—Ç–∏–∫–∞": logistic_avg,
            "% –õ–æ–≥–∏—Å—Ç–∏–∫–∏": logistic_pct,

            "–•—Ä–∞–Ω–µ–Ω–∏–µ": storage_fbo,
            "% —Ö—Ä–∞–Ω–µ–Ω–∏—è": storage_pct,

            "–û—Ç–∑—ã–≤—ã –∑–∞ –±–∞–ª–ª—ã": reviews_cost,
            "% –æ—Ç–∑—ã–≤–æ–≤ –∑–∞ –±–∞–ª–ª—ã": reviews_pct,

            "–ü—Ä–æ—á–∏–µ —Ä–∞—Å—Ö–æ–¥—ã": other_expenses,
            "% –ø—Ä–æ—á–∏—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤": other_expenses_pct,

            "–ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏": compensations,
            "–®—Ç—Ä–∞—Ñ—ã": fines,
            "–ü–ª–∞—Ç–Ω–∞—è –ø—Ä–∏–µ–º–∫–∞": paid_accept,
            "–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏": adjustments,

            "–î–æ–ª—è Ozon, %": share_ozon,
            "–ù–∞–ª–æ–≥–∏": taxes,
            "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é": to_pay,

            "–ü—Ä–∏–±—ã–ª—å": profit,
            "% –ø—Ä–∏–±—ã–ª–∏ –≤ –≤—ã—Ä—É—á–∫–µ": profit_pct_price,

            "–ö–æ–ª-–≤–æ –Ω–µ–¥–µ–ª—å": weeks,
            "–ü—Ä–∏–±—ã–ª—å —Å—Ä–µ–¥–Ω–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è": profit_week,
        }

    @st.cache_data(ttl=3600)
    def load_ops_month(year: int, month: int):
        d1, d2 = month_start_end(year, month)
        return client.fetch_finance_transactions(d1.strftime("%Y-%m-%d"), d2.strftime("%Y-%m-%d"))

    month_rows = []
    progress = st.progress(0, text="–°—á–∏—Ç–∞—é –º–µ—Å—è—Ü—ã‚Ä¶")
    for i, ym in enumerate(months, start=1):
        y, mo = map(int, ym.split("-"))
        ops_m = load_ops_month(y, mo)
        df_ops_m = ops_to_df(ops_m)
        met = month_metrics(df_ops_m)
        # –û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã –∑–∞ –º–µ—Å—è—Ü (–∏–∑ —Ç–∞–±–∞ "–û–ø–µ—Ä. —Ä–∞—Å—Ö–æ–¥—ã")
        d1_m, d2_m = month_start_end(y, mo)
        met["–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã"] = opex_sum_period(df_opex, d1_m, d2_m)
        met["YM"] = ym
        month_rows.append(met)
        progress.progress(i / len(months), text=f"–°—á–∏—Ç–∞—é –º–µ—Å—è—Ü—ã‚Ä¶ {i}/{len(months)}")
    progress.empty()

    df_month = pd.DataFrame(month_rows).sort_values(["YM"]).reset_index(drop=True)
    df_month["–ú–µ—Å—è—Ü"] = df_month["YM"].apply(month_label)

    st.markdown("### –°—Ä–∞–≤–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤")

    month_options = df_month["–ú–µ—Å—è—Ü"].tolist()
    default_sel = month_options[-3:] if len(month_options) >= 3 else month_options
    key_ms = "months_compare_sel"
    if key_ms not in st.session_state:
        st.session_state[key_ms] = default_sel

    b1, b2, _ = st.columns([1.4, 1.1, 3.5])
    with b1:
        if st.button("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ –º–µ—Å—è—Ü—ã", use_container_width=True, key="btn_months_all"):
            st.session_state[key_ms] = month_options[:]
    with b2:
        if st.button("–°–Ω—è—Ç—å –≤—ã–±–æ—Ä", use_container_width=True, key="btn_months_clear"):
            st.session_state[key_ms] = []

    sel_months = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Å—è—Ü—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", options=month_options, key=key_ms)

    df_view = df_month.copy()
    if sel_months:
        df_view = df_view[df_view["–ú–µ—Å—è—Ü"].isin(sel_months)].copy()

    metric_cols = [c for c in df_view.columns if c not in ("YM", "–ú–µ—Å—è—Ü")]
    pivot = (
        df_view.set_index("–ú–µ—Å—è—Ü")[metric_cols]
        .T
        .reset_index()
        .rename(columns={"index": "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"})
    )

    percent_metrics = {
        "% –≤—ã–∫—É–ø–∞",
        "% –∫–æ–º–∏—Å—Å–∏–∏ –æ—Ç –≤—ã—Ä—É—á–∫–∏",
        "% –õ–æ–≥–∏—Å—Ç–∏–∫–∏",
        "% —Ö—Ä–∞–Ω–µ–Ω–∏—è",
        "% –æ—Ç–∑—ã–≤–æ–≤ –∑–∞ –±–∞–ª–ª—ã",
        "% –ø—Ä–æ—á–∏—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤",
        "–î–æ–ª—è Ozon, %",
        "% –ø—Ä–∏–±—ã–ª–∏ –≤ –≤—ã—Ä—É—á–∫–µ",
    }
    int_metrics = {"–ö–æ–ª-–≤–æ –∑–∞–∫–∞–∑–æ–≤", "–í—ã–∫—É–ø–ª–µ–Ω–æ —à—Ç."}

    def format_row(row):
        name = row["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å"]
        for col in row.index:
            if col == "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å":
                continue
            v = row[col]
            if name in percent_metrics:
                row[col] = fmt_pct2(v, 1)
            elif name in int_metrics:
                row[col] = _fmt_int(v)
            elif name in {"–ö–æ–ª-–≤–æ –Ω–µ–¥–µ–ª—å"}:
                try:
                    row[col] = f"{float(v):.1f}"
                except Exception:
                    row[col] = "0.0"
            else:
                row[col] = fmt_money2(v)
        return row

    pivot_pretty = pivot.apply(format_row, axis=1)
    st.markdown("### –ü–æ–º–µ—Å—è—á–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    st.dataframe(
    pivot_pretty,
    use_container_width=True,
    hide_index=True
    )

    def export_monthly_xlsx(df_rows: pd.DataFrame, df_pivot_pretty: pd.DataFrame) -> bytes:
        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as w:
            df_rows.to_excel(w, index=False, sheet_name="Monthly_rows_raw")
            df_pivot_pretty.to_excel(w, index=False, sheet_name="Monthly_pivot_pretty")
        return bio.getvalue()

    st.download_button(
        "–°–∫–∞—á–∞—Ç—å XLSX (–ø–æ–º–µ—Å—è—á–Ω–∞—è —Å–≤–æ–¥–∫–∞)",
        data=export_monthly_xlsx(df_view, pivot_pretty),
        file_name="ozon_monthly_summary.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )



# ================== TAB 3 (ABC) ==================
with tab3:
    st.subheader("ABC-–∞–Ω–∞–ª–∏–∑ –º–∞–≥–∞–∑–∏–Ω–∞")

    import calendar as _cal2
    import io

    def _fmt_int(x):
        try:
            return f"{int(round(float(x))):,}".replace(",", " ")
        except Exception:
            return "0"

    def _fmt_money(x):
        try:
            return f"{float(x):,.0f} ‚ÇΩ".replace(",", " ")
        except Exception:
            return "0 ‚ÇΩ"

    def month_start_end(year: int, month: int):
        start = date(year, month, 1)
        last_day = _cal2.monthrange(year, month)[1]
        return start, date(year, month, last_day)

    def closed_months_until_today():
        y_last, m_last = last_closed_month(date.today())
        out = []
        y = 2020
        m = 1
        while (y < y_last) or (y == y_last and m <= m_last):
            out.append((y, m))
            if m == 12:
                y += 1
                m = 1
            else:
                m += 1
        return out

    def closed_quarters_for_year(year: int, closed_set):
        q_map = {1: [1,2,3], 2: [4,5,6], 3: [7,8,9], 4: [10,11,12]}
        res = []
        for q, mm in q_map.items():
            if all((year, m) in closed_set for m in mm):
                res.append(q)
        return res

    def abc_class_from_metric(df: pd.DataFrame, col: str):
        s = df[col].fillna(0).astype(float)
        total = float(s.sum())
        if total <= 0:
            return pd.Series(["C"] * len(df), index=df.index)
        share = s / total
        cum = share.cumsum()
        return cum.apply(lambda x: "A" if x <= 0.8 else "B" if x <= 0.95 else "C")

    @st.cache_data(ttl=3600)
    def load_ops_month_abc(y: int, m: int):
        d1, d2 = month_start_end(y, m)
        return client.fetch_finance_transactions(d1.strftime("%Y-%m-%d"), d2.strftime("%Y-%m-%d"))

    closed = closed_months_until_today()
    closed_set = set(closed)
    years = sorted({y for y, _ in closed}, reverse=True)
    if not years:
        st.info("–ù–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –º–µ—Å—è—Ü–µ–≤.")
        st.stop()

    colA, colB, colC = st.columns([1.1, 1.2, 2.2])
    with colA:
        mode = st.radio("–ü–µ—Ä–∏–æ–¥", ["–ú–µ—Å—è—Ü—ã", "–ö–≤–∞—Ä—Ç–∞–ª—ã"], horizontal=True, key="abc_mode")
    with colB:
        sel_year = st.selectbox("–ì–æ–¥", years, index=0, key="abc_year")
    with colC:
        only_profit = st.checkbox("–¢–æ–ª—å–∫–æ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ SKU", value=False, key="abc_only_profit")

    months_in_year = [(y, m) for (y, m) in closed if y == sel_year]
    month_options = [month_name_ru(m) for (y, m) in months_in_year]
    month_map = {month_name_ru(m): (y, m) for (y, m) in months_in_year}

    q_list = closed_quarters_for_year(sel_year, closed_set)
    q_options = [f"{q} –∫–≤." for q in q_list]
    q_to_months = {
        f"{q} –∫–≤.": [(sel_year, mm) for mm in ([1,2,3] if q==1 else [4,5,6] if q==2 else [7,8,9] if q==3 else [10,11,12])]
        for q in q_list
    }

    selected_months = []
    chosen_labels = []
    chosen_q = []

    if mode == "–ú–µ—Å—è—Ü—ã":
        if not month_options:
            st.info("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–¥ –Ω–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –º–µ—Å—è—Ü–µ–≤.")
            st.stop()

        key_ms = "abc_months_sel"
        if key_ms not in st.session_state:
            st.session_state[key_ms] = month_options[:]

        b1, b2, _ = st.columns([1.6, 1.2, 3.2])
        with b1:
            if st.button("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ –∑–∞–∫—Ä—ã—Ç—ã–µ –º–µ—Å—è—Ü—ã", use_container_width=True, key="abc_btn_all_m"):
                st.session_state[key_ms] = month_options[:]
        with b2:
            if st.button("–°–Ω—è—Ç—å –≤—ã–±–æ—Ä", use_container_width=True, key="abc_btn_clear_m"):
                st.session_state[key_ms] = []

        chosen_labels = st.multiselect("–ú–µ—Å—è—Ü—ã (–∑–∞–∫—Ä—ã—Ç—ã–µ)", options=month_options, key=key_ms)
        selected_months = [month_map[x] for x in chosen_labels if x in month_map]
    else:
        if not q_options:
            st.info("–ó–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–¥ –Ω–µ—Ç –∑–∞–∫—Ä—ã—Ç—ã—Ö –∫–≤–∞—Ä—Ç–∞–ª–æ–≤.")
            st.stop()

        key_q = "abc_quarters_sel"
        if key_q not in st.session_state:
            st.session_state[key_q] = q_options[:]

        b1, b2, _ = st.columns([1.6, 1.2, 3.2])
        with b1:
            if st.button("–í—ã–±—Ä–∞—Ç—å –≤—Å–µ –∑–∞–∫—Ä—ã—Ç—ã–µ –∫–≤–∞—Ä—Ç–∞–ª—ã", use_container_width=True, key="abc_btn_all_q"):
                st.session_state[key_q] = q_options[:]
        with b2:
            if st.button("–°–Ω—è—Ç—å –≤—ã–±–æ—Ä", use_container_width=True, key="abc_btn_clear_q"):
                st.session_state[key_q] = []

        chosen_q = st.multiselect("–ö–≤–∞—Ä—Ç–∞–ª—ã (–∑–∞–∫—Ä—ã—Ç—ã–µ)", options=q_options, key=key_q)
        months_flat = []
        for qlbl in chosen_q:
            months_flat.extend(q_to_months.get(qlbl, []))
        selected_months = sorted(set(months_flat), key=lambda x: (x[0], x[1]))

    if not selected_months:
        st.warning("–í—ã–±–µ—Ä–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –º–µ—Å—è—Ü/–∫–≤–∞—Ä—Ç–∞–ª.")
        st.stop()

    dfs = []
    p = st.progress(0, text="–ó–∞–≥—Ä—É–∂–∞—é –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Å—è—Ü–∞–º‚Ä¶")
    for i, (yy, mm) in enumerate(selected_months, 1):
        dfs.append(ops_to_df(load_ops_month_abc(yy, mm)))
        p.progress(i / len(selected_months), text=f"–ó–∞–≥—Ä—É–∂–∞—é –æ–ø–µ—Ä–∞—Ü–∏–∏‚Ä¶ {i}/{len(selected_months)}")
    p.empty()

    df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()
    sku_df = df[df["sku"].notna()].copy()
    if sku_df.empty:
        st.info("–ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ SKU –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.")
        st.stop()

    sku_df["sku"] = pd.to_numeric(sku_df["sku"], errors="coerce").astype("Int64")
    sku_df = sku_df.dropna(subset=["sku"]).copy()
    sku_df["sku"] = sku_df["sku"].astype(int)

    sku_df["qty_orders"] = sku_df.apply(lambda r: r["qty"] if r["type"]=="orders" else 0, axis=1)
    sku_df["qty_returns"] = sku_df.apply(lambda r: r["qty"] if r["type"]=="returns" else 0, axis=1)

    g = sku_df.groupby(["sku","name"], as_index=False).agg(
        qty_orders=("qty_orders","sum"),
        qty_returns=("qty_returns","sum"),
        accruals=("accruals_for_sale","sum"),
        profit=("amount","sum")
    )
    g["buyout_qty"] = (g["qty_orders"] - g["qty_returns"]).clip(lower=0)

    # --- –ê—Ä—Ç–∏–∫—É–ª—ã –∏–∑ COGS (–∫–∞–∫ –≤ —Ä–∞–±–æ—á–µ–π –≤–µ—Ä—Å–∏–∏) ---
    if cogs_df is not None and not cogs_df.empty:
        c2 = cogs_df[["sku", "article"]].copy()
        c2["sku"] = pd.to_numeric(c2["sku"], errors="coerce").astype("Int64")
        c2 = c2.dropna(subset=["sku"]).copy()
        c2["sku"] = c2["sku"].astype(int)
        c2["article"] = c2["article"].fillna("").astype(str)

        g["sku"] = pd.to_numeric(g["sku"], errors="coerce").astype("Int64")
        g = g.dropna(subset=["sku"]).copy()
        g["sku"] = g["sku"].astype(int)

        g = g.merge(c2.drop_duplicates("sku"), on="sku", how="left")

    if "article" not in g.columns:
        g["article"] = ""
    g["article"] = g["article"].fillna("").astype(str)

    # --- –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ ---
    try:
        known = g[(g["article"].astype(str).str.strip() != "") & g["name"].notna()].copy()
        if not known.empty:
            name_to_article = (
                known.assign(_a=known["article"].astype(str).str.strip())
                .groupby("name")["_a"]
                .agg(lambda s: s.value_counts().index[0])
            )
            mask_empty = g["article"].astype(str).str.strip() == ""
            g.loc[mask_empty, "article"] = (
                g.loc[mask_empty, "name"]
                .map(name_to_article)
                .apply(lambda a: f"–î—É–±–ª—å ({a})" if isinstance(a, str) and a.strip() else "")
            )
    except Exception:
        pass
    g["article"] = g["article"].fillna("").astype(str)

    if only_profit:
        g = g[g["profit"] > 0].copy()

    if g.empty:
        st.info("–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å SKU.")
        st.stop()

    g_buy = g.sort_values("buyout_qty", ascending=False).copy()
    g_buy["grp_buyout"] = abc_class_from_metric(g_buy, "buyout_qty")

    g_turn = g.sort_values("accruals", ascending=False).copy()
    g_turn["grp_turn"] = abc_class_from_metric(g_turn, "accruals")

    g_prof = g.sort_values("profit", ascending=False).copy()
    g_prof["grp_profit"] = abc_class_from_metric(g_prof, "profit")

    g_res = g.merge(g_buy[["sku","grp_buyout"]], on="sku", how="left")
    g_res = g_res.merge(g_turn[["sku","grp_turn"]], on="sku", how="left")
    g_res = g_res.merge(g_prof[["sku","grp_profit"]], on="sku", how="left")
    g_res["–ò–¢–û–ì–û"] = g_res["grp_buyout"].fillna("C") + g_res["grp_turn"].fillna("C") + g_res["grp_profit"].fillna("C")

    view = g_res.rename(columns={
        "sku": "SKU",
        "article": "–ê—Ä—Ç–∏–∫—É–ª",
        "name": "–¢–æ–≤–∞—Ä",
        "buyout_qty": "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç",
        "accruals": "–û–±–æ—Ä–æ—Ç, ‚ÇΩ",
        "profit": "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ",
        "grp_buyout": "–ì—Ä—É–ø–ø–∞ –ø–æ –≤—ã–∫—É–ø—É",
        "grp_turn": "–ì—Ä—É–ø–ø–∞ –ø–æ –æ–±–æ—Ä–æ—Ç—É",
        "grp_profit": "–ì—Ä—É–ø–ø–∞ –ø—Ä–∏–±—ã–ª—å"
    }).copy()

    # —ç–∫—Å–ø–æ—Ä—Ç (—Å—ã—Ä—ã–µ —á–∏—Å–ª–∞)
    export_df = view.copy()
    for col in ["–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç", "–û–±–æ—Ä–æ—Ç", "–ü—Ä–∏–±—ã–ª—å"]:
        if col in export_df.columns:
            export_df[col] = pd.to_numeric(export_df[col], errors="coerce")
    if "SKU" in export_df.columns:
        export_df["SKU"] = pd.to_numeric(export_df["SKU"], errors="coerce").astype("Int64")

    # –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–æ—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏)
    # –∫–æ–ª-–≤–æ: int, –¥–µ–Ω—å–≥–∏: float
    if "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç" in view.columns:
        view["–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç"] = pd.to_numeric(view["–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç"], errors="coerce").fillna(0).astype(int)
    if "–û–±–æ—Ä–æ—Ç, ‚ÇΩ" in view.columns:
        view["–û–±–æ—Ä–æ—Ç, ‚ÇΩ"] = pd.to_numeric(view["–û–±–æ—Ä–æ—Ç, ‚ÇΩ"], errors="coerce").fillna(0.0)
    if "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ" in view.columns:
        view["–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ"] = pd.to_numeric(view["–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ"], errors="coerce").fillna(0.0)

    # –ø–µ—Ä–µ–¥ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º (—á—Ç–æ–±—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –±—ã–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π)
    view["SKU"] = pd.to_numeric(view["SKU"], errors="coerce").fillna(0).astype(int)

    st.dataframe(
        view[[
            "–ê—Ä—Ç–∏–∫—É–ª", "SKU", "–¢–æ–≤–∞—Ä",
            "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç", "–ì—Ä—É–ø–ø–∞ –ø–æ –≤—ã–∫—É–ø—É",
            "–û–±–æ—Ä–æ—Ç, ‚ÇΩ", "–ì—Ä—É–ø–ø–∞ –ø–æ –æ–±–æ—Ä–æ—Ç—É",
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ", "–ì—Ä—É–ø–ø–∞ –ø—Ä–∏–±—ã–ª—å", "–ò–¢–û–ì–û"
        ]],
        use_container_width=True,
        hide_index=True,
        column_config={
            "SKU": st.column_config.NumberColumn(format="%.0f"),  # üëà –∫–ª—é—á–µ–≤–æ–µ: –±–µ–∑ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
            "–í—ã–∫—É–ø–ª–µ–Ω–æ, —à—Ç": st.column_config.NumberColumn(format="%.0f"),
            "–û–±–æ—Ä–æ—Ç, ‚ÇΩ": st.column_config.NumberColumn(format="%.0f"),
            "–ü—Ä–∏–±—ã–ª—å, ‚ÇΩ": st.column_config.NumberColumn(format="%.0f"),
        },
    )

    # ===== –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è XLSX (—Å–Ω–∏–∑—É —Å–ª–µ–≤–∞) =====
    def _period_label(mode, chosen_labels, chosen_q, sel_year):
        if mode == "–ú–µ—Å—è—Ü—ã":
            return f"{sel_year}_" + "-".join(chosen_labels) if chosen_labels else str(sel_year)
        else:
            return f"{sel_year}_" + "-".join(chosen_q) if chosen_q else str(sel_year)

    period_label = _period_label(mode, chosen_labels, chosen_q, sel_year)

    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        export_df.to_excel(writer, index=False, sheet_name="ABC")
    buf.seek(0)

    btn_col, _ = st.columns([1, 6])
    with btn_col:
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å XLSX",
            data=buf,
            file_name=f"ABC_{period_label}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
